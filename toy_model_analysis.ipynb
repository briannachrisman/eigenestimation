{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 366,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import importlib\n",
        "import gc\n",
        "import copy\n",
        "\n",
        "# Third-party imports\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import einops\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import GPT2Model, GPT2Config, GPT2Tokenizer\n",
        "from datasets import load_dataset\n",
        "from transformer_lens.utils import tokenize_and_concatenate\n",
        "\n",
        "# Local imports\n",
        "import toy_models.xornet\n",
        "import toy_models.tms\n",
        "import toy_models.train\n",
        "import toy_models.transformer_wrapper\n",
        "import eigenestimation_algorithm.train\n",
        "import eigenestimation_algorithm.eigenestimation\n",
        "import eigenestimation_algorithm.evaluation\n",
        "\n",
        "# Reload modules for interactive sessions\n",
        "importlib.reload(toy_models.xornet)\n",
        "importlib.reload(toy_models.tms)\n",
        "importlib.reload(toy_models.train)\n",
        "importlib.reload(toy_models.transformer_wrapper)\n",
        "importlib.reload(eigenestimation_algorithm.train)\n",
        "importlib.reload(eigenestimation_algorithm.eigenestimation)\n",
        "importlib.reload(eigenestimation_algorithm.evaluation)\n",
        "\n",
        "# Specific imports from local modules\n",
        "from toy_models.xornet import XORNet, GenerateXORData\n",
        "from toy_models.tms import Autoencoder, GenerateTMSData\n",
        "from toy_models.train import TrainModel\n",
        "from toy_models.transformer_wrapper import TransformerWrapper, DeleteParams, KLDivergenceLoss\n",
        "from eigenestimation_algorithm.eigenestimation import EigenEstimation\n",
        "from eigenestimation_algorithm.train import TrainEigenEstimation\n",
        "from eigenestimation_algorithm.evaluation import (\n",
        "    PrintFeatureVals,\n",
        "    ActivatingExamples,\n",
        "    PrintFeatureValsTransformer,\n",
        "    PrintActivatingExamplesTransformer,\n",
        ")\n",
        "\n",
        "# Device configuration\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "importlib.reload(eigenestimation_algorithm.evaluation)\n",
        "\n",
        "from eigenestimation_algorithm.evaluation import (\n",
        "    PrintFeatureVals,\n",
        "    ActivatingExamples,\n",
        "    PrintFeatureValsTransformer,\n",
        "    PrintActivatingExamplesTransformer,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Toy Models\n",
        "\n",
        "Setup toy models, generate/pull data, and train."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## XORNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_xornet, Y_xornet, dataloader_xornet = GenerateXORData(n_repeats=100, batch_size=24)\n",
        "model_xornet = XORNet().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 300, Loss: 1.2728344245260814e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/brianna-interpretability/eigenestimation/toy_models/train.py:53: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  return model, torch.Tensor(params), torch.Tensor(losses)\n"
          ]
        }
      ],
      "source": [
        "X_xornet, Y_xornet, dataloader_xornet = GenerateXORData(n_repeats=100, batch_size=24)\n",
        "model_xornet = XORNet().to(device)\n",
        "\n",
        "\n",
        "_, _, _ =TrainModel(\n",
        "    model=model_xornet,\n",
        "    criterion=nn.MSELoss(),\n",
        "    learning_rate=.01,\n",
        "    dataloader=dataloader_xornet,\n",
        "    n_epochs=1000,\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TMS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "id": "9Wj0Z4mdTQAO",
        "outputId": "6f33c69e-b0be-476c-aa99-de20e16a233c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 300, Loss: 0.005096422974020243\n",
            "Epoch 400, Loss: 0.0034515862353146076\n",
            "Epoch 500, Loss: 0.0016781346639618278\n",
            "Epoch 600, Loss: 0.006362148094922304\n",
            "Epoch 700, Loss: 0.004493646789342165\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[303], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m X_tms, Y_tms, dataloader_TMS \u001b[38;5;241m=\u001b[39m GenerateTMSData(\n\u001b[1;32m     12\u001b[0m     num_features\u001b[38;5;241m=\u001b[39mn_features, num_datapoints\u001b[38;5;241m=\u001b[39mn_datapoints, sparsity\u001b[38;5;241m=\u001b[39msparsity, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m     13\u001b[0m tms_model \u001b[38;5;241m=\u001b[39m Autoencoder(n_features, hidden_dim)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 14\u001b[0m _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mTrainModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtms_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMSELoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_TMS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation/toy_models/train.py:36\u001b[0m, in \u001b[0;36mTrainModel\u001b[0;34m(model, criterion, learning_rate, dataloader, n_epochs, device)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m---> 36\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     37\u001b[0m             optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Zero the gradients\u001b[39;00m\n\u001b[1;32m     38\u001b[0m             outputs \u001b[38;5;241m=\u001b[39m model(x_batch\u001b[38;5;241m.\u001b[39mto(device))  \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/utils/data/dataset.py:211\u001b[0m, in \u001b[0;36mTensorDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/utils/data/dataset.py:211\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(tensor[index] \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#@title Train TMS\n",
        "n_features = 5\n",
        "hidden_dim = 2\n",
        "n_datapoints = 2056\n",
        "sparsity = .05\n",
        "\n",
        "batch_size = 16\n",
        "learning_rate = .1\n",
        "n_epochs = 1000\n",
        "\n",
        "X_tms, Y_tms, dataloader_TMS = GenerateTMSData(\n",
        "    num_features=n_features, num_datapoints=n_datapoints, sparsity=sparsity, batch_size=batch_size)\n",
        "tms_model = Autoencoder(n_features, hidden_dim).to(device)\n",
        "_, _, _ = TrainModel(tms_model, nn.MSELoss(), learning_rate, dataloader_TMS, n_epochs=n_epochs, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot TMS representations.\n",
        "en = copy.deepcopy(tms_model.W).detach().cpu().numpy()\n",
        "\n",
        "for i in range(en.shape[1]):\n",
        "  plt.plot([0, en[0,i]], [0,en[1,i]], 'b-')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGTF2lp-813s"
      },
      "source": [
        "## 2-layer transformer\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "-JyFbkBhuOlR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pretrained model roneneldan/TinyStories-1M into HookedTransformer\n",
            "4096\n",
            "transformer.blocks.4.attn.W_K 4096\n"
          ]
        }
      ],
      "source": [
        "# @title Import pretrained gpt2 (2 layers)\n",
        "# Disable fused kernels (FlashAttention and memory-efficient attention)\n",
        "# We have to disable this to compute second-order gradients on transformer models.\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, GPT2LMHeadModel\n",
        "import transformer_lens\n",
        "torch.backends.cuda.enable_flash_sdp(False)\n",
        "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
        "\n",
        "# Ensure the math kernel is enabled (it is True by default)\n",
        "torch.backends.cuda.enable_math_sdp(True)\n",
        "\n",
        "# Load in a 2-L GPT2.\n",
        "#gpt2 = GPT2Model.from_pretrained('gpt2', config=config)\n",
        "#tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\",)\n",
        "#tokenizer.pad_token = tokenizer.eos_token\n",
        "#transformer_model = TransformerWrapper(gpt2, tokenizer)\n",
        "\n",
        "\n",
        "#gpt2  = transformer_lens.HookedTransformer.from_pretrained('gpt2-small')\n",
        "gpt2  = transformer_lens.HookedTransformer.from_pretrained(\"roneneldan/TinyStories-1M\")#\n",
        "#gpt2 = GPT2LMHeadModel.from_pretrained('gpt2', config=config)\n",
        "#tokenizer = gpt2.tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"roneneldan/TinyStories-1M\")\n",
        "#tokenizer.pad_token = tokenizer.eos_token\n",
        "transformer_model = TransformerWrapper(gpt2, gpt2.tokenizer)\n",
        "\n",
        "# Make the eigenestimation a little smaller but only looking at a subset of the parameters.\n",
        "# Pick a random subset of tensors to include in paramters, and turn the rest into frozen buffers.\n",
        "params_to_delete = [name for name, param in transformer_model.named_parameters()]\n",
        "params_to_delete = [p for p in params_to_delete if 'blocks.4.attn.W_K' not in p]#!='transformer.h.1.ln_2.weight']\n",
        "\n",
        "# Delete 3/4 of the parameters.\n",
        "#for p in (params_to_delete[::20]):\n",
        "#  params_to_delete.remove(p)\n",
        "\n",
        "DeleteParams(transformer_model, params_to_delete)\n",
        "\n",
        "print(sum([p.numel() for p in transformer_model.parameters()]))\n",
        "for n,p in transformer_model.named_parameters(): print(n, p.numel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPT2TokenizerFast(name_or_path='roneneldan/TinyStories-1M', vocab_size=50257, model_max_length=2048, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
              "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
              "}"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([27321, 16])\n"
          ]
        }
      ],
      "source": [
        "# Load in data.\n",
        "#dataset = load_dataset('imdb', split='test[:5%]')\n",
        "dataset = load_dataset('roneneldan/TinyStories', split=\"validation[:10%]\")\n",
        "#del dataset, X_transformer\n",
        "#dataset = load_dataset('imdb', split='train')\n",
        "X_transformer = tokenize_and_concatenate(dataset, transformer_model.tokenizer, max_length = 16, add_bos_token=False)['tokens']\n",
        "transformer_dataloader = DataLoader(X_transformer, batch_size=24, shuffle=True)\n",
        "print(X_transformer.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F3k4QTXsbgM"
      },
      "source": [
        "# Eigenestimation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz2siQHyQWZ0"
      },
      "source": [
        "# Tests on Toy Models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlNRhg3iQ2yk"
      },
      "source": [
        "## Xornet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7gdVpNvP5oU",
        "outputId": "fdbd20b8-606b-4cab-e291-154210b81316"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 : -1.766,  High Hessian Loss: -2.073,  Basis Loss: 0.307\n",
            "Epoch 1 : -1.515,  High Hessian Loss: -1.656,  Basis Loss: 0.141\n",
            "Epoch 2 : -1.839,  High Hessian Loss: -2.019,  Basis Loss: 0.180\n",
            "Epoch 3 : -2.063,  High Hessian Loss: -2.379,  Basis Loss: 0.316\n",
            "Epoch 4 : -2.230,  High Hessian Loss: -2.715,  Basis Loss: 0.485\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 160,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_u_vectors = 3\n",
        "batch_size = 8\n",
        "lambda_penalty = 1\n",
        "repeats = 24\n",
        "n_epochs = 5\n",
        "learning_rate = .01\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "eigenmodel_xornet = EigenEstimation(model_xornet.to(device), lambda x,y : nn.MSELoss(reduction='none')(x,y).mean(dim=-1).unsqueeze(-1), n_u_vectors).to(device)\n",
        "\n",
        "dataloader_xornet_eigen = DataLoader(\n",
        "    einops.repeat(X_xornet, 's f -> (s r) f', r=repeats), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "TrainEigenEstimation(eigenmodel_xornet, dataloader_xornet_eigen, learning_rate, n_epochs, lambda_penalty, device=device)\n",
        "\n",
        "# Clear cuda cache\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUGWSKrfRJOv",
        "outputId": "79eaa80b-8a64-4671-c74c-301123572273"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 0.] -->\n",
            " [[0.27]\n",
            " [0.16]\n",
            " [0.01]]\n",
            "[0. 1.] -->\n",
            " [[0.62]\n",
            " [2.67]\n",
            " [0.04]]\n",
            "[1. 0.] -->\n",
            " [[1.09]\n",
            " [0.66]\n",
            " [2.02]]\n",
            "[1. 1.] -->\n",
            " [[2.33]\n",
            " [0.53]\n",
            " [0.39]]\n",
            "feature 0\n",
            "[1. 1.] -> 2.3252432\n",
            "[1. 0.] -> 1.0929958\n",
            "[0. 1.] -> 0.61902356\n",
            "[0. 0.] -> 0.273664\n",
            "feature 1\n",
            "[0. 1.] -> 2.670694\n",
            "[1. 0.] -> 0.65577537\n",
            "[1. 1.] -> 0.52892005\n",
            "[0. 0.] -> 0.15629882\n",
            "feature 2\n",
            "[1. 0.] -> 2.021866\n",
            "[1. 1.] -> 0.39354768\n",
            "[0. 1.] -> 0.035297774\n",
            "[0. 0.] -> 0.011965705\n"
          ]
        }
      ],
      "source": [
        "# Look at features\n",
        "PrintFeatureVals(X_xornet, eigenmodel_xornet)\n",
        "\n",
        "for f_idx in range(eigenmodel_xornet.n_u_vectors):\n",
        "  sample, val = ActivatingExamples(X_xornet.to(device), eigenmodel_xornet.to(device), f_idx, 4, device=device)\n",
        "  print('feature', f_idx)\n",
        "  for s, v in zip(sample, val):\n",
        "    print(s, '->', v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.5512, -0.1639, -0.1506, -0.4597, -0.4121, -0.5152],\n",
              "        [-0.2677,  0.5992,  0.5294, -0.3516,  0.4063, -0.0194],\n",
              "        [ 0.2417, -0.0943, -0.7611, -0.5743, -0.0809, -0.1305]],\n",
              "       device='cuda:0', requires_grad=True)"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eigenmodel_xornet.u"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCx0rhdoTGJx"
      },
      "source": [
        "## TMS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 374,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLj93rI3TIJ9",
        "outputId": "b45eb47a-3e70-4927-8785-a1722ff46080"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 : -0.134,  High Hessian Loss: -0.194,  Basis Loss: 0.060\n",
            "Epoch 1 : -0.151,  High Hessian Loss: -0.165,  Basis Loss: 0.013\n",
            "Epoch 2 : -0.171,  High Hessian Loss: -0.201,  Basis Loss: 0.030\n",
            "Epoch 3 : -0.178,  High Hessian Loss: -0.219,  Basis Loss: 0.041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f76c9c870a0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ubuntu/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
            "    def _clean_thread_parent_frames(\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 : -0.227,  High Hessian Loss: -0.271,  Basis Loss: 0.044\n",
            "Epoch 5 : -0.263,  High Hessian Loss: -0.284,  Basis Loss: 0.021\n",
            "Epoch 6 : -0.238,  High Hessian Loss: -0.247,  Basis Loss: 0.009\n",
            "Epoch 7 : -0.234,  High Hessian Loss: -0.249,  Basis Loss: 0.015\n",
            "Epoch 8 : -0.265,  High Hessian Loss: -0.282,  Basis Loss: 0.017\n",
            "Epoch 9 : -0.272,  High Hessian Loss: -0.277,  Basis Loss: 0.005\n",
            "Epoch 10 : -0.267,  High Hessian Loss: -0.269,  Basis Loss: 0.002\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f76c9c870a0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ubuntu/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
            "    def _clean_thread_parent_frames(\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 : -0.249,  High Hessian Loss: -0.252,  Basis Loss: 0.003\n",
            "Epoch 12 : -0.211,  High Hessian Loss: -0.219,  Basis Loss: 0.008\n",
            "Epoch 13 : -0.204,  High Hessian Loss: -0.215,  Basis Loss: 0.011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f76c9c870a0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ubuntu/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
            "    def _clean_thread_parent_frames(\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14 : -0.259,  High Hessian Loss: -0.278,  Basis Loss: 0.019\n",
            "Epoch 15 : -0.296,  High Hessian Loss: -0.316,  Basis Loss: 0.020\n",
            "Epoch 16 : -0.267,  High Hessian Loss: -0.290,  Basis Loss: 0.023\n",
            "Epoch 17 : -0.263,  High Hessian Loss: -0.279,  Basis Loss: 0.016\n",
            "Epoch 18 : -0.278,  High Hessian Loss: -0.298,  Basis Loss: 0.020\n",
            "Epoch 19 : -0.272,  High Hessian Loss: -0.288,  Basis Loss: 0.016\n"
          ]
        }
      ],
      "source": [
        "#@title Train Eigenmodel\n",
        "n_u_vectors = 5\n",
        "batch_size = 4\n",
        "lambda_penalty = 1\n",
        "n_epochs = 20\n",
        "learning_rate = .01\n",
        "\n",
        "\n",
        "dataloader = DataLoader(X_tms, batch_size=batch_size, shuffle=True)\n",
        "eigenmodel_tms = EigenEstimation(tms_model.to(device),lambda x,y : nn.MSELoss(reduction='none')(x,y).mean(dim=-1).unsqueeze(-1), n_u_vectors).to(device)\n",
        "TrainEigenEstimation(eigenmodel_tms, dataloader, learning_rate, n_epochs, lambda_penalty, device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 379,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLJPlPcZTIKK",
        "outputId": "f75e7cf5-9dd5-4829-f6cd-cfecaf2daa08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "feature 0\n",
            "[0.    0.779 0.    0.    0.948] -> 3.342\n",
            "[0.    0.833 0.    0.    0.35 ] -> 2.111\n",
            "[0.    0.999 0.    0.    0.   ] -> 1.862\n",
            "[0.    0.997 0.    0.    0.   ] -> 1.857\n",
            "[0.    0.272 0.    0.    0.944] -> 1.836\n",
            "feature 1\n",
            "[0.888 0.    0.    0.835 0.   ] -> 3.406\n",
            "[0.795 0.    0.    0.812 0.   ] -> 3.075\n",
            "[0.796 0.    0.    0.78  0.   ] -> 2.977\n",
            "[0.472 0.    0.    0.881 0.   ] -> 2.455\n",
            "[0.285 0.    0.    0.91  0.   ] -> 2.101\n",
            "feature 2\n",
            "[0.758 0.    0.    0.    0.975] -> 2.078\n",
            "[0.641 0.    0.    0.    0.698] -> 1.383\n",
            "[0.517 0.    0.    0.    0.744] -> 1.295\n",
            "[0.    0.    0.    0.    0.999] -> 1.274\n",
            "[0.    0.    0.    0.    0.992] -> 1.259\n",
            "feature 3\n",
            "[0.758 0.    0.    0.    0.975] -> 2.516\n",
            "[0.641 0.    0.    0.    0.698] -> 1.724\n",
            "[0.979 0.    0.    0.    0.   ] -> 1.666\n",
            "[0.971 0.    0.    0.    0.   ] -> 1.646\n",
            "[0.517 0.    0.    0.    0.744] -> 1.546\n",
            "feature 4\n",
            "[0.126 0.    0.942 0.477 0.   ] -> 2.439\n",
            "[0.    0.    0.984 0.    0.   ] -> 2.241\n",
            "[0.    0.    0.971 0.    0.   ] -> 2.199\n",
            "[0.   0.   0.97 0.   0.  ] -> 2.196\n",
            "[0.    0.    0.967 0.    0.   ] -> 2.187\n",
            "feature 0\n",
            "[0.    0.999 0.    0.    0.   ] -> 1.862\n",
            "[0.    0.997 0.    0.    0.   ] -> 1.857\n",
            "[0.    0.981 0.    0.    0.   ] -> 1.816\n",
            "[0.    0.971 0.    0.    0.   ] -> 1.793\n",
            "[0.    0.957 0.    0.    0.   ] -> 1.758\n",
            "feature 1\n",
            "[0.    0.    0.    0.998 0.   ] -> 1.728\n",
            "[0.    0.    0.    0.996 0.   ] -> 1.724\n",
            "[0.    0.    0.    0.995 0.   ] -> 1.721\n",
            "[0.    0.    0.    0.991 0.   ] -> 1.712\n",
            "[0.   0.   0.   0.97 0.  ] -> 1.662\n",
            "feature 2\n",
            "[0.    0.    0.    0.    0.999] -> 1.274\n",
            "[0.    0.    0.    0.    0.992] -> 1.259\n",
            "[0.    0.    0.    0.    0.969] -> 1.213\n",
            "[0.    0.    0.    0.    0.952] -> 1.181\n",
            "[0.    0.    0.    0.    0.938] -> 1.154\n",
            "feature 3\n",
            "[0.979 0.    0.    0.    0.   ] -> 1.666\n",
            "[0.971 0.    0.    0.    0.   ] -> 1.646\n",
            "[0.915 0.    0.    0.    0.   ] -> 1.523\n",
            "[0.901 0.    0.    0.    0.   ] -> 1.493\n",
            "[0.897 0.    0.    0.    0.   ] -> 1.485\n",
            "feature 4\n",
            "[0.    0.    0.984 0.    0.   ] -> 2.241\n",
            "[0.    0.    0.971 0.    0.   ] -> 2.199\n",
            "[0.   0.   0.97 0.   0.  ] -> 2.196\n",
            "[0.    0.    0.967 0.    0.   ] -> 2.187\n",
            "[0.    0.    0.958 0.    0.   ] -> 2.157\n"
          ]
        }
      ],
      "source": [
        "#@title Look at features\n",
        "#X = X_tms[:10]\n",
        "#PrintFeatureVals(X_tms, eigenmodel_tms)\n",
        "\n",
        "\n",
        "    \n",
        "for f_idx in range(eigenmodel_tms.n_u_vectors):\n",
        "  sample, val = ActivatingExamples(X_tms, eigenmodel_tms, f_idx, 5)\n",
        "  print('feature', f_idx)\n",
        "  for s, v in zip(sample, val):\n",
        "    print(s.round(3), '->', v.round(3))\n",
        "\n",
        "for f_idx in range(eigenmodel_tms.n_u_vectors):\n",
        "  sample, val = ActivatingExamples(X_tms[(X_tms!=0).sum(dim=-1)==1], eigenmodel_tms, f_idx, 5)\n",
        "  print('feature', f_idx)\n",
        "  for s, v in zip(sample, val):\n",
        "    print(s.round(3), '->', v.round(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 376,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[-0.   0.5 -0.   0.   0.3]\n",
            "  [-0.  -0.3  0.   0.  -0.3]]\n",
            "\n",
            " [[ 0.4  0.  -0.   0.3 -0. ]\n",
            "  [-0.4 -0.  -0.  -0.4 -0.1]]\n",
            "\n",
            " [[-0.2  0.1  0.   0.1 -0.4]\n",
            "  [ 0.3 -0.   0.   0.  -0.6]]\n",
            "\n",
            " [[ 0.4 -0.1  0.   0.   0.2]\n",
            "  [ 0.3  0.   0.  -0.3  0.4]]\n",
            "\n",
            " [[-0.  -0.1 -0.6 -0.1 -0. ]\n",
            "  [-0.  -0.1 -0.5 -0.1 -0. ]]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot TMS representations.\n",
        "en = torch.stack([eigenmodel_tms.vector_to_parameters(u)['W'] for u in eigenmodel_tms.u]).detach().cpu().numpy().round(1)\n",
        "print(en)\n",
        "hues = ['b-', 'r-', 'g-', 'y-', 'k-']\n",
        "for hue, feature in zip(hues, en):\n",
        "    for x,y in zip(feature[0], feature[1]):\n",
        "        plt.plot([0, x], [0,y], hue, label=hue)\n",
        "\n",
        "en = copy.deepcopy(tms_model.W).detach().cpu().numpy()\n",
        "\n",
        "for i in range(en.shape[1]):\n",
        "  plt.plot([0, en[0,i]], [0,en[1,i]], color='grey', alpha=.1)\n",
        "\n",
        "\n",
        "plt.xlabel('')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 308,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[ 0. ,  0. , -0.2,  0.2,  0.1],\n",
              "        [ 0. , -0.2,  0.4, -0.1,  0.7]],\n",
              "\n",
              "       [[ 0.4,  0. , -0. ,  0. ,  0.3],\n",
              "        [ 0.3, -0. ,  0. ,  0.5, -0.3]],\n",
              "\n",
              "       [[ 0. , -0. , -0. ,  0.2, -0.5],\n",
              "        [-0. ,  0. , -0. ,  0.5,  0.1]],\n",
              "\n",
              "       [[-0.3, -0.8,  0. , -0. ,  0.2],\n",
              "        [ 0.2,  0.1,  0.1, -0.3,  0.2]],\n",
              "\n",
              "       [[ 0. ,  0.4,  0.4, -0. , -0.1],\n",
              "        [-0.1,  0. , -0.4, -0.1, -0.3]],\n",
              "\n",
              "       [[-0. ,  0.8,  0.3,  0.1,  0.1],\n",
              "        [ 0.1,  0.3, -0.2, -0. ,  0.1]]], dtype=float32)"
            ]
          },
          "execution_count": 308,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6, 2, 5)"
            ]
          },
          "execution_count": 289,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "en.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5, 2, 5)"
            ]
          },
          "execution_count": 279,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "en.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 5)"
            ]
          },
          "execution_count": 277,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[-0. ,  0.7,  0.5,  0. ,  0. ],\n",
              "        [ 0. ,  0.1,  0.4, -0. ,  0. ]],\n",
              "\n",
              "       [[-0.4,  0. , -0. , -0.1,  0. ],\n",
              "        [-0.4,  0.1, -0. , -0.5,  0. ]],\n",
              "\n",
              "       [[ 0. ,  0.7,  0.1,  0. ,  0. ],\n",
              "        [-0. , -0.1, -0. , -0. , -0. ]],\n",
              "\n",
              "       [[ 0. ,  0.1,  0.1, -0. ,  0. ],\n",
              "        [-0. ,  0. , -0.5,  0. , -0.7]],\n",
              "\n",
              "       [[-0.4, -0.3,  0. , -0.1,  0. ],\n",
              "        [ 0.3,  0.4, -0. , -0.3,  0. ]]], dtype=float32)"
            ]
          },
          "execution_count": 259,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for i in \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBq1uAotxJB_"
      },
      "source": [
        "## 2L Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 389,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6973GptxH2T",
        "outputId": "bcae6bb6-fe6d-4226-8b7f-c93bb10b472f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 : -6.750,  High Hessian Loss: -8.918,  Basis Loss: 2.167\n",
            "Epoch 1 : -7.106,  High Hessian Loss: -8.995,  Basis Loss: 1.889\n"
          ]
        }
      ],
      "source": [
        "#@title Train Eigenmodel\n",
        "n_u_vectors = 10\n",
        "batch_size = 32\n",
        "lambda_penalty = 1\n",
        "n_epochs = 2\n",
        "learning_rate = .01\n",
        "u_batch_size = 10\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "x_transformer_dataloader = DataLoader(X_transformer[:500], batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "#eigenmodel_transformer = EigenEstimation(transformer_model.to(device), \n",
        "#                         KLDivergenceLoss(reduction='none'), n_u_vectors, u_chunk_size=10).to(device)\n",
        "\n",
        "TrainEigenEstimation(\n",
        "    eigenmodel_transformer,\n",
        "    x_transformer_dataloader,\n",
        "    lr=learning_rate,\n",
        "    n_epochs= n_epochs,\n",
        "    lambda_penalty=lambda_penalty,\n",
        "    u_batch_size = u_batch_size,\n",
        "    device = device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 391,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "transformer.blocks.4.attn.W_K 4096\n",
            "\n",
            "\n",
            " upon a time, there was a kind man named Tom**.** Tom had a big -> . (Value: 42.845)\n",
            " zoo.Once upon a time, there was a little boy named Timmy**.** -> . (Value: 40.725)\n",
            " upon a time, there was a woman named Lily.** She** loved to go for ->  She (Value: 38.833)\n",
            "Once upon a time, there was a little boy named Timmy**.** Timmy -> . (Value: 38.542)\n",
            "Once upon a time, there was a little boy named Timmy**.** Timmy -> . (Value: 38.542)\n",
            "\n",
            "\n",
            " upon a time, there was a woman named Lily.** She** loved to go for ->  She (Value: 64.518)\n",
            " could always ask the black cat.Once upon a time**,** there was a small -> , (Value: 56.562)\n",
            " loved ones. The end.Once upon a time**,** there was a little girl -> , (Value: 50.217)\n",
            " enjoyed the sunshine.Once upon a time**,** there was a little boy -> , (Value: 46.414)\n",
            " street and always looked out for banana peels.Once upon a time**,** there -> , (Value: 46.287)\n",
            "\n",
            "\n",
            " and trucks. One day,** Tim**my's dad took him to the park to ->  Tim (Value: 69.034)\n",
            " lost and felt sad.newlinenewlineOne day,** Tim**my's friend, a ->  Tim (Value: 66.466)\n",
            " toys. The next day,** Tim**my went to his friend's house and said ->  Tim (Value: 62.213)\n",
            " was playing just as well as before.** Tim**my was so happy with his new ->  Tim (Value: 57.687)\n",
            " the noisy trunk.Once upon a time, there was a boy named** Tim**my ->  Tim (Value: 54.684)\n",
            "\n",
            "\n",
            " park. One day, she saw a big statue of a dog**.** It was -> . (Value: 30.722)\n",
            "'t like that. He wanted his truck to be the** best**. They argued for ->  best (Value: 27.736)\n",
            " every day. One day, he saw a little bird on a branch**.** The -> . (Value: 26.222)\n",
            "newlinenewlineOne day, Timmy saw a black cat in his backyard**.** The -> . (Value: 22.828)\n",
            "ily said, \"Let's ask for help!\" They saw a man** and** asked ->  and (Value: 22.407)\n",
            "\n",
            "\n",
            " upon a time, there was a woman named Lily.** She** loved to go for ->  She (Value: 59.775)\n",
            "Once upon a time, there was an old man.** He** liked to read magazines ->  He (Value: 39.421)\n",
            " the noisy trunk.Once upon a time, there was a boy named** Tim**my ->  Tim (Value: 38.685)\n",
            " summer.Once upon a time, there was an old lady.** She** was very ->  She (Value: 37.195)\n",
            " came in to see what was going on.newlinenewlineShe told** Tim**my that ->  Tim (Value: 36.652)\n",
            "\n",
            "\n",
            " the park every day. newlinenewlineOne day, the man** saw** the woman ->  saw (Value: 39.632)\n",
            " the dark hole in the ground and he fell in.newlinenewline**Tim**my tried -> Tim (Value: 30.418)\n",
            " and went inside the tent. newlinenewlineThe lion** saw** a man with a ->  saw (Value: 28.665)\n",
            " Allowed.\" Timmy was sad because he wanted Max to come with them**.** -> . (Value: 28.455)\n",
            "'s mommy lifted her up so she could see over it. She** saw** her ->  saw (Value: 28.105)\n",
            "\n",
            "\n",
            " toy tools. From that day on,** Tim**my learned the importance of sharing and ->  Tim (Value: 75.689)\n",
            " was playing just as well as before.** Tim**my was so happy with his new ->  Tim (Value: 63.231)\n",
            " at them. He even got to touch a baby shark! After that,** Tim** ->  Tim (Value: 59.772)\n",
            " then, his mom came in and asked what was wrong.** Tim**my told her ->  Tim (Value: 58.194)\n",
            " the dark hole in the ground and he fell in.newlinenewline**Tim**my tried -> Tim (Value: 57.360)\n",
            "\n",
            "\n",
            " named Timmy. He had a big, brown dog named Max**.** Max loved -> . (Value: 54.549)\n",
            " park. One day, she saw a big statue of a dog**.** It was -> . (Value: 43.561)\n",
            " She loved to walk on the trail with her dog, Max**.** Max was very -> . (Value: 39.359)\n",
            "newlinenewlineOne day, Timmy saw a black cat in his backyard**.** The -> . (Value: 36.026)\n",
            " and wanted to make him feel better. Tommy** told** Sammy a joke and Sammy laughed ->  told (Value: 34.926)\n",
            "\n",
            "\n",
            " was playing just as well as before.** Tim**my was so happy with his new ->  Tim (Value: 55.711)\n",
            " part of the park where dogs were allowed.** Tim**my was happy again because he ->  Tim (Value: 38.506)\n",
            " then, his mom came in and asked what was wrong.** Tim**my told her ->  Tim (Value: 37.558)\n",
            " should answer with courage. So,** Tim**my took a deep breath and stood up ->  Tim (Value: 34.767)\n",
            " came in to see what was going on.newlinenewlineShe told** Tim**my that ->  Tim (Value: 33.680)\n",
            "\n",
            "\n",
            " came in to see what was going on.newlinenewlineShe told** Tim**my that ->  Tim (Value: 46.779)\n",
            " at them. He even got to touch a baby shark! After that,** Tim** ->  Tim (Value: 34.167)\n",
            " the dark hole in the ground and he fell in.newlinenewline**Tim**my tried -> Tim (Value: 30.990)\n",
            " part of the park where dogs were allowed.** Tim**my was happy again because he ->  Tim (Value: 30.866)\n",
            " that they were safe.newlinenewlineBut the next day,** Tim**my didn't ->  Tim (Value: 30.029)\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "for n, p in eigenmodel_transformer.model.named_parameters(): print(n, p.numel())\n",
        "print('\\n')\n",
        "for i in list(range(min(50,eigenmodel_transformer.n_u_vectors))):\n",
        "  PrintActivatingExamplesTransformer(eigenmodel_transformer, X_transformer[500:1500], i, 5, 64, device)\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.0000e+00,  1.7224e-03, -9.3009e-05,  ..., -1.8438e-03,\n",
              "          2.3738e-04, -8.3544e-04],\n",
              "        [ 1.7224e-03,  1.0000e+00,  1.2504e-03,  ..., -2.0977e-03,\n",
              "          2.0711e-02,  5.4612e-04],\n",
              "        [-9.3009e-05,  1.2504e-03,  1.0000e+00,  ...,  4.9548e-04,\n",
              "          2.3637e-04,  9.0389e-04],\n",
              "        ...,\n",
              "        [-1.8438e-03, -2.0977e-03,  4.9548e-04,  ...,  1.0000e+00,\n",
              "          1.7052e-03, -1.3676e-03],\n",
              "        [ 2.3738e-04,  2.0711e-02,  2.3637e-04,  ...,  1.7052e-03,\n",
              "          1.0000e+00, -3.7534e-04],\n",
              "        [-8.3544e-04,  5.4612e-04,  9.0389e-04,  ..., -1.3676e-03,\n",
              "         -3.7534e-04,  1.0000e+00]], device='cuda:0', grad_fn=<MmBackward0>)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eigenmodel_transformer.u @ eigenmodel_transformer.u.transpose(0,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.9555, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "tensor(-0.9555, device='cuda:0', grad_fn=<MinBackward1>)\n",
            "tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    abs(torch.tril(eigenmodel_transformer.u @ eigenmodel_transformer.u.transpose(0,1), diagonal=-1)\n",
        "    ).max())\n",
        "print((\n",
        "    torch.tril(eigenmodel_transformer.u @ eigenmodel_transformer.u.transpose(0,1), diagonal=-1)).min()\n",
        ")\n",
        "print(abs(\n",
        "    2*torch.tril(eigenmodel_transformer.u @ eigenmodel_transformer.u.transpose(0,1), diagonal=-1)).mean()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SCRATCH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "hvp_revrev.<locals>.<lambda>() takes 1 positional argument but 2 were given",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m params \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m2\u001b[39m, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)    \u001b[38;5;66;03m# Parameters to differentiate\u001b[39;00m\n\u001b[1;32m     25\u001b[0m tangent_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn((\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m))   \u001b[38;5;66;03m# Tangents for each parameter\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mhvp_revrev\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtangent_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Vectorize over both the parameters (tangents) and input samples\u001b[39;00m\n\u001b[1;32m     30\u001b[0m batched_hvp \u001b[38;5;241m=\u001b[39m vmap(\u001b[38;5;28;01mlambda\u001b[39;00m t: hvp_revrev(f, x_batch, t, params))(tangent_batch)\n",
            "Cell \u001b[0;32mIn[6], line 14\u001b[0m, in \u001b[0;36mhvp_revrev\u001b[0;34m(f, primals, params, *tangents)\u001b[0m\n\u001b[1;32m     12\u001b[0m grad_f \u001b[38;5;241m=\u001b[39m grad(\u001b[38;5;28;01mlambda\u001b[39;00m p: f(primals, p))\u001b[38;5;66;03m#(params)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Perform VJP to get HVP\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m _, vjp_fn \u001b[38;5;241m=\u001b[39m \u001b[43mvjp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprimals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m*\u001b[39mtangents)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vjp_fn(\u001b[38;5;241m*\u001b[39mtangents)\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/eager_transforms.py:338\u001b[0m, in \u001b[0;36mvjp\u001b[0;34m(func, has_aux, *primals)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;129m@exposed_in\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.func\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(func: Callable, \u001b[38;5;241m*\u001b[39mprimals, has_aux: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    243\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;124;03m    Standing for the vector-Jacobian product, returns a tuple containing the\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m    results of ``func`` applied to ``primals`` and a function that, when\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m        should not depend on the result of a context manager outside of ``f``.\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 338\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_vjp_with_argnums\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprimals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_aux\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/vmap.py:48\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 48\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/eager_transforms.py:399\u001b[0m, in \u001b[0;36m_vjp_with_argnums\u001b[0;34m(func, argnums, has_aux, *primals)\u001b[0m\n\u001b[1;32m    397\u001b[0m     diff_primals \u001b[38;5;241m=\u001b[39m _slice_argnums(primals, argnums, as_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    398\u001b[0m     tree_map_(partial(_create_differentiable, level\u001b[38;5;241m=\u001b[39mlevel), diff_primals)\n\u001b[0;32m--> 399\u001b[0m primals_out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprimals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(primals_out, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(primals_out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n",
            "Cell \u001b[0;32mIn[6], line 14\u001b[0m, in \u001b[0;36mhvp_revrev.<locals>.<lambda>\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m     12\u001b[0m grad_f \u001b[38;5;241m=\u001b[39m grad(\u001b[38;5;28;01mlambda\u001b[39;00m p: f(primals, p))\u001b[38;5;66;03m#(params)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Perform VJP to get HVP\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m _, vjp_fn \u001b[38;5;241m=\u001b[39m vjp(\u001b[38;5;28;01mlambda\u001b[39;00m p: \u001b[43mgrad_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprimals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m, params)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m*\u001b[39mtangents)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vjp_fn(\u001b[38;5;241m*\u001b[39mtangents)\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/apis.py:399\u001b[0m, in \u001b[0;36mgrad.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43meager_transforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/eager_transforms.py:1449\u001b[0m, in \u001b[0;36mgrad_impl\u001b[0;34m(func, argnums, has_aux, args, kwargs)\u001b[0m\n\u001b[1;32m   1448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrad_impl\u001b[39m(func: Callable, argnums: argnums_t, has_aux: \u001b[38;5;28mbool\u001b[39m, args, kwargs):\n\u001b[0;32m-> 1449\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_and_value_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1450\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m   1451\u001b[0m         grad, (_, aux) \u001b[38;5;241m=\u001b[39m results\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/vmap.py:48\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 48\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/eager_transforms.py:1407\u001b[0m, in \u001b[0;36mgrad_and_value_impl\u001b[0;34m(func, argnums, has_aux, args, kwargs)\u001b[0m\n\u001b[1;32m   1404\u001b[0m diff_args \u001b[38;5;241m=\u001b[39m _slice_argnums(args, argnums, as_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1405\u001b[0m tree_map_(partial(_create_differentiable, level\u001b[38;5;241m=\u001b[39mlevel), diff_args)\n\u001b[0;32m-> 1407\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m   1409\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n",
            "\u001b[0;31mTypeError\u001b[0m: hvp_revrev.<locals>.<lambda>() takes 1 positional argument but 2 were given"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.func import vmap, vjp, grad\n",
        "\n",
        "# Define a function with parameters and inputs\n",
        "def f(x, params):\n",
        "    # Example function with parameters (a simple linear combination)\n",
        "    return (x * params).sin().sum()\n",
        "\n",
        "# HVP function that takes parameters\n",
        "def hvp_revrev(f, primals, params, *tangents):\n",
        "    # Compute gradient of f with respect to params only\n",
        "    grad_f = grad(lambda p: f(primals, p))#(params)\n",
        "    # Perform VJP to get HVP\n",
        "    _, vjp_fn = vjp(lambda p: grad_f(primals, p), params)\n",
        "    print(*tangents)\n",
        "    return vjp_fn(*tangents)\n",
        "\n",
        "# Batch sizes for inputs and parameters\n",
        "batch_size = 2048\n",
        "num_tangents = 10\n",
        "\n",
        "# Sample inputs and parameters\n",
        "x_batch = torch.randn((10, 2), requires_grad=False)  # Input, no gradient needed\n",
        "params = torch.randn(2, requires_grad=True)    # Parameters to differentiate\n",
        "tangent_batch = torch.randn((3, 2))   # Tangents for each parameter\n",
        "\n",
        "print(hvp_revrev(f, x_batch[1,:], params, tangent_batch[1,:]))\n",
        "\n",
        "# Vectorize over both the parameters (tangents) and input samples\n",
        "batched_hvp = vmap(lambda t: hvp_revrev(f, x_batch, t, params))(tangent_batch)\n",
        "\n",
        "print(batched_hvp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.9411869049072266\n",
            "1.9412012100219727\n",
            "torch.Size([48, 24])\n",
            "5.047354221343994\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[-5.3644e-07, -1.5974e-05,  0.0000e+00,  ..., -2.2590e-05,\n",
              "           2.3651e-04,  7.4776e-07],\n",
              "         [ 0.0000e+00,  8.0542e-07, -6.5770e-05,  ..., -3.8147e-06,\n",
              "           5.7220e-06,  2.6703e-05],\n",
              "         [ 2.3842e-07,  3.0518e-05,  0.0000e+00,  ..., -7.4191e-05,\n",
              "           1.5259e-05,  9.1553e-05],\n",
              "         ...,\n",
              "         [ 5.0664e-07, -6.6757e-06,  1.9073e-05,  ...,  6.6757e-06,\n",
              "           3.5095e-04, -1.6223e-04],\n",
              "         [ 2.3842e-07, -1.2643e-04,  6.1035e-05,  ...,  2.2888e-05,\n",
              "          -3.9673e-04,  3.0836e-05],\n",
              "         [-8.3447e-07, -3.5381e-04, -1.5640e-04,  ..., -3.6422e-04,\n",
              "           0.0000e+00,  9.5367e-05]],\n",
              "\n",
              "        [[-5.9605e-08, -1.4496e-04, -7.6294e-06,  ...,  3.8862e-05,\n",
              "           1.1826e-04,  1.9958e-06],\n",
              "         [-8.1956e-07,  1.3017e-06,  1.0261e-05,  ...,  8.5831e-06,\n",
              "           1.2207e-04,  5.7220e-06],\n",
              "         [ 1.2293e-07,  1.5259e-05,  1.5259e-05,  ..., -1.3313e-05,\n",
              "          -1.0490e-05,  1.5259e-05],\n",
              "         ...,\n",
              "         [ 1.7136e-06, -4.1008e-05,  0.0000e+00,  ...,  7.6294e-05,\n",
              "          -1.5259e-05, -2.0325e-05],\n",
              "         [ 2.3842e-07,  2.6511e-05, -6.1035e-05,  ...,  3.8147e-06,\n",
              "          -5.3406e-05,  4.0352e-05],\n",
              "         [-1.7881e-07, -8.4496e-04, -1.1826e-04,  ...,  1.6384e-04,\n",
              "           6.1035e-05,  4.5776e-05]],\n",
              "\n",
              "        [[-2.9802e-08,  1.0490e-05, -1.1444e-05,  ..., -1.5423e-06,\n",
              "           6.4850e-05,  1.5505e-07],\n",
              "         [ 3.7253e-08,  7.3685e-08,  9.4277e-06,  ..., -1.9073e-06,\n",
              "           3.0279e-05,  9.5367e-07],\n",
              "         [ 1.4901e-08,  5.7220e-06, -9.5367e-07,  ..., -4.3968e-06,\n",
              "          -1.5259e-05,  4.5776e-05],\n",
              "         ...,\n",
              "         [ 1.0058e-07,  5.4538e-05, -3.8147e-06,  ...,  2.8610e-06,\n",
              "          -5.0545e-05, -2.5183e-05],\n",
              "         [-7.4506e-09, -3.1775e-05,  1.5259e-05,  ..., -5.7220e-06,\n",
              "          -6.1035e-05,  2.1571e-05],\n",
              "         [ 2.9802e-08, -3.4332e-05, -2.0027e-05,  ..., -1.1317e-05,\n",
              "           1.3351e-05,  0.0000e+00]],\n",
              "\n",
              "        [[-3.4273e-07,  1.1444e-05,  1.6689e-06,  ..., -1.1683e-05,\n",
              "           8.7738e-05,  3.8486e-07],\n",
              "         [ 5.9605e-08,  2.2643e-07,  6.5296e-07,  ...,  2.2650e-06,\n",
              "          -7.6294e-06,  2.3079e-04],\n",
              "         [ 1.6205e-07,  1.9073e-06,  4.7684e-07,  ..., -1.2934e-05,\n",
              "          -5.7220e-06,  6.1035e-05],\n",
              "         ...,\n",
              "         [ 6.5565e-07,  5.4836e-06, -7.1526e-06,  ..., -7.6294e-06,\n",
              "           4.9591e-05, -2.5079e-05],\n",
              "         [ 3.2783e-07, -3.8798e-05,  1.5259e-05,  ..., -1.4305e-06,\n",
              "          -7.6294e-06,  1.4773e-05],\n",
              "         [-9.6858e-08, -3.2425e-05, -1.9073e-05,  ...,  1.2719e-05,\n",
              "           4.5776e-05,  3.0518e-05]],\n",
              "\n",
              "        [[ 3.1292e-07, -9.5367e-05, -1.5259e-05,  ..., -5.4389e-07,\n",
              "           6.1035e-05,  1.9401e-07],\n",
              "         [ 4.1723e-07,  1.1694e-07,  7.7361e-06,  ...,  1.4305e-06,\n",
              "           5.3406e-05,  8.9407e-08],\n",
              "         [-1.2666e-06, -4.5776e-05,  1.5259e-05,  ...,  1.3085e-06,\n",
              "           0.0000e+00, -1.5259e-05],\n",
              "         ...,\n",
              "         [ 2.9802e-07,  1.9407e-04, -1.3351e-05,  ..., -4.2915e-06,\n",
              "          -2.1935e-05,  1.2267e-05],\n",
              "         [ 9.2387e-07, -1.0108e-04, -3.0518e-05,  ..., -6.9141e-06,\n",
              "           4.1962e-05,  5.2257e-06],\n",
              "         [-1.7881e-07, -1.9655e-05, -2.2888e-05,  ..., -4.3218e-05,\n",
              "           4.5776e-05, -5.7220e-06]]], device='cuda:0')"
            ]
          },
          "execution_count": 222,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from torch.func import jvp, grad, vjp, jacrev, jacfwd, functional_call, vmap\n",
        "from torch import vmap\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.amp import autocast\n",
        "\n",
        "n_features = 24\n",
        "\n",
        "\n",
        "import torch.profiler\n",
        "\n",
        "with torch.profiler.profile(\n",
        "    activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
        "    profile_memory=True,\n",
        "    record_shapes=True\n",
        ") as prof:\n",
        "\n",
        "    # Define the neural network\n",
        "    class SimpleNN(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(SimpleNN, self).__init__()\n",
        "            # Define two hidden layers with 12 nodes each\n",
        "            self.hidden1 = nn.Linear(n_features, 12)  # 1 input node to 12 hidden nodes\n",
        "            self.hidden2 = nn.Linear(12, 11) # 12 hidden nodes to 12 hidden nodes\n",
        "            self.output = nn.Linear(11, 24)   # 12 hidden nodes to 1 output node\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = torch.relu(self.hidden1(x))  # ReLU activation function for first layer\n",
        "            x = torch.relu(self.hidden2(x))  # ReLU activation function for second layer\n",
        "            x = self.output(x)               # Output layer without activation (regression)\n",
        "            return x\n",
        "\n",
        "    # Initialize the model\n",
        "    #model = transformer_model#\n",
        "\n",
        "\n",
        "    import torch\n",
        "\n",
        "    # Flatten model parameters into a single vector\n",
        "    def parameters_to_vector(named_parameters):\n",
        "        return torch.cat([param.view(-1) for name, param in named_parameters.items()])\n",
        "\n",
        "    # Restore parameters from a vector to the dictionary format\n",
        "    def vector_to_parameters(vector, named_parameters):\n",
        "        # Create an iterator to slice vector based on parameter shapes\n",
        "        pointer = 0\n",
        "        new_params = {}\n",
        "        for name, param in named_parameters.items():\n",
        "            numel = param.numel()  # Number of elements in this parameter\n",
        "            # Slice out `numel` elements from the vector\n",
        "            new_params[name] = vector[pointer:pointer + numel].view(param.shape)\n",
        "            pointer += numel\n",
        "        return new_params\n",
        "    \n",
        "\n",
        "\n",
        "    # Define a function with both inputs and parameters\n",
        "    def f(X, params):\n",
        "        # An example function using parameters (e.g., element-wise sine with params)\n",
        "        with torch.no_grad():\n",
        "            ans =  functional_call(model, vector_to_parameters(params, template), X)\n",
        "        #with autocast(device):\n",
        "        return ans.sum(dim=-1)\n",
        "\n",
        "\n",
        "    # Function to compute the Hessian-vector product with respect to parameters\n",
        "    def hvp_revrev(f, X, params, tangents):\n",
        "        ans = jvp(\n",
        "            lambda pp: jvp(\n",
        "                lambda p: f(X,p), (pp,), (tangents,)\n",
        "                )[1], \n",
        "                (params,), (tangents,))[1]\n",
        "        return ans.detach()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    torch.cuda.reset_max_memory_allocated()\n",
        "\n",
        "    print(torch.cuda.max_memory_allocated()/1024**3)\n",
        "    # Initialize input and parameters\n",
        "    batch_size = 64\n",
        "    n_vectors = 5\n",
        "    n_vectors_per_round=2\n",
        "    #X = torch.randn((batch_size, n_features), requires_grad=False).to(device)    # Fixed input tensor\n",
        "    #model = SimpleNN().to(device)\n",
        "\n",
        "\n",
        "    model = transformer_model.to(device)\n",
        "    X = X_transformer[:batch_size,:n_features].to(device)\n",
        "\n",
        "    template = {name: param.detach().clone() for name, param in model.named_parameters()}\n",
        "\n",
        "\n",
        "    param_dict = {name:v for name, v in model.named_parameters()}\n",
        "    param_vec = parameters_to_vector(param_dict)\n",
        "    param_dict = vector_to_parameters(param_vec, param_dict)\n",
        "\n",
        "    params = parameters_to_vector(param_dict)\n",
        "    tangent = torch.randn((n_vectors, len(params))).to(device)                    # Tangent vector for HVP\n",
        "    print(torch.cuda.max_memory_allocated()/1024**3)\n",
        "    #batched_hvp = vmap(lambda t: vmap(lambda x: jvp(lambda p: jacrev(f, argnums=1)(x,p), (params,), (t,)), chunk_size=3)(X), chunk_size=3)(tangent[:1])\n",
        "    #print(batched_hvp.shape)\n",
        "    #a = hvp_revrev(f, X[1], params, tangent[1])\n",
        "    unbatched_hvp = hvp_revrev(f, X, params, tangent[1])\n",
        "   # def compute_single_hvp(tangent):\n",
        "   #     return hvp_revrev(f, X, params, tangent)\n",
        "    #batched_hvp = vmap(lambda t: hvp_revrev(f, X, params, t), chunk_size=n_vectors_per_round, in_dims=0)(tangent)\n",
        "    print(a.shape)\n",
        "    print(torch.cuda.max_memory_allocated()/1024**3)\n",
        "batched_hvp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of active CUDA tensors: 155\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_15370/3593842136.py:6: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
            "  tensors = [obj for obj in gc.get_objects() if isinstance(obj, torch.Tensor) and obj.is_cuda]\n"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "def list_active_tensors():\n",
        "    tensors = [obj for obj in gc.get_objects() if isinstance(obj, torch.Tensor) and obj.is_cuda]\n",
        "    print(f\"Number of active CUDA tensors: {len(tensors)}\")\n",
        "\n",
        "list_active_tensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.25814247131347656\n",
            "3.144221305847168\n",
            "torch.Size([48, 24])\n"
          ]
        }
      ],
      "source": [
        "import time \n",
        "t = time.time()\n",
        "tan = tangent[1]\n",
        "\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "torch.cuda.reset_max_memory_allocated()\n",
        "X = X_transformer[:48,].to(device)\n",
        "a = jvp(\n",
        "    lambda pp: jvp(\n",
        "        lambda p: f(X,p), (pp,), (tan,)\n",
        "        )[1], \n",
        "    (params,), (tan,))[1]\n",
        "\n",
        "\n",
        "print(t-time.time())\n",
        "a.shape\n",
        "print(torch.cuda.max_memory_allocated()/1024**3)\n",
        "print(a.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([24])"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jac"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5, 2, 24])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batched_hvp[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 24, 768])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batched_hvp.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0.]]], device='cuda:0')"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batched_hvp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-50.0201, -52.5890],\n",
              "        [-51.7902, -29.2547]], device='cuda:0', grad_fn=<SumBackward1>)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jacrev(f, argnums=1)(X[1],params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([24, 3928])"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hvp_revrev(f, X[1,:], params, tangent[1]).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[139], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtransformer_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation/toy_models/transformer_wrapper.py:15\u001b[0m, in \u001b[0;36mTransformerWrapper.forward\u001b[0;34m(self, tokenized_X)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokenized_X: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Generate model outputs\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     logits: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenized_X\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Rearrange the output to a flat batch of logits\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     probs \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:1030\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     position_ids \u001b[38;5;241m=\u001b[39m position_ids\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1030\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwte\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1031\u001b[0m position_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwpe(position_ids)\n\u001b[1;32m   1032\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m position_embeds\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/nn/modules/sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/nn/functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)"
          ]
        }
      ],
      "source": [
        "transformer_model(X[1,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9.61838150024414\n",
            "9.67314338684082\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "torch.cuda.reset_max_memory_allocated()\n",
        "print(torch.cuda.max_memory_allocated()/1024**3)\n",
        "jacrev(f, argnums=1)(X[1],params)\n",
        "#X = X_transformer[:24,].to(device)\n",
        "#transformer_model.to(device)(X.to(device))\n",
        "print(torch.cuda.max_memory_allocated()/1024**3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hidden1.weight True\n",
            "hidden1.bias True\n",
            "hidden2.weight True\n",
            "hidden2.bias True\n",
            "output.weight True\n",
            "output.bias True\n"
          ]
        }
      ],
      "source": [
        "for n, p in model.named_parameters():\n",
        "    print(n,p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([48, 9880])\n",
            "torch.Size([9880])\n",
            "torch.Size([48, 64])\n"
          ]
        }
      ],
      "source": [
        "print(tangent.shape)\n",
        "print(params.shape)\n",
        "print(X.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.func import jvp\n",
        "x = torch.randn([])\n",
        "f = lambda x: x * torch.tensor([1., 2., 3])\n",
        "value, grad = jvp(f, (x,), (torch.tensor(1.),))\n",
        "assert torch.allclose(value, f(x))\n",
        "assert torch.allclose(grad, torch.tensor([1., 2, 3]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "_vjp_with_argnums.<locals>.wrapper() takes from 1 to 3 positional arguments but 2048 were given",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[97], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m tangent_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(num_tangents, batch_size)      \u001b[38;5;66;03m# Tangents for each parameter\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Vectorize HVP computation over tangent vectors using vmap\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m batched_hvp \u001b[38;5;241m=\u001b[39m \u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mhvp_revrev\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtangent_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(batched_hvp)\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/apis.py:203\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/vmap.py:331\u001b[0m, in \u001b[0;36mvmap_impl\u001b[0;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(\n\u001b[1;32m    321\u001b[0m         func,\n\u001b[1;32m    322\u001b[0m         flat_in_dims,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    328\u001b[0m     )\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/vmap.py:479\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[0;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[1;32m    476\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(\n\u001b[1;32m    477\u001b[0m         flat_in_dims, flat_args, vmap_level, args_spec\n\u001b[1;32m    478\u001b[0m     )\n\u001b[0;32m--> 479\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
            "Cell \u001b[0;32mIn[97], line 25\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     22\u001b[0m tangent_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(num_tangents, batch_size)      \u001b[38;5;66;03m# Tangents for each parameter\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Vectorize HVP computation over tangent vectors using vmap\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m batched_hvp \u001b[38;5;241m=\u001b[39m vmap(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mhvp_revrev\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m)(tangent_batch)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(batched_hvp)\n",
            "Cell \u001b[0;32mIn[97], line 15\u001b[0m, in \u001b[0;36mhvp_revrev\u001b[0;34m(f, X, params, tangents)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Calculate the vector-Jacobian product to get the HVP\u001b[39;00m\n\u001b[1;32m     14\u001b[0m _, vjp_fn \u001b[38;5;241m=\u001b[39m vjp(\u001b[38;5;28;01mlambda\u001b[39;00m p: f(X, p), params)\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvjp_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtangents\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mTypeError\u001b[0m: _vjp_with_argnums.<locals>.wrapper() takes from 1 to 3 positional arguments but 2048 were given"
          ]
        }
      ],
      "source": [
        "#from functorch import jvp, grad, vjp\n",
        "from torch.func import jvp, grad, vjp, vmap\n",
        "def hvp(f, primals, tangents):\n",
        "  return jvp(grad(f), primals, tangents)[1]\n",
        "\n",
        "def f(x):\n",
        "  return x.sin().sum()\n",
        "\n",
        "x = torch.randn(2048)\n",
        "tangent = torch.randn(2048)\n",
        "\n",
        "result = hvp(f, (x,), (tangent,))\n",
        "\n",
        "def hvp_revrev(f, primals, tangents):\n",
        "    \n",
        "  _, vjp_fn = vjp(grad(f), *primals)\n",
        "  return vjp_fn(*tangents)\n",
        "\n",
        "result_hvp_revrev = hvp_revrev(f, (x,), (tangent,))\n",
        "print(result_hvp_revrev.shape[0])\n",
        "assert torch.allclose(result, result_hvp_revrev[0])\n",
        "result_hvp_revrev\n",
        "\n",
        "\n",
        "# Create batch of inputs and tangents\n",
        "batch_size = 2048\n",
        "x_batch = torch.randn((10,batch_size), requires_grad=True)\n",
        "\n",
        "tangent_batch = torch.randn((2,batch_size))\n",
        "\n",
        "\n",
        "#batched_hvp = vmap(lambda x: vmap(lambda t: hvp_revrev(f, (x,), (t,)))(tangent_batch))(x_batch)\n",
        "\n",
        "#print(batched_hvp[0].shape)\n",
        "#print(len(batched_hvp))\n",
        "#batched_hvp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function torch.func.vmap(func: Callable, in_dims: Union[int, Tuple] = 0, out_dims: Union[int, Tuple[int, ...]] = 0, randomness: str = 'error', *, chunk_size=None) -> Callable>"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "You are attempting to call Tensor.requires_grad_() (or perhaps using torch.autograd.functional.* APIs) inside of a function being transformed by a functorch transform. This is unsupported, please attempt to use the functorch transforms (e.g. grad, vjp, jacrev, jacfwd, hessian) or call requires_grad_() outside of a function being transformed instead.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[49], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m U \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([param\u001b[38;5;241m.\u001b[39mview(k_vectors, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m eigenmodel_transformer\u001b[38;5;241m.\u001b[39m_parameters\u001b[38;5;241m.\u001b[39mvalues()], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Compute HVPs\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m HVPs \u001b[38;5;241m=\u001b[39m \u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhvp_func\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mU\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# HVPs is of shape (k_vectors, n_params)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHessian-Matrix Product H @ U:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/apis.py:203\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/vmap.py:331\u001b[0m, in \u001b[0;36mvmap_impl\u001b[0;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(\n\u001b[1;32m    321\u001b[0m         func,\n\u001b[1;32m    322\u001b[0m         flat_in_dims,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    328\u001b[0m     )\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/vmap.py:479\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[0;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[1;32m    476\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(\n\u001b[1;32m    477\u001b[0m         flat_in_dims, flat_args, vmap_level, args_spec\n\u001b[1;32m    478\u001b[0m     )\n\u001b[0;32m--> 479\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
            "Cell \u001b[0;32mIn[49], line 28\u001b[0m, in \u001b[0;36mhvp_func\u001b[0;34m(u_i)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhvp_func\u001b[39m(u_i):\n\u001b[0;32m---> 28\u001b[0m     hvp \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhvp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu_i\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hvp\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/autograd/functional.py:1137\u001b[0m, in \u001b[0;36mhvp\u001b[0;34m(func, inputs, v, create_graph, strict)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[1;32m   1136\u001b[0m     is_inputs_tuple, inputs \u001b[38;5;241m=\u001b[39m _as_tuple(inputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhvp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1137\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43m_grad_preprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1140\u001b[0m         _, v \u001b[38;5;241m=\u001b[39m _as_tuple(v, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhvp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/autograd/functional.py:88\u001b[0m, in \u001b[0;36m_grad_preprocess\u001b[0;34m(inputs, create_graph, need_graph)\u001b[0m\n\u001b[1;32m     86\u001b[0m             res\u001b[38;5;241m.\u001b[39mappend(inp\u001b[38;5;241m.\u001b[39mclone())\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m         res\u001b[38;5;241m.\u001b[39mappend(\u001b[43minp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequires_grad_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneed_graph\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(res)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: You are attempting to call Tensor.requires_grad_() (or perhaps using torch.autograd.functional.* APIs) inside of a function being transformed by a functorch transform. This is unsupported, please attempt to use the functorch transforms (e.g. grad, vjp, jacrev, jacfwd, hessian) or call requires_grad_() outside of a function being transformed instead."
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
        "from torch.func import vmap\n",
        "\n",
        "# Assume model, x, targets, and loss_fn are defined\n",
        "# model = ...\n",
        "# x = ...\n",
        "# targets = ...\n",
        "# loss_fn = ...\n",
        "\n",
        "def get_flat_params(model):\n",
        "    return parameters_to_vector(model.parameters())\n",
        "\n",
        "def set_flat_params(model, flat_params):\n",
        "    vector_to_parameters(flat_params, model.parameters())\n",
        "\n",
        "# Get flat parameters w0\n",
        "w0 = get_flat_params(model).detach()\n",
        "w0.requires_grad_(True)\n",
        "\n",
        "def f(w):\n",
        "    set_flat_params(model, w)\n",
        "    outputs = model(x)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "    return loss\n",
        "\n",
        "def hvp_func(u_i):\n",
        "    hvp = torch.autograd.functional.hvp(f, w0, u_i)[1]\n",
        "    return hvp\n",
        "\n",
        "# Prepare U tensor\n",
        "k_vectors = eigenmodel_transformer.n_u_vectors  # Number of u vectors\n",
        "n_params = w0.numel()               # Number of parameters\n",
        "# Assuming eigenmodel._parameters contains the u vectors\n",
        "U = torch.cat([param.view(k_vectors, -1) for param in eigenmodel_transformer._parameters.values()], dim=1)\n",
        "\n",
        "# Compute HVPs\n",
        "hvp_func(U)\n",
        "#HVPs = vmap(hvp_func)(U)\n",
        "\n",
        "# HVPs is of shape (k_vectors, n_params)\n",
        "#print(\"Hessian-Matrix Product H @ U:\")\n",
        "#print(HVPs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title Import pretrained gpt2 (2 layers)\n",
        "# Disable fused kernels (FlashAttention and memory-efficient attention)\n",
        "# We have to disable this to compute second-order gradients on transformer models.\n",
        "torch.backends.cuda.enable_flash_sdp(False)\n",
        "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
        "\n",
        "# Ensure the math kernel is enabled (it is True by default)\n",
        "torch.backends.cuda.enable_math_sdp(True)\n",
        "\n",
        "# Load in a 2-L GPT2.\n",
        "config = GPT2Config.from_pretrained('gpt2', n_layer=2)\n",
        "gpt2 = GPT2Model.from_pretrained('gpt2', config=config)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\",)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "transformer_model = TransformerWrapper(gpt2, tokenizer)\n",
        "\n",
        "# Make the eigenestimation a little smaller but only looking at a subset of the parameters.\n",
        "# Pick a random subset of tensors to include in paramters, and turn the rest into frozen buffers.\n",
        "params_to_delete = [name for name, param in transformer_model.named_parameters()]\n",
        "params_to_delete = [p for p in params_to_delete if p!='transformer.h.1.ln_1.weight']\n",
        "\n",
        "# Delete 3/4 of the parameters.\n",
        "#for p in (params_to_delete[::20]):\n",
        "#  params_to_delete.remove(p)\n",
        "\n",
        "DeleteParams(transformer_model, params_to_delete)\n",
        "\n",
        "print(sum([p.numel() for p in transformer_model.parameters()]))\n",
        "for n,_ in transformer_model.named_parameters(): print(n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.func import functional_call, vmap, grad\n",
        "\n",
        "def compute_loss(params, buffers, sample, target):\n",
        "    batch = sample.unsqueeze(0)\n",
        "    targets = target.unsqueeze(0)\n",
        "    loss = eigenmodel_transformer.compute_loss()\n",
        "    predictions = functional_call(model, (params, buffers), (batch,))\n",
        "    loss = loss_fn(predictions, targets)\n",
        "    return loss\n",
        "\n",
        "params = {k: v.detach() for k, v in model.named_parameters()}\n",
        "buffers = {k: v.detach() for k, v in model.named_buffers()}\n",
        "\n",
        "ft_compute_grad = grad(compute_loss)\n",
        "ft_compute_sample_grad = vmap(ft_compute_grad, in_dims=(None, None, 0, 0))\n",
        "ft_per_sample_grads = ft_compute_sample_grad(params, buffers, x, y)\n",
        "\n",
        "print(ft_per_sample_grads)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TransformerWrapper(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-1): 2 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2SdpaAttention(\n",
              "          (c_attn): Conv1D(nf=2304, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=768)\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D(nf=3072, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=3072)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 247,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformer_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/cuda/memory.py:365: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from torch import autograd\n",
        "import time\n",
        "#model = nn.Linear(10, 20)\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "torch.cuda.reset_max_memory_allocated()\n",
        "\n",
        "\n",
        "# Run your code\n",
        "\n",
        "#x = torch.randn(8, 10) # 10 elements long\n",
        "\n",
        "model = transformer_model\n",
        "t  = time.time()\n",
        "k = 2\n",
        "vecs = tuple([einops.repeat(torch.randn_like(p, requires_grad=True), '...->k ...', k=k) for p in model.parameters()])\n",
        "\n",
        "\n",
        "batch_size=10\n",
        "vec = tuple(k[0] for k in vecs)\n",
        "\n",
        "# X\n",
        "grad_batch_size = 20\n",
        "x = X_transformer[:grad_batch_size,:]\n",
        "out_model = model(x.to(device))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.func import jvp, grad, vjp\n",
        "\n",
        "# Define a function with both inputs and parameters\n",
        "def f(X, params):\n",
        "    # An example function using parameters (e.g., element-wise sine with params)\n",
        "    return (X * params).sin().sum()\n",
        "\n",
        "# Function to compute the Hessian-vector product with respect to parameters\n",
        "def hvp_revrev(f, X, params, tangents):\n",
        "    # Compute the gradient of `f` with respect to `params`\n",
        "    grad_f = grad(lambda p: f(X, p))(params)\n",
        "    \n",
        "    # Compute the vector-Jacobian product (vjp) of this gradient with respect to `params`\n",
        "    _, vjp_fn = vjp(lambda p: grad(lambda p_: f(X, p_))(p), params)\n",
        "    \n",
        "    # Apply vjp_fn to compute the Hessian-vector product\n",
        "    return vjp_fn(tangents)\n",
        "\n",
        "# Initialize input and parameters\n",
        "batch_size = 2048\n",
        "X = torch.randn((batch_size, 100), requires_grad=False)    # Fixed input tensor\n",
        "params = torch.randn(100, requires_grad=True) # Parameters to differentiate\n",
        "tangent = torch.randn((batch_size, 100))                    # Tangent vector for HVP\n",
        "\n",
        "# Compute the Hessian-vector product with respect to params\n",
        "#result_hvp = hvp_revrev(f, X[1:,], params, tangent[1,:])\n",
        "\n",
        "torch.cuda.reset_max_memory_allocated()\n",
        "batched_hvp = vmap(lambda x: vmap(lambda t: hvp_revrev(f, x, params, t))(tangent))(X)\n",
        "\n",
        "print(batched_hvp[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "torch.cuda.reset_max_memory_allocated()\n",
        "print(torch.cuda.reset_max_memory_allocated()/1024**3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/cuda/memory.py:365: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "got 24 tensors and 2 gradients",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[46], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m t  \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     17\u001b[0m vecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([einops\u001b[38;5;241m.\u001b[39mrepeat(torch\u001b[38;5;241m.\u001b[39mrandn_like(p, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...->k ...\u001b[39m\u001b[38;5;124m'\u001b[39m, k\u001b[38;5;241m=\u001b[39mk) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters()])\n\u001b[0;32m---> 18\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 160 x 20 x 10 - (batch x outputs) x (params)\u001b[39;00m\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/autograd/__init__.py:492\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(gO):\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _engine_run_backward(\n\u001b[1;32m    483\u001b[0m             outputs,\n\u001b[1;32m    484\u001b[0m             gO,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    489\u001b[0m             accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    490\u001b[0m         )\n\u001b[0;32m--> 492\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_vmap_internals\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvjp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_none_pass_through\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m     result \u001b[38;5;241m=\u001b[39m _engine_run_backward(\n\u001b[1;32m    497\u001b[0m         outputs,\n\u001b[1;32m    498\u001b[0m         grad_outputs_,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    503\u001b[0m         accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    504\u001b[0m     )\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_vmap_internals.py:231\u001b[0m, in \u001b[0;36m_vmap.<locals>.wrapped\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    228\u001b[0m     batched_inputs, batch_size \u001b[38;5;241m=\u001b[39m _create_batched_inputs(\n\u001b[1;32m    229\u001b[0m         in_dims, args, vmap_level, func\n\u001b[1;32m    230\u001b[0m     )\n\u001b[0;32m--> 231\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_none_pass_through:\n\u001b[1;32m    233\u001b[0m         _validate_outputs(batched_outputs, func)\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/autograd/__init__.py:482\u001b[0m, in \u001b[0;36mgrad.<locals>.vjp\u001b[0;34m(gO)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(gO):\n\u001b[0;32m--> 482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgO\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[0;31mRuntimeError\u001b[0m: got 24 tensors and 2 gradients"
          ]
        }
      ],
      "source": [
        "from torch import autograd\n",
        "import time\n",
        "#model = nn.Linear(10, 20)\n",
        "\n",
        "\n",
        "torch.cuda.reset_max_memory_allocated()\n",
        "gc.collect()\n",
        "# Run your code\n",
        "\n",
        "#x = torch.randn(8, 10) # 10 elements long\n",
        "\n",
        "model = transformer_model\n",
        "#x = X_transformer[[1],:4]\n",
        "x.requires_grad=False\n",
        "\n",
        "t  = time.time()\n",
        "vecs = tuple([einops.repeat(torch.randn_like(p, requires_grad=True), '...->k ...', k=k) for p in model.parameters()])\n",
        "grads = autograd.grad(outputs=outputs, inputs=model.parameters(), create_graph=True, grad_outputs = [i for i in torch.eye(len(outputs))][:2], is_grads_batched=True) # 160 x 20 x 10 - (batch x outputs) x (params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 160 x 20 x 10 - (batch x outputs) x (params)\u001b[39;00m\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/autograd/__init__.py:492\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(gO):\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _engine_run_backward(\n\u001b[1;32m    483\u001b[0m             outputs,\n\u001b[1;32m    484\u001b[0m             gO,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    489\u001b[0m             accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    490\u001b[0m         )\n\u001b[0;32m--> 492\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_vmap_internals\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvjp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_none_pass_through\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m     result \u001b[38;5;241m=\u001b[39m _engine_run_backward(\n\u001b[1;32m    497\u001b[0m         outputs,\n\u001b[1;32m    498\u001b[0m         grad_outputs_,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    503\u001b[0m         accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    504\u001b[0m     )\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_vmap_internals.py:231\u001b[0m, in \u001b[0;36m_vmap.<locals>.wrapped\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    228\u001b[0m     batched_inputs, batch_size \u001b[38;5;241m=\u001b[39m _create_batched_inputs(\n\u001b[1;32m    229\u001b[0m         in_dims, args, vmap_level, func\n\u001b[1;32m    230\u001b[0m     )\n\u001b[0;32m--> 231\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_none_pass_through:\n\u001b[1;32m    233\u001b[0m         _validate_outputs(batched_outputs, func)\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/autograd/__init__.py:482\u001b[0m, in \u001b[0;36mgrad.<locals>.vjp\u001b[0;34m(gO)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(gO):\n\u001b[0;32m--> 482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgO\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
          ]
        }
      ],
      "source": [
        "grads = autograd.grad(outputs=outputs, inputs=model.parameters(), create_graph=True, grad_outputs = [i for i in torch.eye(len(outputs))], is_grads_batched=True) # 160 x 20 x 10 - (batch x outputs) x (params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'),)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.010288476943969727 timex!\n",
            "0.010380983352661133 timey!\n",
            "0.01228642463684082 time1!\n",
            "0.012312173843383789 time2!!\n",
            "1 torch.Size([24, 768]) grads2\n",
            "1 torch.Size([24]) grads2_v\n",
            "0.015348434448242188 timex!\n",
            "0.015373945236206055 timey!\n",
            "0.016979694366455078 time1!\n",
            "0.017002582550048828 time2!!\n",
            "1 torch.Size([24, 768]) grads2\n",
            "1 torch.Size([24]) grads2_v\n",
            "0.019487380981445312 timex!\n",
            "0.019510984420776367 timey!\n",
            "0.02113509178161621 time1!\n",
            "0.021158456802368164 time2!!\n",
            "1 torch.Size([24, 768]) grads2\n",
            "1 torch.Size([24]) grads2_v\n",
            "0.0236208438873291 timex!\n",
            "0.023643970489501953 timey!\n",
            "0.02518177032470703 time1!\n",
            "0.025208234786987305 time2!!\n",
            "1 torch.Size([24, 768]) grads2\n",
            "1 torch.Size([24]) grads2_v\n",
            "0.027808189392089844 timex!\n",
            "0.02783203125 timey!\n",
            "0.029371261596679688 time1!\n",
            "0.029393911361694336 time2!!\n",
            "1 torch.Size([24, 768]) grads2\n",
            "1 torch.Size([24]) grads2_v\n",
            "0.03181171417236328 timex!\n",
            "0.031835317611694336 timey!\n",
            "0.03336381912231445 time1!\n",
            "0.033431291580200195 time2!!\n",
            "1 torch.Size([24, 768]) grads2\n",
            "1 torch.Size([24]) grads2_v\n",
            "0.0358126163482666 timex!\n",
            "0.035836219787597656 timey!\n",
            "0.03736567497253418 time1!\n",
            "0.03738808631896973 time2!!\n",
            "1 torch.Size([24, 768]) grads2\n",
            "1 torch.Size([24]) grads2_v\n",
            "0.03983187675476074 timex!\n",
            "0.039855241775512695 timey!\n",
            "0.04137468338012695 time1!\n",
            "0.0413968563079834 time2!!\n",
            "1 torch.Size([24, 768]) grads2\n",
            "1 torch.Size([24]) grads2_v\n",
            "0.043810367584228516 timex!\n",
            "0.04383397102355957 timey!\n",
            "0.045363664627075195 time1!\n",
            "0.04542708396911621 time2!!\n",
            "1 torch.Size([24, 768]) grads2\n",
            "1 torch.Size([24]) grads2_v\n",
            "0.04782748222351074 timex!\n",
            "0.0478520393371582 timey!\n",
            "0.049365997314453125 time1!\n",
            "0.04938793182373047 time2!!\n",
            "1 torch.Size([24, 768]) grads2\n",
            "1 torch.Size([24]) grads2_v\n",
            "0.31429481506347656 memory\n",
            "0.04986381530761719 time!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/cuda/memory.py:365: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from torch import autograd\n",
        "import time\n",
        "#model = nn.Linear(10, 20)\n",
        "\n",
        "\n",
        "torch.cuda.reset_max_memory_allocated()\n",
        "gc.collect()\n",
        "# Run your code\n",
        "\n",
        "#x = torch.randn(8, 10) # 10 elements long\n",
        "\n",
        "model = transformer_model\n",
        "#x = X_transformer[[1],:4]\n",
        "x.requires_grad=False\n",
        "\n",
        "t  = time.time()\n",
        "vecs = tuple([einops.repeat(torch.randn_like(p, requires_grad=True), '...->k ...', k=k) for p in model.parameters()])\n",
        "grads = autograd.grad(outputs=outputs, inputs=model.parameters(), create_graph=True, grad_outputs = [i for i in torch.eye(len(outputs))], is_grads_batched=True) # 160 x 20 x 10 - (batch x outputs) x (params)\n",
        "\n",
        "x = X_transformer[1,:]\n",
        "vec = tuple(k[0] for k in vecs)\n",
        "for _ in range(10):\n",
        "\n",
        "    out_model = model(x.to(device))\n",
        "    loss = nn.MSELoss(reduction='none')(out_model, out_model.detach()).mean(dim=-1)\n",
        "\n",
        "    dims = ' '.join([f'd{i}' for i in range(len(loss.shape))])\n",
        "\n",
        "    out = loss.flatten()#einops.rearrange(loss, f'{dims} -> ({dims})') # Flatten.\n",
        "    outputs = [i for i in out]\n",
        "    print(time.time()-t, 'timex!')\n",
        "\n",
        "    print(time.time()-t, 'timey!')\n",
        "\n",
        "    #print(len(grads), grads[0].shape, 'grads')\n",
        "    #print(time.time()-t, 'time0!')\n",
        "\n",
        "    p=sum([einops.einsum(g, v, 'o ... , ... -> o') for g,v in zip(grads, vec)]) # (batch x outputs) x k.\n",
        "    #print(p.shape, 'p')\n",
        "\n",
        "    p_dims = ' '\n",
        "    p_reshape = [i for i in einops.rearrange(p, 'o->(o)')] # (batch k)\n",
        "    #print(len(p_reshape))\n",
        "    grads2 = autograd.grad(p_reshape, vec, create_graph=True, grad_outputs = [i for i in torch.eye(len(p_reshape))], is_grads_batched=True) # for each grad - (batch x outputs x k) x (params)\n",
        "    print(time.time()-t, 'time1!')\n",
        "    #grads2 = autograd.grad(p_reshape, vecs, create_graph=True, grad_outputs = [i for i in torch.eye(len(p_reshape))], is_grads_batched=True) # for each grad - (batch x outputs x k) x (params)\n",
        "    print(time.time()-t, 'time2!!')\n",
        "    print(len(grads2), grads2[0].shape, 'grads2')\n",
        "\n",
        "    #dims_grad2 =  [' '.join([f'd{i}' for idd in range(len(g.shape[1:]))]) for g in grads2]\n",
        "    #grads2_v = tuple((g**2).sum(dim=-1) for g in grads2)\n",
        "    grads2_v = tuple((g**2).sum(dim=-1) for g in grads2)\n",
        "    #print(time.time()-t, 'time3!!')\n",
        "\n",
        "    print(len(grads2_v), grads2_v[0].shape, 'grads2_v')\n",
        "\n",
        "    #grads2_v = sum([einops.einsum(g,v, 'batch outputs k ... , k ... -> batch outputs k') for g,v,d in zip(grads2_rearranged, vecs, dims)])\n",
        "\n",
        "\n",
        "    peak_memory = torch.cuda.max_memory_allocated() / (1024**3)\n",
        "    \n",
        "\n",
        "print(peak_memory, 'memory')    \n",
        "print(time.time()-t, 'time!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/cuda/memory.py:365: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out_model.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([480, 768])"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grads[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 5            |        cudaMalloc retries: 5         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |  19690 MiB |  19840 MiB |   1001 GiB |    982 GiB |\n",
            "|       from large pool |  19669 MiB |  19818 MiB |    936 GiB |    916 GiB |\n",
            "|       from small pool |     21 MiB |     81 MiB |     65 GiB |     65 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |  19690 MiB |  19840 MiB |   1001 GiB |    982 GiB |\n",
            "|       from large pool |  19669 MiB |  19818 MiB |    936 GiB |    916 GiB |\n",
            "|       from small pool |     21 MiB |     81 MiB |     65 GiB |     65 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Requested memory      |  19674 MiB |  19824 MiB |    999 GiB |    980 GiB |\n",
            "|       from large pool |  19653 MiB |  19803 MiB |    934 GiB |    915 GiB |\n",
            "|       from small pool |     21 MiB |     81 MiB |     65 GiB |     65 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |  24722 MiB |  24722 MiB | 230422 MiB | 205700 MiB |\n",
            "|       from large pool |  24624 MiB |  24624 MiB | 224238 MiB | 199614 MiB |\n",
            "|       from small pool |     98 MiB |     98 MiB |   6184 MiB |   6086 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |   4961 MiB |   5301 MiB | 481461 MiB | 476500 MiB |\n",
            "|       from large pool |   4954 MiB |   5291 MiB | 384885 MiB | 379930 MiB |\n",
            "|       from small pool |      6 MiB |     18 MiB |  96576 MiB |  96570 MiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     224    |     297    |  205042    |  204818    |\n",
            "|       from large pool |     103    |     106    |   39128    |   39025    |\n",
            "|       from small pool |     121    |     194    |  165914    |  165793    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     224    |     297    |  205042    |  204818    |\n",
            "|       from large pool |     103    |     106    |   39128    |   39025    |\n",
            "|       from small pool |     121    |     194    |  165914    |  165793    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      79    |      79    |    3706    |    3627    |\n",
            "|       from large pool |      30    |      30    |     614    |     584    |\n",
            "|       from small pool |      49    |      49    |    3092    |    3043    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      63    |      99    |  107707    |  107644    |\n",
            "|       from large pool |      36    |      39    |    7218    |    7182    |\n",
            "|       from small pool |      27    |      62    |  100489    |  100462    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.memory_summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'jedi.inference.base_value.ValueSet'> S{}\n",
            "deleted\n",
            "<class 'unittest.mock._Call'> call.size()\n",
            "deleted\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_3489/2896909092.py:6: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
            "  if obj.is_cuda:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'> torch.Size([1024, 1024])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([1024, 1024])\n",
            "deleted\n",
            "<class 'torch.storage.UntypedStorage'> 154389504\n",
            "<class 'torch.storage.UntypedStorage'> 3145728\n",
            "<class 'torch.storage.UntypedStorage'> 3072\n",
            "<class 'torch.storage.UntypedStorage'> 3072\n",
            "<class 'torch.storage.UntypedStorage'> 7077888\n",
            "<class 'torch.storage.UntypedStorage'> 9216\n",
            "<class 'torch.storage.UntypedStorage'> 2359296\n",
            "<class 'torch.storage.UntypedStorage'> 3072\n",
            "<class 'torch.storage.UntypedStorage'> 3072\n",
            "<class 'torch.storage.UntypedStorage'> 3072\n",
            "<class 'torch.storage.UntypedStorage'> 9437184\n",
            "<class 'torch.storage.UntypedStorage'> 12288\n",
            "<class 'torch.storage.UntypedStorage'> 9437184\n",
            "<class 'torch.storage.UntypedStorage'> 3072\n",
            "<class 'torch.storage.UntypedStorage'> 3072\n",
            "<class 'torch.storage.UntypedStorage'> 3072\n",
            "<class 'torch.storage.UntypedStorage'> 7077888\n",
            "<class 'torch.storage.UntypedStorage'> 9216\n",
            "<class 'torch.storage.UntypedStorage'> 2359296\n",
            "<class 'torch.storage.UntypedStorage'> 3072\n",
            "<class 'torch.storage.UntypedStorage'> 3072\n",
            "<class 'torch.storage.UntypedStorage'> 3072\n",
            "<class 'torch.storage.UntypedStorage'> 9437184\n",
            "<class 'torch.storage.UntypedStorage'> 12288\n",
            "<class 'torch.storage.UntypedStorage'> 9437184\n",
            "<class 'torch.storage.UntypedStorage'> 3072\n",
            "<class 'torch.storage.UntypedStorage'> 3072\n",
            "<class 'torch.storage.UntypedStorage'> 3072\n",
            "<class 'torch.Tensor'> torch.Size([1, 1, 1024, 1024])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([1, 1, 1024, 1024])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([15153, 24])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([50257, 768])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024, 768])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 2304])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([2304])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 2304])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([2304])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([100, 4])\n",
            "deleted\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([10, 768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([5])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([3, 5])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([3, 5])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([5])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([3, 5])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([5])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([5])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([5])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([3, 5])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([5])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([5])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([5])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([3, 5])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([3])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([10, 24, 768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([10, 24, 768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([240, 3072])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([10, 24, 3072])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([10, 24, 3072])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([10, 24, 3072])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([10, 24, 768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([10, 24, 768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([10, 24, 768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([240, 768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([20, 24, 768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([20, 24, 768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([480, 3072])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([20, 24, 3072])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([20, 24, 3072])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([20, 24, 3072])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([20, 24, 768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([20, 24, 768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([20, 24, 768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([480, 768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([3, 24, 768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([3, 24, 768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([72, 3072])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([3, 24, 3072])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([3, 24, 3072])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([3, 24, 3072])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([3, 24, 768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([3, 24, 768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([3, 24, 768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([72])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([72, 2, 768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([72, 2])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([3, 24])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([3, 24, 768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([3, 24, 768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([72, 3072])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([3, 24, 3072])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([3, 24, 3072])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([3, 24, 3072])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([3, 24, 768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([3, 24, 768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([3, 24, 768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([3, 24])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([72])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([2, 768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([768])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "deleted\n",
            "<class 'torch.Tensor'> torch.Size([72, 768])\n",
            "deleted\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# prints currently alive Tensors and Variables\n",
        "import torch\n",
        "import gc\n",
        "for obj in gc.get_objects():\n",
        "    try:\n",
        "        if obj.is_cuda:\n",
        "                print(type(obj), obj.size())\n",
        "        \n",
        "                obj.detach().cpu()\n",
        "                del obj\n",
        "                print('deleted')\n",
        "                \n",
        "    except:\n",
        "        pass\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'torch' has no attribute 'is_cuda'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[112], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_cuda\u001b[49m(obj)\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/__init__.py:2563\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m   2560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _lazy_modules:\n\u001b[1;32m   2561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m-> 2563\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'is_cuda'"
          ]
        }
      ],
      "source": [
        "torch.is_cuda(obj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/cuda/memory.py:365: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "8101683200"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.reset_peak_memory_stats()\n",
        "i = 0\n",
        "torch.cuda.max_memory_allocated()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "    grads2 = autograd.grad(p_reshape, vecs, create_graph=True, grad_outputs = [i for i in torch.eye(len(p_reshape))], is_grads_batched=True) # for each grad - (batch x outputs x k) x (params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "grad_and_value(f)(*args): Expected f(*args) to return a scalar Tensor, got tensor with 1 dims. Maybe you wanted to use the vjp or jacrev APIs instead?",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[37], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m targets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(batch_size)\n\u001b[1;32m     18\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (weights, examples, targets)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#grad_weight_per_example = vmap(grad(compute_grad, argnums=0), in_dims=(None, 0, 0))(*inputs)\u001b[39;00m\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/apis.py:399\u001b[0m, in \u001b[0;36mgrad.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43meager_transforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/eager_transforms.py:1449\u001b[0m, in \u001b[0;36mgrad_impl\u001b[0;34m(func, argnums, has_aux, args, kwargs)\u001b[0m\n\u001b[1;32m   1448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrad_impl\u001b[39m(func: Callable, argnums: argnums_t, has_aux: \u001b[38;5;28mbool\u001b[39m, args, kwargs):\n\u001b[0;32m-> 1449\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_and_value_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1450\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m   1451\u001b[0m         grad, (_, aux) \u001b[38;5;241m=\u001b[39m results\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/vmap.py:48\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 48\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/eager_transforms.py:1422\u001b[0m, in \u001b[0;36mgrad_and_value_impl\u001b[0;34m(func, argnums, has_aux, args, kwargs)\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1418\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_and_value(f)(*args): Expected f(*args) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1419\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto return a Tensor, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(output)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1420\u001b[0m     )\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1422\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1423\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_and_value(f)(*args): Expected f(*args) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1424\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto return a scalar Tensor, got tensor with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1425\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dims. Maybe you wanted to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1426\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse the vjp or jacrev APIs instead?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1427\u001b[0m     )\n\u001b[1;32m   1429\u001b[0m flat_diff_args, spec \u001b[38;5;241m=\u001b[39m tree_flatten(diff_args)\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;66;03m# NB: need create_graph so that backward pass isn't run in no_grad mode\u001b[39;00m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: grad_and_value(f)(*args): Expected f(*args) to return a scalar Tensor, got tensor with 1 dims. Maybe you wanted to use the vjp or jacrev APIs instead?"
          ]
        }
      ],
      "source": [
        "from torch.func import grad, vmap\n",
        "batch_size, feature_size = 3, 5\n",
        "def model(weights, feature_vec):\n",
        "    # Very simple linear model with activation\n",
        "    assert feature_vec.dim() == 1\n",
        "    return feature_vec.dot(weights).relu()\n",
        "def compute_loss(weights, example, target):\n",
        "    y = model(weights, example)\n",
        "    return ((y - target) ** 2).mean()  # MSELoss\n",
        "\n",
        "def compute_grad(weights, example, target):\n",
        "    return jvp(compute_loss, argnums=0)(weights, example, target)\n",
        "\n",
        "\n",
        "weights = torch.randn(feature_size, requires_grad=True)\n",
        "examples = torch.randn(batch_size, feature_size)\n",
        "targets = torch.randn(batch_size)\n",
        "inputs = (weights, examples, targets)\n",
        "grad(compute_grad, argnums=0)(weights, examples[0], targets[0])\n",
        "#grad_weight_per_example = vmap(grad(compute_grad, argnums=0), in_dims=(None, 0, 0))(*inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 345,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 768])"
            ]
          },
          "execution_count": 345,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out_model.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 24])"
            ]
          },
          "execution_count": 316,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 314,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 torch.Size([240, 768]) grads\n"
          ]
        }
      ],
      "source": [
        "print(len(grads), grads[0].shape, 'grads')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'(b o k d0 d1) -> b o k d0 d1'"
            ]
          },
          "execution_count": 210,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " f'(b o k {dims}) -> b o k {dims}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([7, 20, 10])"
            ]
          },
          "execution_count": 196,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vecs[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'p' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[32], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m v \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn([\u001b[38;5;241m10\u001b[39m, flat_params\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]], requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#p=einops.einsum('(out @ v)\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241m.\u001b[39mbackward(create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(v\u001b[38;5;241m.\u001b[39mgrad)\n\u001b[1;32m     17\u001b[0m linear\u001b[38;5;241m.\u001b[39mzero_grad()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'p' is not defined"
          ]
        }
      ],
      "source": [
        "from torch import autograd\n",
        "linear = nn.Linear(10, 20)\n",
        "\n",
        "x = torch.randn(1, 10)\n",
        "out = [i for i in (linear(x)**2)[0]]\n",
        "\n",
        "\n",
        "flat_params = torch.cat([p.view(-1) for p in linear.parameters()])# flatten.requires_grad=True\n",
        "v = torch.randn([10, flat_params.shape[0]], requires_grad=True)\n",
        "\n",
        "p=einops.einsum(out, v, )\n",
        "\n",
        "p.backward(create_graph=True)\n",
        "\n",
        "print(v.grad)\n",
        "\n",
        "linear.zero_grad()\n",
        "\n",
        "grads = autograd.grad(out, linear.parameters(), create_graph=True)\n",
        "grads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "220"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "flat_params.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor(1.0687, device='cuda:0', grad_fn=<UnbindBackward0>),\n",
              " tensor(0.1070, device='cuda:0', grad_fn=<UnbindBackward0>),\n",
              " tensor(0.8654, device='cuda:0', grad_fn=<UnbindBackward0>),\n",
              " tensor(0.0577, device='cuda:0', grad_fn=<UnbindBackward0>),\n",
              " tensor(0.0269, device='cuda:0', grad_fn=<UnbindBackward0>),\n",
              " tensor(0.0672, device='cuda:0', grad_fn=<UnbindBackward0>),\n",
              " tensor(0.0040, device='cuda:0', grad_fn=<UnbindBackward0>),\n",
              " tensor(0.1864, device='cuda:0', grad_fn=<UnbindBackward0>),\n",
              " tensor(0.0787, device='cuda:0', grad_fn=<UnbindBackward0>),\n",
              " tensor(0.8409, device='cuda:0', grad_fn=<UnbindBackward0>),\n",
              " tensor(0.0864, device='cuda:0', grad_fn=<UnbindBackward0>),\n",
              " tensor(0.0186, device='cuda:0', grad_fn=<UnbindBackward0>),\n",
              " tensor(0.0904, device='cuda:0', grad_fn=<UnbindBackward0>),\n",
              " tensor(0.0019, device='cuda:0', grad_fn=<UnbindBackward0>),\n",
              " tensor(0.0746, device='cuda:0', grad_fn=<UnbindBackward0>),\n",
              " tensor(0.3169, device='cuda:0', grad_fn=<UnbindBackward0>),\n",
              " tensor(0.1385, device='cuda:0', grad_fn=<UnbindBackward0>),\n",
              " tensor(0.0167, device='cuda:0', grad_fn=<UnbindBackward0>),\n",
              " tensor(0.4491, device='cuda:0', grad_fn=<UnbindBackward0>),\n",
              " tensor(0.0878, device='cuda:0', grad_fn=<UnbindBackward0>)]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/cuda/memory.py:365: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GradTrackingTensor(lvl=2, value=\n",
            "    BatchedTensor(lvl=1, bdim=0, value=\n",
            "        tensor([[-3.4078e-02, -2.3414e-01,  1.1105e+00,  2.0623e-01, -9.2142e-02,\n",
            "                  3.2440e-01,  2.4454e-03,  1.2116e-05,  5.1514e-02,  2.8423e-01,\n",
            "                 -3.2002e-01, -1.8888e+00, -3.6671e-11,  1.4318e+00, -1.5549e-01,\n",
            "                 -1.2171e+00,  8.1368e-03,  6.8094e+00,  7.2591e-03,  1.2072e+00,\n",
            "                  1.1051e+00,  4.1215e-02, -2.8333e-01, -1.7296e-09],\n",
            "                [ 2.5315e-02, -1.8952e-10, -9.9086e-08, -7.0067e-02,  5.0342e-04,\n",
            "                  7.4225e-04,  9.2458e-01,  5.8505e-03, -1.2408e+00, -3.8720e+00,\n",
            "                  1.2356e+01,  8.9047e-06, -7.4990e-01, -1.7808e+00,  5.2451e-02,\n",
            "                  2.3128e+00, -3.5312e-01,  1.1556e-01, -5.5430e-01,  7.9101e-01,\n",
            "                  1.8138e-01,  2.9986e-01,  1.3191e+00, -9.7872e-01],\n",
            "                [-9.1007e-02, -6.1624e-01,  2.2481e-02,  9.8138e-01, -2.8843e-02,\n",
            "                 -9.4954e-02,  1.1853e-01,  2.5127e+00,  2.3700e-01,  6.3030e-02,\n",
            "                  7.4460e-02, -5.0439e-01, -3.3080e+00,  1.6508e-01, -2.3315e-01,\n",
            "                 -6.3921e-03, -5.2783e-01,  7.3891e-02,  5.2336e-01, -8.9559e-01,\n",
            "                  3.4226e-02,  2.5009e-05,  9.9229e-01,  4.3431e-01]], device='cuda:0',\n",
            "               grad_fn=<CatBackward0>)\n",
            "    )\n",
            ")\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "grad_and_value(f)(*args): Expected f(*args) to return a scalar Tensor, got tensor with 1 dims. Maybe you wanted to use the vjp or jacrev APIs instead?",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[31], line 68\u001b[0m\n\u001b[1;32m     66\u001b[0m params \u001b[38;5;241m=\u001b[39m eigenmodel_transformer\u001b[38;5;241m.\u001b[39m_parameters\n\u001b[1;32m     67\u001b[0m w0 \u001b[38;5;241m=\u001b[39m eigenmodel_transformer\u001b[38;5;241m.\u001b[39mw0\n\u001b[0;32m---> 68\u001b[0m HVPs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhvp_inhouse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_transformer\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(peak_memory)\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/apis.py:203\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/vmap.py:331\u001b[0m, in \u001b[0;36mvmap_impl\u001b[0;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(\n\u001b[1;32m    321\u001b[0m         func,\n\u001b[1;32m    322\u001b[0m         flat_in_dims,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    328\u001b[0m     )\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/vmap.py:479\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[0;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[1;32m    476\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(\n\u001b[1;32m    477\u001b[0m         flat_in_dims, flat_args, vmap_level, args_spec\n\u001b[1;32m    478\u001b[0m     )\n\u001b[0;32m--> 479\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
            "Cell \u001b[0;32mIn[31], line 44\u001b[0m, in \u001b[0;36mhvp_inhouse\u001b[0;34m(params, X, w0)\u001b[0m\n\u001b[1;32m     25\u001b[0m u \u001b[38;5;241m=\u001b[39m {name:v[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m name, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#loss = eigenmodel_transformer.compute_loss(X, w0).sum()  # Sum over batch\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Compute gradient of loss w.r.t. parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Compute Hessian-vector product\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m hvp \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmyloss2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Flatten hvp and u vectors\u001b[39;00m\n\u001b[1;32m     47\u001b[0m hvp_flat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([h\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hvp\u001b[38;5;241m.\u001b[39mvalues()])\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/apis.py:399\u001b[0m, in \u001b[0;36mgrad.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43meager_transforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/eager_transforms.py:1449\u001b[0m, in \u001b[0;36mgrad_impl\u001b[0;34m(func, argnums, has_aux, args, kwargs)\u001b[0m\n\u001b[1;32m   1448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrad_impl\u001b[39m(func: Callable, argnums: argnums_t, has_aux: \u001b[38;5;28mbool\u001b[39m, args, kwargs):\n\u001b[0;32m-> 1449\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_and_value_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1450\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m   1451\u001b[0m         grad, (_, aux) \u001b[38;5;241m=\u001b[39m results\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/vmap.py:48\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 48\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/eager_transforms.py:1422\u001b[0m, in \u001b[0;36mgrad_and_value_impl\u001b[0;34m(func, argnums, has_aux, args, kwargs)\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1418\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_and_value(f)(*args): Expected f(*args) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1419\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto return a Tensor, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(output)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1420\u001b[0m     )\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1422\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1423\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_and_value(f)(*args): Expected f(*args) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1424\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto return a scalar Tensor, got tensor with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1425\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dims. Maybe you wanted to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1426\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse the vjp or jacrev APIs instead?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1427\u001b[0m     )\n\u001b[1;32m   1429\u001b[0m flat_diff_args, spec \u001b[38;5;241m=\u001b[39m tree_flatten(diff_args)\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;66;03m# NB: need create_graph so that backward pass isn't run in no_grad mode\u001b[39;00m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: grad_and_value(f)(*args): Expected f(*args) to return a scalar Tensor, got tensor with 1 dims. Maybe you wanted to use the vjp or jacrev APIs instead?"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "#from torch.autograd\n",
        "from torch.func import functional_call, vmap, grad\n",
        "\n",
        "def myloss(X, w0):\n",
        "    return eigenmodel_transformer.compute_loss(X, w0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def myloss2(X, w0, u):\n",
        "\n",
        "    grads = torch.func.jacrev(myloss, argnums=1)(X, w0)##torch.autograd.grad(loss, w0.values(), create_graph=True)\n",
        "    grad_u = torch.cat([einops.einsum(g,u, 'batch p, p->batch') for g, u in zip(grads.values(), u.values())])\n",
        "    # Flatten gradients and u vectors\n",
        "#    grads_flat = torch.cat([g.view(-1) for g in grads.values()])\n",
        "#    u_flat = torch.cat([u_i.view(-1) for u_i in u.values()])\n",
        "    \n",
        "    # Compute dot product\n",
        "#    grad_u = torch.dot(grads_flat, u_flat)\n",
        "    return grad_u\n",
        "\n",
        "def hvp_inhouse(params, X, w0):\n",
        "    u = {name:v[0] for name, v in params.items()}\n",
        "\n",
        "    #loss = eigenmodel_transformer.compute_loss(X, w0).sum()  # Sum over batch\n",
        "\n",
        "    # Compute gradient of loss w.r.t. parameters\n",
        "    #grads = torch.func.grad(myloss, argnums=1)(X, w0)##torch.autograd.grad(loss, w0.values(), create_graph=True)\n",
        "    \n",
        "    #print(grads)\n",
        "    # Flatten gradients and u vectors\n",
        "    #grads_flat = torch.cat([g.view(-1) for g in grads])\n",
        "    #u_flat = torch.cat([u_i.view(-1) for u_i in u.values()])\n",
        "    \n",
        "    #print(grads_flat.shape)\n",
        "    #print(u_flat.shape)\n",
        "    # Compute dot product\n",
        "    #grad_u = torch.dot(grads_flat, u_flat)\n",
        "    \n",
        "\n",
        "    # Compute Hessian-vector product\n",
        "    hvp = torch.func.grad(myloss2, argnums=1, is_grads_batched=True)(X, w0, u)\n",
        "\n",
        "    # Flatten hvp and u vectors\n",
        "    hvp_flat = torch.cat([h.view(-1) for h in hvp.values()])\n",
        "    u_flat = torch.cat([u_i.view(-1) for u_i in u.values()])\n",
        "\n",
        "    # Compute dot product\n",
        "    dH_du = torch.dot(hvp_flat, u_flat)\n",
        "    return dH_du\n",
        "\n",
        "\n",
        "torch.cuda.reset_max_memory_allocated()\n",
        "# Run your code\n",
        "peak_memory = torch.cuda.max_memory_allocated() / 1024**2\n",
        "\n",
        "\n",
        "\n",
        "#test = hvp_inhouse(X_transformer[:3,], eigenmodel_transformer._parameters)\n",
        "\n",
        "\n",
        "\n",
        "# Compute HVPs for all vectors in U\n",
        "peak_memory = torch.cuda.max_memory_allocated() / 1024**2\n",
        "\n",
        "params = eigenmodel_transformer._parameters\n",
        "w0 = eigenmodel_transformer.w0\n",
        "HVPs = torch.vmap(hvp_inhouse, in_dims=(None, 0, None))(params, X_transformer[:3,:], w0)\n",
        "print(peak_memory)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'orch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43morch\u001b[49m\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m      3\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhvp_inhouse\u001b[39m(X, params, w0):\n",
            "\u001b[0;31mNameError\u001b[0m: name 'orch' is not defined"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "def hvp_inhouse(X, params, w0):\n",
        "    u = {name:v[0] for name, v in params.items()}\n",
        "\n",
        "    loss = eigenmodel_transformer.compute_loss(X, w0).sum()  # Sum over batch\n",
        "\n",
        "    # Compute gradient of loss w.r.t. parameters\n",
        "    grads = torch.autograd.grad(loss, w0.values(), create_graph=True)\n",
        "    \n",
        "    print(grads)\n",
        "    # Flatten gradients and u vectors\n",
        "    grads_flat = torch.cat([g.view(-1) for g in grads])\n",
        "    u_flat = torch.cat([u_i.view(-1) for u_i in u.values()])\n",
        "    \n",
        "    print(grads_flat.shape)\n",
        "    print(u_flat.shape)\n",
        "    # Compute dot product\n",
        "    grad_u = torch.dot(grads_flat, u_flat)\n",
        "    \n",
        "\n",
        "    # Compute Hessian-vector product\n",
        "    hvp = torch.autograd.grad(grad_u, w0.values(), retain_graph=True)\n",
        "\n",
        "    # Flatten hvp and u vectors\n",
        "    hvp_flat = torch.cat([h.view(-1) for h in hvp])\n",
        "    u_flat = torch.cat([u_i.view(-1) for u_i in u.values()])\n",
        "\n",
        "    # Compute dot product\n",
        "    dH_du = torch.dot(hvp_flat, u_flat)\n",
        "    return dH_du\n",
        "\n",
        "\n",
        "torch.cuda.reset_max_memory_allocated()\n",
        "# Run your code\n",
        "\n",
        "\n",
        "#test = hvp_inhouse(X_transformer[:3,], eigenmodel_transformer._parameters)\n",
        "peak_memory = torch.cuda.max_memory_allocated() / 1024**2\n",
        "print(peak_memory)\n",
        "\n",
        "from torch.func import vmap\n",
        "\n",
        "# Compute HVPs for all vectors in U\n",
        "params = eigenmodel_transformer._parameters\n",
        "w0 = eigenmodel_transformer.w0\n",
        "HVPs = vmap(hvp_inhouse, in_dims=(0, None, None))(X_transformer[:3,:], params, w0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 938.7214, 1162.7638,  806.2974], device='cuda:0',\n",
              "       grad_fn=<MvBackward0>)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.func import functional_call, vmap, grad\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eigenmodel_transformer.compute_loss(X_transformer[:3,:], w0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def attempt(self, x, w0, u):\n",
        "    # Compute loss\n",
        "    loss = eigenestimation_algorithm.compute_loss(x, w0).sum()  # Sum over batch\n",
        "\n",
        "    # Compute gradient of loss w.r.t. parameters\n",
        "    grads = torch.autograd.grad(loss, w0.values(), create_graph=True)\n",
        "\n",
        "    # Flatten gradients and u vectors\n",
        "    grads_flat = torch.cat([g.view(-1) for g in grads])\n",
        "    u_flat = torch.cat([u_i.view(-1) for u_i in u.values()])\n",
        "\n",
        "    # Compute dot product\n",
        "    grad_u = torch.dot(grads_flat, u_flat)\n",
        "    return grad_u\n",
        "\n",
        "\n",
        "    # Compute grad along u\n",
        "    grad_u = self.grad_along_u(x, self.w0, u)\n",
        "\n",
        "    # Compute Hessian-vector product\n",
        "    hvp = torch.autograd.grad(grad_u, self.w0.values(), retain_graph=True)\n",
        "\n",
        "    # Flatten hvp and u vectors\n",
        "    hvp_flat = torch.cat([h.view(-1) for h in hvp])\n",
        "    u_flat = torch.cat([u_i.view(-1) for u_i in u.values()])\n",
        "\n",
        "    # Compute dot product\n",
        "    dH_du = torch.dot(hvp_flat, u_flat)\n",
        "    return dH_du\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def call(X, params):\n",
        "    params_dict = {k:v for k,v in zip(params.keys(), param_tuple)}\n",
        "    return functional_call(transformer_model, X[:2,:2], params_dict)\n",
        "##eigenmodel_transformer(X_transformer[:2,:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.func import jacrev, functional_call\n",
        "\n",
        "param_tuple = tuple([v[0] for v in eigenmodel_transformer._parameters.values()])\n",
        "v_tuple = tuple([torch.rand_like(v[0]) for v in eigenmodel_transformer._parameters.values()])\n",
        "\n",
        "X = X_transformer[:2,:2]\n",
        "def Call(*params):\n",
        "    params_ordered_dict = eigenmodel_transformer._parameters\n",
        "    param_tuple = params\n",
        "    params_dict = {k:v for k,v in zip(params_ordered_dict.keys(), param_tuple)}\n",
        "    out = functional_call(transformer_model, params_dict,  X)\n",
        "    return out\n",
        "\n",
        "torch.autograd.functional.hvp(Call, tuple(X.float()) + param_tuple, v=tuple(torch.zeros(X.shape))+v_tuple)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eigenmodel_transformer._parameters.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tuple(X.float()) + param_tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tuple(torch.zeros(X.shape))+v_tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    for i in range(n_u_vectors):\n",
        "        print(f'-----{i}-----')\n",
        "        PrintActivatingExamplesTransformer(eigenmodel_transformer, X_transformer[::100,:4], 1,top_k=5, batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eigenmodel_transformer.double_grad_along_u(X_transformer[:2,], u=eigenmodel_transformer._parameters).shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(list(eigenmodel_transformer._parameters.values())[0]**2).sum(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    PrintFeatureValsTransformer(eigenmodel_transformer, X_transformer[::100,:10], 4, 1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "GGfOzqG9Pa9C",
        "LxERVD-g8Y9C",
        "DGTF2lp-813s",
        "sHPJ8o_G7mZt",
        "CAtCqkSQbSaA",
        "0IudwqWOdYQR"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0182948587f94b9c8ee166a4857cbc64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c788b73048d84d2091ba6fdb4beb032d",
            "placeholder": "​",
            "style": "IPY_MODEL_1f558314e5644b149fd81eaf5f56794d",
            "value": "Map (num_proc=10): 100%"
          }
        },
        "03c318e6b07b47d9afb7aa239aa518ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05d2418c87b44fae8bf00c426ae9eb78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "091594635b134ce99c71cf1db16526c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b0250fe6ad14548bba09ed2cf78e9a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f1efc0432d24e75a9c2625cf0c87016": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "106412f5c9d8483b94fd992519a05070": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0182948587f94b9c8ee166a4857cbc64",
              "IPY_MODEL_a6868646ca214b39a29a231c41a2c5da",
              "IPY_MODEL_37db266040a54bbab4ae0c78d1402c8d"
            ],
            "layout": "IPY_MODEL_da0ebc4694cf422ea7bc65f282f55c2e"
          }
        },
        "1239413aee944685ab10d95a646bb212": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "131e1bfb869a4c4089ec793e50a09f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7f960316d5a4d10ac9363d52bcc6e71",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aac3d0eb5b334915bc9820b793f734bf",
            "value": 25000
          }
        },
        "1a7d0d238df34772b9044ff5be118e8c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bea7df13e8c47bcba4294bb41161f4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f558314e5644b149fd81eaf5f56794d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23f7036a798c47bc9eae5e015dbaf76e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28815477856d441080df64f856fce57d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "290e0afedc774ea4aff3262a77ae6232": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2df0dcddfe864d7786dcf9a2af957689": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_587a9b50f4534847bcc26bd274f12e8d",
            "placeholder": "​",
            "style": "IPY_MODEL_70b6ba0b163141368c2c1407a3b2a408",
            "value": " 50000/50000 [00:00&lt;00:00, 168109.00 examples/s]"
          }
        },
        "2e1c71c7c3c643c08f2c68703fcfe832": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "314a36ea6e5c40c9b14b798715881a22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3289b9e724ac4c938678d55e86f7330a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ee488c271ca485b8304df0f30c72d52",
              "IPY_MODEL_f5d6567526c64a9f9286e480ee57e28e",
              "IPY_MODEL_2df0dcddfe864d7786dcf9a2af957689"
            ],
            "layout": "IPY_MODEL_fedda8ef165842d69469450c103ea30d"
          }
        },
        "3578dc7a53cf4708b9153f6e286ab24f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3638f52fad834bfdb0ad1fce6c3a5691": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cee7aad85024e8fa0cbb7ecfaaa1cf6",
            "placeholder": "​",
            "style": "IPY_MODEL_bc66a456264f4cfa9eb85c184e3ec27c",
            "value": " 20.5M/20.5M [00:00&lt;00:00, 327MB/s]"
          }
        },
        "37db266040a54bbab4ae0c78d1402c8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28815477856d441080df64f856fce57d",
            "placeholder": "​",
            "style": "IPY_MODEL_b8f4a8958030410193aaeb95aab076a9",
            "value": " 250/250 [00:10&lt;00:00, 25.27 examples/s]"
          }
        },
        "3a8290ee014742febefa7e23d048a18a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a8a8bad11664c9aaec3a3f17f013477": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b1854751fa141a4891196d07f135221": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c7a40a4ce78442895b726019f672ca6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cc0df343506435b8c108cd69d51d89f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e1b1a7da8024732af0c9cdbe924b9ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4136ceea9ba8471a8010de0e565a709c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "420bde1bd00f498593fd8a93dc58902f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45ce75556a0c4ccf9feb97e667e5b119": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48ce4642b55c48e6bd23a0aba373d364": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b3acd3526fa4a2993e2274bdf4eae35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "541443183a6d40a38eca72898fb917d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "581fca5501054424b787bb3936fd0c51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_808a2d87c63249cea15492a02b34e6e6",
            "placeholder": "​",
            "style": "IPY_MODEL_1bea7df13e8c47bcba4294bb41161f4d",
            "value": "Generating train split: 100%"
          }
        },
        "587a9b50f4534847bcc26bd274f12e8d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c93c4db6e704cf0acb09229cf29472d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0ef5b6f865b4583a46f11c6b64baf51",
            "max": 20470363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05d2418c87b44fae8bf00c426ae9eb78",
            "value": 20470363
          }
        },
        "6658013b6e424c9882651c71046a97d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70a9c225586b422c89776cb4404cea3b",
            "placeholder": "​",
            "style": "IPY_MODEL_7153f5d451a344689aca4a23fd267a13",
            "value": " 21.0M/21.0M [00:00&lt;00:00, 231MB/s]"
          }
        },
        "680c99e0ead8422eade91e99cdf13ef0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "684c3a767e3b403898a5899cf183e1a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d088c6fba45c4fe2be0c3b7b31510f76",
              "IPY_MODEL_754c55b478054e6998e2790ec607f0d7",
              "IPY_MODEL_a522b6e0641e4591842153e5c42ccabd"
            ],
            "layout": "IPY_MODEL_2e1c71c7c3c643c08f2c68703fcfe832"
          }
        },
        "6abafbd7c3f64450b5af4009d52211bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_581fca5501054424b787bb3936fd0c51",
              "IPY_MODEL_131e1bfb869a4c4089ec793e50a09f01",
              "IPY_MODEL_e0055756742448959961f1653a99a81a"
            ],
            "layout": "IPY_MODEL_420bde1bd00f498593fd8a93dc58902f"
          }
        },
        "70a9c225586b422c89776cb4404cea3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70b6ba0b163141368c2c1407a3b2a408": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "714276a2de3644a682940268ae9ebfc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7153f5d451a344689aca4a23fd267a13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73e901aa3ef441da81138d2e02a0fcc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a8a8bad11664c9aaec3a3f17f013477",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_714276a2de3644a682940268ae9ebfc2",
            "value": 25000
          }
        },
        "754c55b478054e6998e2790ec607f0d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1239413aee944685ab10d95a646bb212",
            "max": 41996509,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45ce75556a0c4ccf9feb97e667e5b119",
            "value": 41996509
          }
        },
        "78fa322680d14395a54b375cbbbb3418": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe52df55cc4b4072ab0a0c1617c71175",
            "max": 7809,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_541443183a6d40a38eca72898fb917d3",
            "value": 7809
          }
        },
        "808a2d87c63249cea15492a02b34e6e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86594350ac2e46eea084f223dfda1aae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "877754d374964795bde8a66af5cd17b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1753904d2a14ca1adcd17b6f007f193",
            "placeholder": "​",
            "style": "IPY_MODEL_091594635b134ce99c71cf1db16526c6",
            "value": "test-00000-of-00001.parquet: 100%"
          }
        },
        "8d71a3168e404f758443cc646dc9b55d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ee488c271ca485b8304df0f30c72d52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b0250fe6ad14548bba09ed2cf78e9a7",
            "placeholder": "​",
            "style": "IPY_MODEL_03c318e6b07b47d9afb7aa239aa518ef",
            "value": "Generating unsupervised split: 100%"
          }
        },
        "931d0757865c42a3b6ee2cd4c56ef562": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cee7aad85024e8fa0cbb7ecfaaa1cf6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a522b6e0641e4591842153e5c42ccabd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a7d0d238df34772b9044ff5be118e8c",
            "placeholder": "​",
            "style": "IPY_MODEL_e1520123c50f4c559bb32fa225d00e8f",
            "value": " 42.0M/42.0M [00:00&lt;00:00, 342MB/s]"
          }
        },
        "a6868646ca214b39a29a231c41a2c5da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a8290ee014742febefa7e23d048a18a",
            "max": 250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb5375e0c5694c5f95483108b83a05cc",
            "value": 250
          }
        },
        "a83affc5e5a946788a7d1f1f4ab252cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d95f1d285e58481882e8b511a33580a5",
            "placeholder": "​",
            "style": "IPY_MODEL_314a36ea6e5c40c9b14b798715881a22",
            "value": "README.md: 100%"
          }
        },
        "a8ad203d8bf043ce95bbeff43691cf44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_290e0afedc774ea4aff3262a77ae6232",
            "placeholder": "​",
            "style": "IPY_MODEL_86594350ac2e46eea084f223dfda1aae",
            "value": "Generating test split: 100%"
          }
        },
        "aac3d0eb5b334915bc9820b793f734bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae7325313ac14a8ca14d5fd2fee89e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_877754d374964795bde8a66af5cd17b8",
              "IPY_MODEL_5c93c4db6e704cf0acb09229cf29472d",
              "IPY_MODEL_3638f52fad834bfdb0ad1fce6c3a5691"
            ],
            "layout": "IPY_MODEL_0f1efc0432d24e75a9c2625cf0c87016"
          }
        },
        "ae9a57dbdd444595b3142ce89822c71f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48ce4642b55c48e6bd23a0aba373d364",
            "placeholder": "​",
            "style": "IPY_MODEL_23f7036a798c47bc9eae5e015dbaf76e",
            "value": " 25000/25000 [00:00&lt;00:00, 142066.48 examples/s]"
          }
        },
        "b8f4a8958030410193aaeb95aab076a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc66a456264f4cfa9eb85c184e3ec27c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c07cc541262744ea89f027fe5d859210": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a83affc5e5a946788a7d1f1f4ab252cc",
              "IPY_MODEL_78fa322680d14395a54b375cbbbb3418",
              "IPY_MODEL_e67f44172d2247729433f3889847df5b"
            ],
            "layout": "IPY_MODEL_d3323d7c1d694236a948699005f9341c"
          }
        },
        "c0e9174592b0410a8e6a9fb2c0e7278f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1753904d2a14ca1adcd17b6f007f193": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c46cde1438d54fa89bdbe7c093089125": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8ad203d8bf043ce95bbeff43691cf44",
              "IPY_MODEL_73e901aa3ef441da81138d2e02a0fcc0",
              "IPY_MODEL_ae9a57dbdd444595b3142ce89822c71f"
            ],
            "layout": "IPY_MODEL_8d71a3168e404f758443cc646dc9b55d"
          }
        },
        "c788b73048d84d2091ba6fdb4beb032d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca7e73e9cf5347928557a754f1a46754": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb13fb61baea4fd1923f990acd31f200": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_680c99e0ead8422eade91e99cdf13ef0",
            "placeholder": "​",
            "style": "IPY_MODEL_3e1b1a7da8024732af0c9cdbe924b9ce",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "d088c6fba45c4fe2be0c3b7b31510f76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c7a40a4ce78442895b726019f672ca6",
            "placeholder": "​",
            "style": "IPY_MODEL_c0e9174592b0410a8e6a9fb2c0e7278f",
            "value": "unsupervised-00000-of-00001.parquet: 100%"
          }
        },
        "d0ef5b6f865b4583a46f11c6b64baf51": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3323d7c1d694236a948699005f9341c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7f960316d5a4d10ac9363d52bcc6e71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d95f1d285e58481882e8b511a33580a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da0ebc4694cf422ea7bc65f282f55c2e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de80c2d0e39c4e299106c8cc45ac5d37": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0055756742448959961f1653a99a81a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3578dc7a53cf4708b9153f6e286ab24f",
            "placeholder": "​",
            "style": "IPY_MODEL_931d0757865c42a3b6ee2cd4c56ef562",
            "value": " 25000/25000 [00:00&lt;00:00, 98860.67 examples/s]"
          }
        },
        "e1520123c50f4c559bb32fa225d00e8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e67f44172d2247729433f3889847df5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4136ceea9ba8471a8010de0e565a709c",
            "placeholder": "​",
            "style": "IPY_MODEL_4b3acd3526fa4a2993e2274bdf4eae35",
            "value": " 7.81k/7.81k [00:00&lt;00:00, 636kB/s]"
          }
        },
        "e8b144c9c94c4ab5a535341579c07f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de80c2d0e39c4e299106c8cc45ac5d37",
            "max": 20979968,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b1854751fa141a4891196d07f135221",
            "value": 20979968
          }
        },
        "efcde3edec9f4d0cb1288f5a1ea7f088": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5d6567526c64a9f9286e480ee57e28e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efcde3edec9f4d0cb1288f5a1ea7f088",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3cc0df343506435b8c108cd69d51d89f",
            "value": 50000
          }
        },
        "f8cc96106385416d809cdec354f8a6de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb13fb61baea4fd1923f990acd31f200",
              "IPY_MODEL_e8b144c9c94c4ab5a535341579c07f1f",
              "IPY_MODEL_6658013b6e424c9882651c71046a97d0"
            ],
            "layout": "IPY_MODEL_ca7e73e9cf5347928557a754f1a46754"
          }
        },
        "fb5375e0c5694c5f95483108b83a05cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe52df55cc4b4072ab0a0c1617c71175": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fedda8ef165842d69469450c103ea30d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
