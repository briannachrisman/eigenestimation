{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Toy Model of Superposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'toy_models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load in  outputs/toy_models/correlated_input.pt with torch.load\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../outputs/toy_models/correlated_input.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/serialization.py:1014\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1013\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1014\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m                     \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmap can only be used with files saved with \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1021\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`torch.save(_use_new_zipfile_serialization=True), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1022\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease torch.save your checkpoint with this option in order to use mmap.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/serialization.py:1422\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1420\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1421\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1422\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1425\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_metadata(\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load.metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: zip_file\u001b[38;5;241m.\u001b[39mserialization_id()}\n\u001b[1;32m   1427\u001b[0m )\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/serialization.py:1415\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[0;34m(self, mod_name, name)\u001b[0m\n\u001b[1;32m   1413\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1414\u001b[0m mod_name \u001b[38;5;241m=\u001b[39m load_module_mapping\u001b[38;5;241m.\u001b[39mget(mod_name, mod_name)\n\u001b[0;32m-> 1415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'toy_models'"
     ]
    }
   ],
   "source": [
    "# Load in  outputs/toy_models/correlated_input.pt with torch.load\n",
    "import torch\n",
    "model = torch.load('../outputs/toy_models/correlated_input.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import numpy as np\n",
    "    import einops\n",
    "    num_datapoints = 100\n",
    "    sparsity = 0.1\n",
    "    correlation_set_size = 3\n",
    "    num_features = 12\n",
    "    # Initialize feature vectors with random values\n",
    "    feature_vectors: np.ndarray = np.random.rand(num_datapoints, num_features)\n",
    "    # Apply sparsity to the feature vectors\n",
    "    \n",
    "    \n",
    "    sparsity_mask = einops.repeat((np.random.rand(num_datapoints, int(num_features/correlation_set_size)) < sparsity), 'sample feature -> sample (feature s)', s=correlation_set_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False,  True,  True,  True, False, False, False,\n",
       "       False, False, False])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparsity_mask[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m binary_numbers_str: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39mbinary_repr(n, width\u001b[38;5;241m=\u001b[39mnum_features) \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m binary_numbers])\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m digit\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m digit \u001b[38;5;129;01min\u001b[39;00m b] \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m binary_numbers_str])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "binary_numbers_str: np.ndarray = np.array([np.binary_repr(n, width=num_features) for n in binary_numbers])\n",
    "\n",
    "torch.tensor([[1 if digit=='1' else -1 for digit in b] for b in binary_numbers_str])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0747, grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show W_out @ W_in @ H @ W_in.T @ W_out.T - H with imshow\n",
    "from matplotlib import pyplot as plt\n",
    "diff = W_out @ W_in @ H @ W_in.T @ W_out.T - H\n",
    "plt.imshow(diff.detach().numpy(), cmap='bwr')\n",
    "\n",
    "\n",
    "print(diff.norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Loss: 23.2621\n",
      "53.704673767089844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10000, Loss: 0.0319\n",
      "0.04160083085298538\n",
      "Iteration 20000, Loss: 0.0394\n",
      "0.047546640038490295\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[126], line 34\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Sample v from rademacher distribution\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#v = torch.randn(H.shape[0], 1)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#v = torch.where(v > 0, 1.0, -1.0).detach()\u001b[39;00m\n\u001b[1;32m     33\u001b[0m v \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(H\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 34\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     36\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[126], line 22\u001b[0m, in \u001b[0;36mloss_fn\u001b[0;34m(W_in, W_out, H, v)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mloss_fn\u001b[39m(W_in, W_out, H, v):\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW_out\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mW_in\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/functional.py:1480\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m   1474\u001b[0m     \u001b[38;5;129m@overload\u001b[39m  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   1475\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnorm\u001b[39m(\u001b[38;5;28minput\u001b[39m, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfro\u001b[39m\u001b[38;5;124m\"\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   1476\u001b[0m         \u001b[38;5;66;03m# type: (Tensor, str, Optional[int], bool, Optional[Tensor], Optional[int]) -> Tensor\u001b[39;00m\n\u001b[1;32m   1477\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m-> 1480\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnorm\u001b[39m(\u001b[38;5;28minput\u001b[39m, p: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfro\u001b[39m\u001b[38;5;124m\"\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   1481\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the matrix norm or vector norm of a given tensor.\u001b[39;00m\n\u001b[1;32m   1482\u001b[0m \n\u001b[1;32m   1483\u001b[0m \u001b[38;5;124;03m    .. warning::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;124;03m        (tensor(3.7417), tensor(11.2250))\u001b[39;00m\n\u001b[1;32m   1572\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1574\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch import Tensor\n",
    "import torch \n",
    "\n",
    "# Make me a random symmetric matrix\n",
    "H = torch.rand(10, 5)\n",
    "H = H @ H.transpose(0,1)\n",
    "\n",
    "# ... existing code ...\n",
    "\n",
    "# Make W_in and W_out require gradients from the start\n",
    "W_in = torch.nn.Parameter(torch.randn(10, 10))\n",
    "W_out = torch.nn.Parameter(torch.randn(10, 10))\n",
    "\n",
    "# Normalize W_in (but keep it as a parameter)\n",
    "with torch.no_grad():\n",
    "    W_in.data = W_in.data / torch.norm(W_in.data, dim=0)\n",
    "\n",
    "# Define the optimizer with the parameters\n",
    "optimizer = torch.optim.Adam([W_in, W_out], lr=0.001)\n",
    "\n",
    "def loss_fn(W_in, W_out, H, v):\n",
    "    return torch.norm(W_out @ W_in @ H @ v - (H @ v))\n",
    "\n",
    "# Training loop\n",
    "for i in range(100000):\n",
    "    optimizer.zero_grad()\n",
    "    # Sample v from rademacher distribution\n",
    "    \n",
    "\n",
    "    #v = torch.randn(H.shape[0], 1)\n",
    "    #v = torch.where(v > 0, 1.0, -1.0).detach()\n",
    "    \n",
    "    v = torch.eye(H.shape[0])\n",
    "    loss = loss_fn(W_in, W_out, H, v)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Renormalize W_in after each step\n",
    "    W_in.data.div_(torch.norm(W_in.data, dim=0))\n",
    "    \n",
    "    if i % 10000 == 0:\n",
    "        print(f\"Iteration {i}, Loss: {loss.item():.4f}\")\n",
    "        diff = W_out @ W_in @ H @ W_in.T @ W_out.T - H\n",
    "        print(diff.norm().item())\n",
    "# ... existing code ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.4619e+01+0.j,  1.2205e+00+0.j,  7.4423e-01+0.j,  9.6596e-01+0.j,\n",
      "         2.4430e-01+0.j, -2.0550e-07+0.j, -3.7852e-07+0.j, -7.4106e-08+0.j,\n",
      "         8.6402e-08+0.j,  7.0814e-09+0.j])\n"
     ]
    }
   ],
   "source": [
    "# Get eigenvalues of H\n",
    "eigenvalues = torch.linalg.eigvals(H)\n",
    "print(eigenvalues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0735, grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show W_out @ W_in @ H @ W_in.T @ W_out.T - H with imshow\n",
    "from matplotlib import pyplot as plt\n",
    "diff = W_out @ W_in @ H @ W_in.T @ W_out.T - H\n",
    "plt.imshow(diff.detach().numpy(), cmap='bwr')\n",
    "\n",
    "\n",
    "print(diff.norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toy_models.trainer import Trainer as ModelTrainer\n",
    "from toy_models.tms import Autoencoder, GenerateTMSData\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eigenmodel.eigenmodel import EigenModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "grad() got an unexpected keyword argument 'g'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 63\u001b[0m\n\u001b[1;32m     60\u001b[0m vectors \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(batch_size, num_params)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Compute Hessian-vector products\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m hvps \u001b[38;5;241m=\u001b[39m \u001b[43mbatched_hessian_vector_product\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Print results\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHessian-vector products shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, hvps\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# Should be [batch_size, num_params]\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 40\u001b[0m, in \u001b[0;36mbatched_hessian_vector_product\u001b[0;34m(model, loss_fn, inputs, targets, vectors)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhvp_fn\u001b[39m(v):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mvmap(\u001b[38;5;28;01mlambda\u001b[39;00m g: torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(g, params\u001b[38;5;241m.\u001b[39mvalues(), g\u001b[38;5;241m=\u001b[39mv, retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))(grad_vectors)\n\u001b[0;32m---> 40\u001b[0m hvp \u001b[38;5;241m=\u001b[39m \u001b[43mhvp_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hvp\n",
      "Cell \u001b[0;32mIn[1], line 38\u001b[0m, in \u001b[0;36mbatched_hessian_vector_product.<locals>.hvp_fn\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhvp_fn\u001b[39m(v):\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_vectors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/_functorch/apis.py:188\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/_functorch/vmap.py:266\u001b[0m, in \u001b[0;36mvmap_impl\u001b[0;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(func, flat_in_dims, chunks_flat_args,\n\u001b[1;32m    263\u001b[0m                          args_spec, out_dims, randomness, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/_functorch/vmap.py:38\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/_functorch/vmap.py:379\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[0;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(flat_in_dims, flat_args, vmap_level, args_spec)\n\u001b[0;32m--> 379\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 38\u001b[0m, in \u001b[0;36mbatched_hessian_vector_product.<locals>.hvp_fn.<locals>.<lambda>\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhvp_fn\u001b[39m(v):\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mvmap(\u001b[38;5;28;01mlambda\u001b[39;00m g: \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)(grad_vectors)\n",
      "\u001b[0;31mTypeError\u001b[0m: grad() got an unexpected keyword argument 'g'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.func as tf\n",
    "\n",
    "def batched_hessian_vector_product(model, loss_fn, inputs, targets, vectors):\n",
    "    \"\"\"\n",
    "    Computes Hessian-vector products (HVP) for a batch efficiently without explicit loops.\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        loss_fn: Loss function\n",
    "        inputs: Batch of input samples (tensor of shape [batch_size, input_dim])\n",
    "        targets: Batch of targets (tensor of shape [batch_size, output_dim])\n",
    "        vectors: Batch of vectors (tensor of shape [batch_size, num_params])\n",
    "\n",
    "    Returns:\n",
    "        A tensor of shape [batch_size, num_params] containing the Hessian-vector products.\n",
    "    \"\"\"\n",
    "    # Define a function that takes model parameters and computes loss per sample\n",
    "    def single_loss(params, x, y):\n",
    "        pred = tf.functional_call(model, params, (x,))\n",
    "        return loss_fn(pred, y)\n",
    "\n",
    "    # Get the model parameters as a PyTree\n",
    "    params = {k: v for k, v in model.named_parameters()}\n",
    "    \n",
    "    # Compute per-sample gradients (batched automatically)\n",
    "    grad_fn = tf.jacrev(single_loss)  # First-order gradient function\n",
    "    grads = torch.vmap(grad_fn, in_dims=(None, 0, 0))(params, inputs, targets)\n",
    "\n",
    "    # Flatten gradients into a single vector per sample\n",
    "    def flatten(pytree):\n",
    "        return torch.cat([p.flatten(start_dim=1) for p in pytree.values()], dim=1)\n",
    "    \n",
    "    grad_vectors = flatten(grads)  # Shape: (batch_size, num_params)\n",
    "\n",
    "    # Compute Hessian-vector product efficiently\n",
    "    def hvp_fn(v):\n",
    "        return torch.vmap(lambda g: torch.autograd.grad(g, params.values(), g=v, retain_graph=True))(grad_vectors)\n",
    "\n",
    "    hvp = hvp_fn(vectors)\n",
    "\n",
    "    return hvp\n",
    "\n",
    "# Example Usage\n",
    "batch_size = 4\n",
    "input_dim = 10\n",
    "output_dim = 1\n",
    "\n",
    "model = torch.nn.Linear(input_dim, output_dim)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Dummy Data\n",
    "inputs = torch.randn(batch_size, input_dim)\n",
    "targets = torch.randn(batch_size, output_dim)\n",
    "\n",
    "# Get the number of model parameters\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "# Create random vectors for each sample\n",
    "vectors = torch.randn(batch_size, num_params)\n",
    "\n",
    "# Compute Hessian-vector products\n",
    "hvps = batched_hessian_vector_product(model, loss_fn, inputs, targets, vectors)\n",
    "\n",
    "# Print results\n",
    "print(\"Hessian-vector products shape:\", hvps.shape)  # Should be [batch_size, num_params]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([torch.tensor([1,2,3]) for _ in [1,2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[2 for _ in [1,2,3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".eigenestimation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
