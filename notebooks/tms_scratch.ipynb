{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Toy Model of Superposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m parent_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../eigenestimation/eigenestimation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     32\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(parent_dir)\n\u001b[1;32m     34\u001b[0m X_train, Y_train, dataloader_train \u001b[38;5;241m=\u001b[39m GenerateTMSData(\n\u001b[0;32m---> 35\u001b[0m     num_features\u001b[38;5;241m=\u001b[39m\u001b[43mn_features\u001b[49m, num_datapoints\u001b[38;5;241m=\u001b[39mn_datapoints, sparsity\u001b[38;5;241m=\u001b[39msparsity, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m     37\u001b[0m X_eval, Y_eval, dataloader_eval \u001b[38;5;241m=\u001b[39m GenerateTMSData(\n\u001b[1;32m     38\u001b[0m     num_features\u001b[38;5;241m=\u001b[39mn_features, num_datapoints\u001b[38;5;241m=\u001b[39mn_training_datapoints, sparsity\u001b[38;5;241m=\u001b[39msparsity, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m     41\u001b[0m tms_model \u001b[38;5;241m=\u001b[39m AutoencoderSymmetric(n_features, n_hidden)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_features' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch \n",
    "# Parse arguments with argparser\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Run TMS simulation')\n",
    "parser.add_argument('--n_features', type=int, default=5)\n",
    "parser.add_argument('--n_training_datapoints', type=int, default=1000)\n",
    "parser.add_argument('--n_eval_datapoints', type=int, default=1000)\n",
    "parser.add_argument('--sparsity', type=float, default=0.1)\n",
    "parser.add_argument('--batch_size', type=int, default=32)\n",
    "parser.add_argument('--n_hidden', type=int, default=2)\n",
    "parser.add_argument('--learning_rate', type=int, default=.01)\n",
    "parser.add_argument('--n_epochs', type=int, default=10)\n",
    "\n",
    "# Save arguments as variables\n",
    "args = parser.parse_args()\n",
    "n_features = args.n_features\n",
    "n_training_datapoints = args.n_training_datapoints\n",
    "n_eval_datapoints = args.n_eval_datapoints\n",
    "n_hidden = args.n_hidden\n",
    "sparsity = args.sparsity\n",
    "batch_size = args.batch_size\n",
    "learning_rate = args.learning_rate\n",
    "n_epochs = args.n_epochs\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "parent_dir = os.path.expanduser('../eigenestimation/eigenestimation')\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "X_train, Y_train, dataloader_train = GenerateTMSData(\n",
    "    num_features=n_features, num_datapoints=n_datapoints, sparsity=sparsity, batch_size=batch_size)\n",
    "\n",
    "X_eval, Y_eval, dataloader_eval = GenerateTMSData(\n",
    "    num_features=n_features, num_datapoints=n_training_datapoints, sparsity=sparsity, batch_size=batch_size)\n",
    "\n",
    "\n",
    "tms_model = AutoencoderSymmetric(n_features, n_hidden).to(device)\n",
    "\n",
    "_, _, _ = TrainModel(tms_model, nn.MSELoss(), learning_rate, dataloader_train, n_epochs=n_epochs, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toy_models.trainer import Trainer as ModelTrainer\n",
    "from toy_models.tms import Autoencoder, GenerateTMSData\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eigenmodel.eigenmodel import EigenModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1820104484.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[14], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    train_data_loader =\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_data_loader = \n",
    "eval_data_loader = \n",
    "\n",
    "\n",
    "# Instantiate model and trainer\n",
    "model = Autoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "trainer = SimpleTrainer(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    learning_rate=0.01,\n",
    "    n_epochs=50,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    run_name=\"tms\",\n",
    "    checkpoint_freq=100\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trained_model, parameters, losses = trainer.train(train_dataloader, eval_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".eigenestimation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
