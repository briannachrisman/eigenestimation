{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "eigenmodel_path = \"/root/eigenestimation/outputs/eigenmodels/tinystories-8M.pt\"\n",
    "eigenmodel = torch.load(eigenmodel_path)['model']\n",
    "from eigenestimation.evaluation.top_logits import compute_jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circuit 1\n",
      "[\"'s\", ' was', ' is', 'ï¿½', ' means']\n",
      "[' day', ' night', ' dog', ' way', ' idea']\n",
      "Circuit 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' day', ' idea', ' dog', ' little', ' are']\n",
      "[' was', ' is', \"'s\", ' way', ' means']\n",
      "Circuit 3\n",
      "[' day', ' night', ' morning', ' week', ' days']\n",
      "[' is', \"'s\", ' was', ' bird', ' dog']\n"
     ]
    }
   ],
   "source": [
    "for circuit_idx in [1,2,3]:\n",
    "    print(f'Circuit {circuit_idx}')\n",
    "    jac = compute_jacobian(eigenmodel, X_data[[0]].to('cuda'), circuit_idx, device='cuda')\n",
    "    top_token_idxs = jac.argsort(descending=True)[:5]\n",
    "    bottom_token_idxs = jac.argsort(descending=False)[:5]\n",
    "    print([eigenmodel.model.tokenizer.decode(token_idx) for token_idx in top_token_idxs])\n",
    "    print([eigenmodel.model.tokenizer.decode(token_idx) for token_idx in bottom_token_idxs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transformer.transformer.h.1.attn.attention.k_proj.weight': tensor([[-0.0338, -0.0252,  0.0091,  ...,  0.0099,  0.0139, -0.0032],\n",
       "         [ 0.0175, -0.0406, -0.0315,  ...,  0.0334,  0.0150,  0.0046],\n",
       "         [-0.0164,  0.0018,  0.0066,  ...,  0.0130,  0.0117,  0.0334],\n",
       "         ...,\n",
       "         [-0.0261,  0.0261,  0.0139,  ..., -0.0219,  0.0126,  0.0231],\n",
       "         [ 0.0158, -0.0214,  0.0439,  ...,  0.0158,  0.0313,  0.0215],\n",
       "         [ 0.0038,  0.0075,  0.0423,  ..., -0.0036, -0.0116, -0.0154]],\n",
       "        device='cuda:0'),\n",
       " 'transformer.transformer.h.1.attn.attention.v_proj.weight': tensor([[ 0.0049, -0.0012, -0.0045,  ..., -0.0457,  0.0095,  0.0121],\n",
       "         [ 0.0028, -0.0384, -0.0097,  ..., -0.0223,  0.0069,  0.0175],\n",
       "         [ 0.0010,  0.0099,  0.0175,  ...,  0.0185, -0.0076,  0.0357],\n",
       "         ...,\n",
       "         [ 0.0132,  0.0298, -0.0010,  ...,  0.0012,  0.0392,  0.0103],\n",
       "         [ 0.0092,  0.0058, -0.0124,  ...,  0.0094, -0.0018,  0.0116],\n",
       "         [-0.0058, -0.0104, -0.0081,  ..., -0.0318,  0.0119, -0.0131]],\n",
       "        device='cuda:0'),\n",
       " 'transformer.transformer.h.1.attn.attention.q_proj.weight': tensor([[ 0.0073, -0.0450,  0.0068,  ...,  0.0229, -0.0538, -0.0583],\n",
       "         [ 0.0122, -0.0206, -0.0267,  ..., -0.0203,  0.0569,  0.0058],\n",
       "         [ 0.0378,  0.0394,  0.0089,  ...,  0.0348, -0.0683, -0.0318],\n",
       "         ...,\n",
       "         [-0.0571,  0.0066, -0.0309,  ..., -0.0460, -0.0227,  0.0096],\n",
       "         [-0.0004, -0.0398, -0.0272,  ..., -0.0053,  0.0025,  0.0489],\n",
       "         [ 0.0009, -0.0186, -0.0473,  ..., -0.0098, -0.0153, -0.0383]],\n",
       "        device='cuda:0')}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenmodel.param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_path = \"/root/eigenestimation/outputs/top_tokens/tinystories-8M-X_data.pt\"\n",
    "attributions_path = \"/root/eigenestimation/outputs/top_tokens/tinystories-8M-circuit_attributions.pt\"\n",
    "eigenmodel_path = \"/root/eigenestimation/outputs/eigenmodels/tinystories-8M.pt\"\n",
    "X_data = torch.load(X_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "from torch.func import functional_call\n",
    "def reconstruct_network(eigenmodel, coef, sample, feature_idx) -> dict:\n",
    "        original = eigenmodel.param_dict\n",
    "        reconstruction = dict({})\n",
    "        new_network = dict({})\n",
    "        for name in eigenmodel.low_rank_decode:\n",
    "            print(name)\n",
    "            reconstruction[name] = eigenmodel.low_rank_decode[name][0][...,feature_idx]\n",
    "            for tensor in eigenmodel.low_rank_decode[name][1:]:\n",
    "                reconstruction[name] = einops.einsum(reconstruction[name], tensor[...,feature_idx], '... r, w r ->  ... w r')\n",
    "            reconstruction[name] = einops.einsum(reconstruction[name], '... w r  -> ... w')\n",
    "            new_network[name] = coef* reconstruction[name]\n",
    "        return functional_call(eigenmodel.model, new_network, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grad_outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[140], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgrad_outputs\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grad_outputs' is not defined"
     ]
    }
   ],
   "source": [
    "grad_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.transformer.h.1.attn.attention.k_proj.weight\n",
      "transformer.transformer.h.1.attn.attention.v_proj.weight\n",
      "transformer.transformer.h.1.attn.attention.q_proj.weight\n",
      "transformer.transformer.h.1.attn.attention.k_proj.weight\n",
      "transformer.transformer.h.1.attn.attention.v_proj.weight\n",
      "transformer.transformer.h.1.attn.attention.q_proj.weight\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[155], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m output_vals \u001b[38;5;241m=\u001b[39m reconstruct_network(eigenmodel, coef, (X_data[[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m),), \u001b[38;5;241m2\u001b[39m)[\u001b[38;5;241m0\u001b[39m, token_idx, :]\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[:\u001b[38;5;241m10\u001b[39m]\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Compute full Jacobian\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m jacobian \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreconstruct_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43meigenmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Print the Jacobian values\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull Jacobian:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, jacobian)\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/autograd/functional.py:788\u001b[0m, in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[1;32m    786\u001b[0m jac_i: Tuple[List[torch\u001b[38;5;241m.\u001b[39mTensor]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m([] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs)))  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(out\u001b[38;5;241m.\u001b[39mnelement()):\n\u001b[0;32m--> 788\u001b[0m     vj \u001b[38;5;241m=\u001b[39m \u001b[43m_autograd_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    795\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m el_idx, (jac_i_el, vj_el, inp_el) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[1;32m    796\u001b[0m         \u001b[38;5;28mzip\u001b[39m(jac_i, vj, inputs)\n\u001b[1;32m    797\u001b[0m     ):\n\u001b[1;32m    798\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m vj_el \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/autograd/functional.py:192\u001b[0m, in \u001b[0;36m_autograd_grad\u001b[0;34m(outputs, inputs, grad_outputs, create_graph, retain_graph, is_grads_batched)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m,) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(inputs)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_grad_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_grads_batched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/autograd/__init__.py:394\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    390\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    391\u001b[0m         grad_outputs_\n\u001b[1;32m    392\u001b[0m     )\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 394\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    404\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    405\u001b[0m         output\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    407\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mzeros_like(\u001b[38;5;28minput\u001b[39m, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (output, \u001b[38;5;28minput\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(result, t_inputs)\n\u001b[1;32m    409\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import einops\n",
    "from torch.func import functional_call\n",
    "def reconstruct_network(eigenmodel, coef, sample, feature_idx) -> dict:\n",
    "        original = eigenmodel.param_dict\n",
    "        reconstruction = dict({})\n",
    "        new_network = dict({})\n",
    "        for name in eigenmodel.low_rank_decode:\n",
    "            print(name)\n",
    "            reconstruction[name] = eigenmodel.low_rank_decode[name][0][...,feature_idx]\n",
    "            for tensor in eigenmodel.low_rank_decode[name][1:]:\n",
    "                reconstruction[name] = einops.einsum(reconstruction[name], tensor[...,feature_idx], '... r, w r ->  ... w r')\n",
    "            reconstruction[name] = einops.einsum(reconstruction[name], '... w r  -> ... w')\n",
    "            new_network[name] = coef* reconstruction[name]\n",
    "        return functional_call(eigenmodel.model, new_network, sample)\n",
    "\n",
    "# Ensure coef is on the correct device\n",
    "coef = torch.tensor(0.0, requires_grad=True, device='cuda')\n",
    "token_idx = 0\n",
    "# Compute softmax output\n",
    "output_vals = reconstruct_network(eigenmodel, coef, (X_data[[0]].to('cuda'),), 2)[0, token_idx, :].softmax(dim=-1)[:10]\n",
    "\n",
    "# Compute full Jacobian\n",
    "jacobian = torch.autograd.functional.jacobian(lambda c: reconstruct_network(eigenmodel, c, (X_data[[0]].to('cuda'),), 2)[0, token_idx, :].softmax(dim=-1), coef)\n",
    "\n",
    "# Print the Jacobian values\n",
    "print(\"Full Jacobian:\\n\", jacobian)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Jacobian:\n",
      " tensor([ 8.6503e-04,  1.5793e-04, -9.7902e-09,  ..., -1.8958e-09,\n",
      "        -1.0279e-06,  3.3368e-05], device='cuda:0', grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "import top_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 16, 16]' is invalid for input of size 16",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[157], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mreconstruct_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43meigenmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_data_cuda\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[156], line 25\u001b[0m, in \u001b[0;36mreconstruct_network\u001b[0;34m(eigenmodel, coef, sample, feature_idx)\u001b[0m\n\u001b[1;32m     22\u001b[0m     new_network[name] \u001b[38;5;241m=\u001b[39m coef \u001b[38;5;241m*\u001b[39m recon  \u001b[38;5;66;03m# Scale by coef\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Efficient functional call to model\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunctional_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43meigenmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_network\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/_functorch/functional_call.py:143\u001b[0m, in \u001b[0;36mfunctional_call\u001b[0;34m(module, parameter_and_buffer_dicts, args, kwargs, tie_weights, strict)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter_and_buffer_dicts to be a dict, or a list/tuple of dicts, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(parameter_and_buffer_dicts)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m     )\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstateless\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_functional_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameters_and_buffers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtie_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtie_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/nn/utils/stateless.py:264\u001b[0m, in \u001b[0;36m_functional_call\u001b[0;34m(module, parameters_and_buffers, args, kwargs, tie_weights, strict)\u001b[0m\n\u001b[1;32m    260\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args,)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _reparametrize_module(\n\u001b[1;32m    262\u001b[0m     module, parameters_and_buffers, tie_weights\u001b[38;5;241m=\u001b[39mtie_weights, strict\u001b[38;5;241m=\u001b[39mstrict\n\u001b[1;32m    263\u001b[0m ):\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/eigenestimation/eigenestimation/toy_models/transformer_wrapper.py:17\u001b[0m, in \u001b[0;36mTransformerWrapper.forward\u001b[0;34m(self, tokenized_X)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokenized_X: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Generate model outputs\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     model_output: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenized_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Rearrange the output to a flat batch of logits\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs_logits:\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:963\u001b[0m, in \u001b[0;36mGPTNeoForCausalLM.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    961\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 963\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    979\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:745\u001b[0m, in \u001b[0;36mGPTNeoModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    734\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    735\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    736\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    742\u001b[0m         cache_position,\n\u001b[1;32m    743\u001b[0m     )\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 745\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    755\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:454\u001b[0m, in \u001b[0;36mGPTNeoBlock.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, use_cache, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    452\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    453\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(hidden_states)\n\u001b[0;32m--> 454\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[1;32m    464\u001b[0m outputs \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:404\u001b[0m, in \u001b[0;36mGPTNeoAttention.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, use_cache, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    396\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    402\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    403\u001b[0m ):\n\u001b[0;32m--> 404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:249\u001b[0m, in \u001b[0;36mGPTNeoSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, layer_past, head_mask, use_cache, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    246\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj(hidden_states)\n\u001b[1;32m    247\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\n\u001b[0;32m--> 249\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_heads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_heads(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[1;32m    251\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_heads(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py:192\u001b[0m, in \u001b[0;36mGPTNeoSelfAttention._split_heads\u001b[0;34m(self, tensor, num_heads, attn_head_size)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mSplits hidden_size dim into attn_head_size and num_heads\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    191\u001b[0m new_shape \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m (num_heads, attn_head_size)\n\u001b[0;32m--> 192\u001b[0m tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 16, 16]' is invalid for input of size 16"
     ]
    }
   ],
   "source": [
    "reconstruct_network(eigenmodel, coef, (X_data_cuda[[0]],), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_vals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.3364e-08, device='cuda:0'),)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grad_outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[142], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgrad_outputs\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grad_outputs' is not defined"
     ]
    }
   ],
   "source": [
    "grad_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transformer.transformer.h.1.attn.attention.k_proj.weight': tensor([[-0.0338, -0.0252,  0.0091,  ...,  0.0099,  0.0139, -0.0032],\n",
       "         [ 0.0175, -0.0406, -0.0315,  ...,  0.0334,  0.0150,  0.0046],\n",
       "         [-0.0164,  0.0018,  0.0066,  ...,  0.0130,  0.0117,  0.0334],\n",
       "         ...,\n",
       "         [-0.0261,  0.0261,  0.0139,  ..., -0.0219,  0.0126,  0.0231],\n",
       "         [ 0.0158, -0.0214,  0.0439,  ...,  0.0158,  0.0313,  0.0215],\n",
       "         [ 0.0038,  0.0075,  0.0423,  ..., -0.0036, -0.0116, -0.0154]],\n",
       "        device='cuda:0'),\n",
       " 'transformer.transformer.h.1.attn.attention.v_proj.weight': tensor([[ 0.0049, -0.0012, -0.0045,  ..., -0.0457,  0.0095,  0.0121],\n",
       "         [ 0.0028, -0.0384, -0.0097,  ..., -0.0223,  0.0069,  0.0175],\n",
       "         [ 0.0010,  0.0099,  0.0175,  ...,  0.0185, -0.0076,  0.0357],\n",
       "         ...,\n",
       "         [ 0.0132,  0.0298, -0.0010,  ...,  0.0012,  0.0392,  0.0103],\n",
       "         [ 0.0092,  0.0058, -0.0124,  ...,  0.0094, -0.0018,  0.0116],\n",
       "         [-0.0058, -0.0104, -0.0081,  ..., -0.0318,  0.0119, -0.0131]],\n",
       "        device='cuda:0'),\n",
       " 'transformer.transformer.h.1.attn.attention.q_proj.weight': tensor([[ 0.0073, -0.0450,  0.0068,  ...,  0.0229, -0.0538, -0.0583],\n",
       "         [ 0.0122, -0.0206, -0.0267,  ..., -0.0203,  0.0569,  0.0058],\n",
       "         [ 0.0378,  0.0394,  0.0089,  ...,  0.0348, -0.0683, -0.0318],\n",
       "         ...,\n",
       "         [-0.0571,  0.0066, -0.0309,  ..., -0.0460, -0.0227,  0.0096],\n",
       "         [-0.0004, -0.0398, -0.0272,  ..., -0.0053,  0.0025,  0.0489],\n",
       "         [ 0.0009, -0.0186, -0.0473,  ..., -0.0098, -0.0153, -0.0383]],\n",
       "        device='cuda:0')}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)  \u001b[38;5;66;03m# Batch size 8\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Iterate through the DataLoader\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_ids, attention_mask \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(input_ids\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# (batch_size, max_length)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Just to show the first batch\u001b[39;00m\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:32\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m         data\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_iter\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 23\u001b[0m, in \u001b[0;36mTinyStoriesIterableDataset.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset:\n\u001b[1;32m     22\u001b[0m     story \u001b[38;5;241m=\u001b[39m example[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# TinyStories dataset has a 'text' column\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     tokenized \u001b[38;5;241m=\u001b[39m \u001b[43mtokenize_and_concatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_bos_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m tokenized\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/transformer_lens/utils.py:316\u001b[0m, in \u001b[0;36mtokenize_and_concatenate\u001b[0;34m(dataset, tokenizer, streaming, max_length, column_name, add_bos_token, num_proc)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtokenize_and_concatenate\u001b[39m(\n\u001b[1;32m    293\u001b[0m     dataset: Dataset,\n\u001b[1;32m    294\u001b[0m     tokenizer: AutoTokenizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    299\u001b[0m     num_proc: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m    300\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dataset:\n\u001b[1;32m    301\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Helper function to tokenizer and concatenate a dataset of text. This converts the text to tokens, concatenates them (separated by EOS tokens) and then reshapes them into a 2D array of shape (____, sequence_length), dropping the last batch. Tokenizers are much faster if parallelised, so we chop the string into 20, feed it into the tokenizer, in parallel with padding, then remove padding at the end.\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \n\u001b[1;32m    303\u001b[0m \u001b[38;5;124;03m    This tokenization is useful for training language models, as it allows us to efficiently train on a large corpus of text of varying lengths (without, eg, a lot of truncation or padding). Further, for models with absolute positional encodings, this avoids privileging early tokens (eg, news articles often begin with CNN, and models may learn to use early positional encodings to predict these)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m        Dataset: Returns the tokenized dataset, as a dataset of tensors, with a single column called \"tokens\"\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mkeep_single_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;66;03m# We add a padding token, purely to implement the tokenizer. This will be removed before inputting tokens to the model, so we do not need to increment d_vocab in the model.\u001b[39;00m\n\u001b[1;32m    319\u001b[0m         tokenizer\u001b[38;5;241m.\u001b[39madd_special_tokens({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpad_token\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<PAD>\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/transformer_lens/utils.py:286\u001b[0m, in \u001b[0;36mkeep_single_column\u001b[0;34m(dataset, col_name)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mkeep_single_column\u001b[39m(dataset: Dataset, col_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    283\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03m    Acts on a HuggingFace dataset to delete all columns apart from a single column name - useful when we want to tokenize and mix together different strings\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 286\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m:\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m col_name:\n\u001b[1;32m    288\u001b[0m             dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mremove_columns(key)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'features'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the dataset in streaming mode\n",
    "dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train\", streaming=True)\n",
    "\n",
    "# Initialize a tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")  # Replace with your model\n",
    "from transformer_lens.utils import tokenize_and_concatenate\n",
    "\n",
    "\n",
    "class TinyStoriesIterableDataset(IterableDataset):\n",
    "    def __init__(self, dataset, tokenizer, max_length=512):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __iter__(self):\n",
    "        for example in self.dataset:\n",
    "            story = example[\"text\"]  # TinyStories dataset has a 'text' column\n",
    "            tokenized = tokenize_and_concatenate(story, self.tokenizer, max_length=self.max_length, add_bos_token=False)['tokens']\n",
    "            yield tokenized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853a8a5f8b454ae5aa0e5929ac91a47b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84791726f7444e1bed0821e5c88c17a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb6f72aea634fa98fa8dbdf182429ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5ea2ed78b74eb398ae9c7021751d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1795 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 8, 'text': \"Delta may be known for its quiet streets and safe neighborhoods, but that's not an excuse for dismissing your auto insurance coverage. Whether your top priority is saving on your monthly expenses, creating stronger liability protections, or celebrating each year of safe driving with our Vanishing DeductibleÂ® program, Nationwide has what you're looking for. And if you're not sure what you're looking for, then talk to one of our Delta auto insurance agents about the right policy for you and your vehicle(s).\\nNo matter what style of home you own in Delta, home insurance offers essential protection against a range of hazards. it's not just the dwelling, either. Nationwide also provides coverage for your belongings and liability concerns. Talk to one of our Delta home insurance agents about the different types of coverage that make sense for your homeowners policy.\\nWe all worry about what will happen to our loved ones if something should happen to us. that's why every Nationwide life insurance policy includes coverage for the worst-case scenario. Personalized coverage options help our Delta life insurance agents serve younger families as well as those who are already enjoying their retirement. Some of our local Delta customers want help choosing the right type of policy for them. Others are interested in adding Nationwide coverage for long-term care costs. If you've already done your research, we have an easy-to-use tool to find a quote. Otherwise, talk to an agent near you today.\\nEven businesses that aren't on the Fortune 500 list have plenty of property and assets to protect.. Talk to one of our Delta business insurance agents about partnering with Nationwide to better manage your company's risk.\", 'input_ids': [101, 7160, 2089, 2022, 2124, 2005, 2049, 4251, 4534, 1998, 3647, 11681, 1010, 2021, 2008, 1005, 1055, 2025, 2019, 8016, 2005, 28913, 2115, 8285, 5427, 6325, 1012, 3251, 2115, 2327, 9470, 2003, 7494, 2006, 2115, 7058, 11727, 1010, 4526, 6428, 14000, 28548, 1010, 2030, 12964, 2169, 2095, 1997, 3647, 4439, 2007, 2256, 24866, 2139, 8566, 6593, 7028, 29656, 2565, 1010, 9053, 2038, 2054, 2017, 1005, 2128, 2559, 2005, 1012, 1998, 2065, 2017, 1005, 2128, 2025, 2469, 2054, 2017, 1005, 2128, 2559, 2005, 1010, 2059, 2831, 2000, 2028, 1997, 2256, 7160, 8285, 5427, 6074, 2055, 1996, 2157, 3343, 2005, 2017, 1998, 2115, 4316, 1006, 1055, 1007, 1012, 2053, 3043, 2054, 2806, 1997, 2188, 2017, 2219, 1999, 7160, 1010, 2188, 5427, 4107, 6827, 3860, 2114, 1037, 2846, 1997, 22010, 1012, 2009, 1005, 1055, 2025, 2074, 1996, 13160, 1010, 2593, 1012, 9053, 2036, 3640, 6325, 2005, 2115, 20033, 1998, 14000, 5936, 1012, 2831, 2000, 2028, 1997, 2256, 7160, 2188, 5427, 6074, 2055, 1996, 2367, 4127, 1997, 6325, 2008, 2191, 3168, 2005, 2115, 2188, 12384, 2545, 3343, 1012, 2057, 2035, 4737, 2055, 2054, 2097, 4148, 2000, 2256, 3866, 3924, 2065, 2242, 2323, 4148, 2000, 2149, 1012, 2008, 1005, 1055, 2339, 2296, 9053, 2166, 5427, 3343, 2950, 6325, 2005, 1996, 5409, 1011, 2553, 11967, 1012, 3167, 3550, 6325, 7047, 2393, 2256, 7160, 2166, 5427, 6074, 3710, 3920, 2945, 2004, 2092, 2004, 2216, 2040, 2024, 2525, 9107, 2037, 5075, 1012, 2070, 1997, 2256, 2334, 7160, 6304, 2215, 2393, 10549, 1996, 2157, 2828, 1997, 3343, 2005, 2068, 1012, 2500, 2024, 4699, 1999, 5815, 9053, 6325, 2005, 2146, 1011, 2744, 2729, 5366, 1012, 2065, 2017, 1005, 2310, 2525, 2589, 2115, 2470, 1010, 2057, 2031, 2019, 3733, 1011, 2000, 1011, 2224, 6994, 2000, 2424, 1037, 14686, 1012, 4728, 1010, 2831, 2000, 2019, 4005, 2379, 2017, 2651, 1012, 2130, 5661, 2008, 4995, 1005, 1056, 2006, 1996, 7280, 3156, 2862, 2031, 7564, 1997, 3200, 1998, 7045, 2000, 4047, 1012, 1012, 2831, 2000, 2028, 1997, 2256, 7160, 2449, 5427, 6074, 2055, 27001, 2007, 9053, 2000, 2488, 6133, 2115, 2194, 1005, 1055, 3891, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('oscar', \"unshuffled_deduplicated_en\", split='train', streaming=True)\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "shuffled_dataset = dataset.shuffle(buffer_size=100, seed=42)\n",
    "\n",
    "tokenized_dataset = shuffled_dataset.map(lambda x: tokenizer(x[\"text\"]), batched=True, batch_size=10)\n",
    "\n",
    "for b in iter(tokenized_dataset):\n",
    "    print(b)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDataset({\n",
       "    features: Unknown,\n",
       "    num_shards: 670\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "shuffled_dataset = dataset.shuffle(buffer_size=100, seed=42)\n",
    "\n",
    "tokenized_dataset = shuffled_dataset.map(lambda x: tokenizer(x[\"text\"]), batched=True, batch_size=10)\n",
    "\n",
    "for b in iter(tokenized_dataset):\n",
    "    print(b)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    print(next(iter(shuffled_dataset))['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remember to login to wandb!\n",
    "import sys\n",
    "import os \n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import copy \n",
    "import numpy as np\n",
    "import gc\n",
    "import itertools\n",
    "# Append module directory for imports\n",
    "parent_dir = os.path.expanduser('../eigenestimation/eigenestimation')\n",
    "\n",
    "from eigenestimation.evaluation.networks import DrawNeuralNetwork\n",
    "from eigenestimation.eigenmodel.eigenmodel import EigenModel\n",
    "from eigenestimation.utils.loss import MSELoss\n",
    "from eigenestimation.utils.uniform_models import ZeroOutput\n",
    "from eigenestimation.toy_models.data import GenerateTMSInputs\n",
    "from eigenestimation.toy_models.parallel_serial_network import CustomMLP\n",
    "from torch import Tensor\n",
    "import einops\n",
    "\n",
    "from eigenestimation.utils.loss import MSELoss, MSEVectorLoss, KLDivergenceFlattenOverTokensLoss\n",
    "\n",
    "\n",
    "import figure_names\n",
    "from datasets import load_dataset\n",
    "from transformer_lens.utils import tokenize_and_concatenate\n",
    "from torch.utils.data import DataLoader\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_path = \"/root/eigenestimation/outputs/top_tokens/tinystories-8M-X_data.pt\"\n",
    "attributions_path = \"/root/eigenestimation/outputs/top_tokens/tinystories-8M-circuit_attributions.pt\"\n",
    "eigenmodel_path = \"/root/eigenestimation/outputs/eigenmodels/tinystories-8M.pt\"\n",
    "X_data = torch.load(X_data_path)\n",
    "attributions = torch.load(attributions_path)\n",
    "eigenmodel = torch.load(eigenmodel_path)['model']\n",
    "tokenizer = eigenmodel.model.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----- circuit_idx: 0 activation: 0.448 -----\n",
      "\\newlineThe end --> 14.932\n",
      ". Everyone was so happy and the love --> 14.04\n",
      " scared. They do not know what to --> 13.848\n",
      ". Wanna --> 13.596\n",
      " said.  --> 13.409\n",
      "\n",
      "\n",
      "----- circuit_idx: 1 activation: 0.383 -----\n",
      "\\newlineThe end --> 18.447\n",
      ". Wanna --> 16.664\n",
      " not listening to his owner. The end --> 14.378\n",
      " join them. They had a lot of --> 13.888\n",
      " her house, feeling very fancy. From --> 12.416\n",
      "\n",
      "\n",
      "----- circuit_idx: 2 activation: 0.282 -----\n",
      ", and the two of --> 13.014\n",
      " lady. --> 11.312\n",
      " asked her what was --> 9.97\n",
      " together. --> 8.711\n",
      " okay. --> 8.151\n",
      "\n",
      "\n",
      "----- circuit_idx: 3 activation: 0.012 -----\n",
      " refuse them.Once upon --> 20.977\n",
      "\\newlineThe end.Once upon a time --> 19.115\n",
      " and fun!Once upon --> 18.295\n",
      " together.Once upon a time --> 17.409\n",
      " end.Once upon --> 16.752\n",
      "\n",
      "\n",
      "----- circuit_idx: 4 activation: 0.401 -----\n",
      " where he was going and tri --> 15.072\n",
      " scared. They do not know what to --> 13.886\n",
      " One day, Lily was very excited because --> 13.596\n",
      " the park clean and organized.Once upon --> 12.812\n",
      ". \"You are --> 12.806\n",
      "\n",
      "\n",
      "----- circuit_idx: 5 activation: 0.248 -----\n",
      " scared. They do not know what to --> 11.532\n",
      " that it fell down and could --> 8.64\n",
      " the hole. She feels something hard --> 8.152\n",
      " Lily's mitten on --> 8.036\n",
      " happy, but the dress itched a --> 7.91\n",
      "\n",
      "\n",
      "----- circuit_idx: 6 activation: 0.25 -----\n",
      ". Wanna --> 11.982\n",
      " very upset.\\newline\\newline --> 11.457\n",
      ", scared.\\newline\\newline --> 11.445\n",
      " down and asked for their help. \" --> 11.04\n",
      " with a bandage.\\newline\\newline --> 9.697\n",
      "\n",
      "\n",
      "----- circuit_idx: 7 activation: 0.419 -----\n",
      " down and asked for their help. \" --> 14.492\n",
      " not listening to his owner. The end --> 13.778\n",
      " time Lucy looked in --> 13.309\n",
      " scared. They do not know what to --> 12.22\n",
      " loved to help her mom in --> 11.915\n",
      "\n",
      "\n",
      "----- circuit_idx: 8 activation: 0.375 -----\n",
      ". Wanna --> 16.248\n",
      ". Kara watched from the top of --> 14.735\n",
      " but it didn't have --> 13.582\n",
      ".\"\\newline\\newlineBut Ben does --> 11.877\n",
      " said, Ã¢ --> 11.528\n",
      "\n",
      "\n",
      "----- circuit_idx: 9 activation: 0.294 -----\n",
      " He jumped in --> 9.693\n",
      " them in the to --> 8.957\n",
      ".\"\\newline\\newlineBut Ben does --> 8.829\n",
      ". She said they had to --> 8.159\n",
      "\\newline\\newlineJack was so happy! --> 7.965\n",
      "\n",
      "\n",
      "----- circuit_idx: 10 activation: 0.338 -----\n",
      " he followed the voice.  --> 12.632\n",
      ", he didn't make it --> 11.951\n",
      " pass over it easily.  --> 11.809\n",
      " where he was going and tri --> 11.496\n",
      " smile on his face.  --> 11.44\n",
      "\n",
      "\n",
      "----- circuit_idx: 11 activation: 0.272 -----\n",
      ". The kids couldn't believe  --> 16.707\n",
      " food and sometimes his toys. No --> 15.849\n",
      " paper. Alice got out --> 14.531\n",
      ". Kara watched from the top of --> 12.981\n",
      " a time --> 11.375\n",
      "\n",
      "\n",
      "----- circuit_idx: 12 activation: 0.0 -----\n",
      " loved to bake cakes and cookies with her --> 1.607\n",
      ". The kids couldn't believe  --> 1.596\n",
      ", there was a dog named Max. --> 1.59\n",
      " a little girl named Lily --> 1.413\n",
      " He helped her find her way back to --> 1.369\n",
      "\n",
      "\n",
      "----- circuit_idx: 13 activation: 0.315 -----\n",
      ".\"\\newline\\newlineBut Ben does --> 13.365\n",
      " loved to bake cakes and cookies with her --> 10.348\n",
      " her a big hug and a kiss on --> 9.81\n",
      " she loved it there. She couldn't --> 9.661\n",
      " there was a little boy named Timmy --> 9.426\n",
      "\n",
      "\n",
      "----- circuit_idx: 14 activation: 0.313 -----\n",
      " slippery, and they could see fish and --> 11.193\n",
      " who liked to play --> 9.615\n",
      " found some. R --> 9.434\n",
      " loved to bake cakes and cookies with her --> 9.086\n",
      " be in the back and no one --> 9.081\n",
      "\n",
      "\n",
      "----- circuit_idx: 15 activation: 0.0 -----\n",
      "\\newline\\newline\"Don't --> 1.666\n",
      "\\newline\\newline --> 1.497\n",
      ". Wanna --> 1.425\n",
      " Spot accidentally knocked over a be --> 1.396\n",
      "\\newline\\newline --> 1.377\n",
      "\n",
      "\n",
      "----- circuit_idx: 16 activation: 0.284 -----\n",
      " there was a little boy named --> 11.659\n",
      " friend. His name --> 10.712\n",
      " lady in the yard. He ran up --> 9.762\n",
      " time for Timmy to go --> 9.654\n",
      " a little boy named Timmy. --> 9.355\n",
      "\n",
      "\n",
      "----- circuit_idx: 17 activation: 0.396 -----\n",
      " the boy and said, \"Thanks for --> 13.866\n",
      " Anna and her other dolls to have a --> 13.117\n",
      " said, \"I love --> 12.75\n",
      " if they could go home, but --> 11.548\n",
      " disorganized and didn't know what --> 11.378\n",
      "\n",
      "\n",
      "----- circuit_idx: 18 activation: 0.42 -----\n",
      ". Wanna --> 16.785\n",
      " good to listen to the advice that others --> 14.724\n",
      " was a fun day for Lily! --> 13.377\n",
      " they had sweet dreams.Once upon a --> 12.873\n",
      " thing to do. Lily felt very bad --> 12.752\n",
      "\n",
      "\n",
      "----- circuit_idx: 19 activation: 0.0 -----\n",
      ". Kara watched from the top of --> 1.347\n",
      ", there was a boy named --> 1.342\n",
      " practice every day. Little by --> 1.196\n",
      "\\newlineThe end --> 1.176\n",
      "\\newlineAnna and Ben are very happy. --> 1.141\n",
      "\n",
      "\n",
      "----- circuit_idx: 20 activation: 0.4 -----\n",
      ". She said they had to --> 14.188\n",
      " down and asked for their help. \" --> 14.121\n",
      " asked her what was --> 13.815\n",
      ". Wanna --> 13.611\n",
      " in the journal.Once upon --> 13.079\n",
      "\n",
      "\n",
      "----- circuit_idx: 21 activation: 0.341 -----\n",
      ". Wanna --> 16.62\n",
      " was a man named --> 12.847\n",
      "\\newlineAnna and Ben are very --> 11.467\n",
      ". Kara watched from the top of --> 11.352\n",
      "\\newline\\newlineLily didn't know --> 10.534\n",
      "\n",
      "\n",
      "----- circuit_idx: 22 activation: 0.416 -----\n",
      " the back of --> 14.184\n",
      " hungry.  --> 13.763\n",
      " refuse them.Once upon --> 13.187\n",
      " where he was going and tri --> 13.122\n",
      " and Lily continued to run, --> 12.782\n",
      "\n",
      "\n",
      "----- circuit_idx: 23 activation: 0.328 -----\n",
      " face.Once upon --> 14.044\n",
      "\\newlineThe end.Once --> 13.841\n",
      " and fun!Once upon --> 13.26\n",
      ", and the two of --> 11.786\n",
      " now free.Once upon a time --> 11.415\n",
      "\n",
      "\n",
      "----- circuit_idx: 24 activation: 0.239 -----\n",
      " a picture of the pigeon to show my --> 9.747\n",
      " loved to help her mom in --> 9.43\n",
      " Lily picked up --> 9.223\n",
      " scared. They do not know what to --> 8.735\n",
      " the bread with the other sw --> 8.502\n",
      "\n",
      "\n",
      "----- circuit_idx: 25 activation: 0.487 -----\n",
      ", Lily learned to be kind with --> 16.569\n",
      " such a good --> 15.738\n",
      " cannot catch it. The ball goes faster --> 15.593\n",
      " lady in the yard. He ran up --> 15.526\n",
      " time, there was a little girl named --> 14.42\n",
      "\n",
      "\n",
      "----- circuit_idx: 26 activation: 0.067 -----\n",
      " with a bandage.\\newline\\newline --> 56.682\n",
      " create something together!\"\\newline\\newline --> 52.915\n",
      "'t hurt you.\"\\newline\\newline --> 50.594\n",
      " than you!\"\\newline\\newline --> 49.119\n",
      " dropping to the forest floor.\\newline\\newline --> 47.623\n",
      "\n",
      "\n",
      "----- circuit_idx: 27 activation: 0.263 -----\n",
      ". Wanna --> 13.918\n",
      "\\newline\\newlineAt first, it --> 11.906\n",
      ", there was a dog named Max. --> 9.078\n",
      " office, Lily saw a police --> 8.723\n",
      " were big and smelled --> 8.635\n",
      "\n",
      "\n",
      "----- circuit_idx: 28 activation: 0.042 -----\n",
      " now free.Once upon a time --> 43.301\n",
      " face.Once upon a time, --> 29.513\n",
      " special.Once upon a time --> 28.722\n",
      " day?\"Once upon a time, --> 27.46\n",
      " and fun!Once upon a time, --> 27.123\n",
      "\n",
      "\n",
      "----- circuit_idx: 29 activation: 0.238 -----\n",
      " where he was going and tri --> 11.365\n",
      " the bed and broke --> 11.096\n",
      ", he didn't make it --> 9.342\n",
      " loved to bake cakes and cookies with her --> 9.053\n",
      " She looked sad. \"Tom, can --> 8.851\n",
      "\n",
      "\n",
      "----- circuit_idx: 30 activation: 0.266 -----\n",
      "\\newline\\newlineHis owner, --> 11.416\n",
      " them in the to --> 10.054\n",
      " the bread with the other sw --> 9.647\n",
      " her over --> 9.53\n",
      ". But then the jugg --> 9.521\n",
      "\n",
      "\n",
      "----- circuit_idx: 31 activation: 0.356 -----\n",
      ". Wanna --> 22.839\n",
      " started moving again. They made it to --> 17.242\n",
      " little girl named Lily. --> 13.982\n",
      ", there was a dog named Max. --> 13.368\n",
      " a little girl named Lily. --> 12.511\n",
      "\n",
      "\n",
      "----- circuit_idx: 32 activation: 0.341 -----\n",
      " scared. They do not know what to --> 10.828\n",
      " Lily picked up --> 9.452\n",
      " good to listen to the advice that --> 9.424\n",
      " with. One day, Timmy's --> 9.208\n",
      " a time --> 9.033\n",
      "\n",
      "\n",
      "----- circuit_idx: 33 activation: 0.405 -----\n",
      ". Wanna --> 17.807\n",
      "'t mind. She played with --> 14.697\n",
      " Spot accidentally knocked over a be --> 14.452\n",
      " food. His mom was --> 13.678\n",
      " practice every day. Little by --> 13.051\n",
      "\n",
      "\n",
      "----- circuit_idx: 34 activation: 0.419 -----\n",
      ". Wanna --> 29.205\n",
      "\\newline\\newlineAt first, it --> 16.46\n",
      " While it was walking it --> 14.947\n",
      " down and asked for their help. \" --> 14.843\n",
      " go of the string. The kite --> 14.006\n",
      "\n",
      "\n",
      "----- circuit_idx: 35 activation: 0.444 -----\n",
      " scared. They do not know what to --> 13.489\n",
      " It was very sad  --> 13.347\n",
      ". \"Now I'm hungry and my --> 13.087\n",
      ", he didn --> 13.06\n",
      " He got up --> 12.671\n",
      "\n",
      "\n",
      "----- circuit_idx: 36 activation: 0.0 -----\n",
      "\\newline\\newline\"Mommy --> 0.135\n",
      "\\newline\\newline\"Leave me alone! --> 0.119\n",
      " called Lucy. She was 3 years old --> 0.101\n",
      "\\newline\"What is that cloud, Anna --> 0.097\n",
      " \"Don't worry about what Tim --> 0.095\n",
      "\n",
      "\n",
      "----- circuit_idx: 37 activation: 0.401 -----\n",
      ". The kids couldn't believe  --> 13.082\n",
      " scared. They do not know what to --> 12.976\n",
      ", \" --> 12.84\n",
      ", \" --> 11.549\n",
      " his might. This time --> 11.461\n",
      "\n",
      "\n",
      "----- circuit_idx: 38 activation: 0.277 -----\n",
      " saw the bunny and thought --> 11.182\n",
      "'t know what was --> 9.61\n",
      " the boy and said, \"Thanks for --> 9.231\n",
      ". He wished --> 8.378\n",
      " was a man named --> 8.336\n",
      "\n",
      "\n",
      "----- circuit_idx: 39 activation: 0.341 -----\n",
      ", there was a dog named --> 12.193\n",
      " black cat named --> 11.574\n",
      " time, there was a little girl named --> 11.485\n",
      " broke the mushroom! What if it was --> 10.579\n",
      " put some money in --> 10.106\n",
      "\n",
      "\n",
      "----- circuit_idx: 40 activation: 0.001 -----\n",
      ". She said they had to --> 2.162\n",
      "\\newline\"It's --> 1.989\n",
      ". She smiled to --> 1.948\n",
      "? Who's --> 1.852\n",
      "\\newlineThe end.Once --> 1.827\n",
      "\n",
      "\n",
      "----- circuit_idx: 41 activation: 0.412 -----\n",
      " asked.\\newline --> 23.024\n",
      " and the big truck.\"\\newline --> 22.898\n",
      " that she fell asleep quickly. \\newline --> 21.234\n",
      " it just right.\" \\newline --> 21.119\n",
      " motorcycles!\"\\newline\\newline --> 20.977\n",
      "\n",
      "\n",
      "----- circuit_idx: 42 activation: 0.41 -----\n",
      " where he was going and tri --> 18.05\n",
      " the bread with the other sw --> 15.827\n",
      "No, mom. I do --> 15.338\n",
      " scared. They do not know what to --> 14.241\n",
      " Lily lost her t --> 13.638\n",
      "\n",
      "\n",
      "----- circuit_idx: 43 activation: 0.226 -----\n",
      " now free.Once upon a time --> 11.017\n",
      " that it fell down and could not --> 8.637\n",
      " felt sorry for --> 8.546\n",
      " a little girl named --> 7.849\n",
      ". The kids couldn't believe  --> 7.752\n",
      "\n",
      "\n",
      "----- circuit_idx: 44 activation: 0.325 -----\n",
      "\\newlineThe end --> 11.306\n",
      " a few hours of hard --> 10.97\n",
      " to go on --> 10.715\n",
      " Lily's mitten on --> 10.05\n",
      " food and sometimes his toys. No --> 9.776\n",
      "\n",
      "\n",
      "----- circuit_idx: 45 activation: 0.417 -----\n",
      " a time --> 18.012\n",
      " was a man named --> 17.239\n",
      "! You should not --> 15.534\n",
      " now free.Once upon a time --> 15.496\n",
      " a little girl named Lily --> 15.267\n",
      "\n",
      "\n",
      "----- circuit_idx: 46 activation: 0.325 -----\n",
      " time, in a small village, --> 13.332\n",
      " to the train station, Tim's mom --> 10.728\n",
      " was envious of his older --> 10.624\n",
      " upon a time --> 10.463\n",
      "\\newline\\newline\"Don't --> 10.335\n",
      "\n",
      "\n",
      "----- circuit_idx: 47 activation: 0.328 -----\n",
      ". Wanna --> 11.941\n",
      ". But then the jugg --> 11.189\n",
      " he just --> 9.956\n",
      " loved to bake cakes and cookies with her --> 9.635\n",
      " her around. Everywhere L --> 9.585\n",
      "\n",
      "\n",
      "----- circuit_idx: 48 activation: 0.324 -----\n",
      "\\newline\\newlineLily didn't know what --> 14.038\n",
      " than you!\"\\newline\\newline\" --> 11.82\n",
      " if they could go home, but --> 11.691\n",
      "\\newline\\newlineThe judge noticed Lily and --> 11.566\n",
      " started moving again. They made it to --> 10.696\n",
      "\n",
      "\n",
      "----- circuit_idx: 49 activation: 0.0 -----\n",
      " the boy and said, \"Thanks for --> 1.531\n",
      " day, Lily went to the park --> 1.527\n",
      ", there was a dog named --> 1.459\n",
      " a little girl named Lily --> 1.406\n",
      " where he was going and tri --> 1.347\n",
      "\n",
      "\n",
      "----- circuit_idx: 50 activation: 0.276 -----\n",
      " scared. They do not know what to --> 9.966\n",
      ", he didn't make it --> 9.356\n",
      " where he was going and tri --> 9.199\n",
      "ter a while --> 8.934\n",
      " so excited that he said, \"L --> 8.903\n",
      "\n",
      "\n",
      "----- circuit_idx: 51 activation: 0.0 -----\n",
      " and it was very y --> 1.242\n",
      "\\newlineThe end --> 1.192\n",
      " that it fell down and could not get --> 1.186\n",
      "\\newline\\newlineLily didn't know what --> 1.164\n",
      ". Kara watched from the top of --> 1.153\n",
      "\n",
      "\n",
      "----- circuit_idx: 52 activation: 0.371 -----\n",
      ". Wanna --> 26.478\n",
      ". The two of them had a great --> 14.057\n",
      " He jumped in --> 13.984\n",
      " put some money in --> 13.318\n",
      " didn't see the dark hole in --> 12.843\n",
      "\n",
      "\n",
      "----- circuit_idx: 53 activation: 0.254 -----\n",
      " were so many furry animals! Rabb --> 9.889\n",
      " her over --> 9.785\n",
      "\\newline\\newlineAt --> 9.449\n",
      " practice every day. Little by --> 8.725\n",
      ", Lily learned to be kind with --> 8.599\n",
      "\n",
      "\n",
      "----- circuit_idx: 54 activation: 0.357 -----\n",
      "\\newline\\newline\"Don't --> 11.994\n",
      " upon a time --> 11.754\n",
      " the cat. But he was not --> 11.54\n",
      " daddy. One day, they went --> 10.738\n",
      " practice every day. Little by --> 10.656\n",
      "\n",
      "\n",
      "----- circuit_idx: 55 activation: 0.337 -----\n",
      " not listening to his owner. The end --> 16.583\n",
      "? Who's --> 11.084\n",
      " were big and smelled --> 10.899\n",
      " upon a time --> 10.87\n",
      " a time --> 10.792\n",
      "\n",
      "\n",
      "----- circuit_idx: 56 activation: 0.526 -----\n",
      ". Wanna --> 25.828\n",
      " \"Don't worry about what Tim --> 23.45\n",
      " said sorry. His friend forg --> 21.639\n",
      " the bread with the other sw --> 21.461\n",
      " take things that don't belong to --> 19.272\n",
      "\n",
      "\n",
      "----- circuit_idx: 57 activation: 0.0 -----\n",
      "\\newline\\newlineLily didn't know what --> 1.33\n",
      ". Wanna --> 1.305\n",
      "Look, Ben! --> 1.221\n",
      " didn't know it --> 1.216\n",
      " wonder!  --> 1.161\n",
      "\n",
      "\n",
      "----- circuit_idx: 58 activation: 0.457 -----\n",
      " where he was going and tri --> 16.556\n",
      ", and the two of --> 15.187\n",
      " scared. They do not know what to --> 14.988\n",
      " and a little scared.  --> 14.783\n",
      " it on a plate for Claire  --> 14.62\n",
      "\n",
      "\n",
      "----- circuit_idx: 59 activation: 0.315 -----\n",
      ". Wanna --> 17.471\n",
      " house. She picked up --> 10.216\n",
      " not listening to his owner. The end --> 9.42\n",
      " black cat named --> 9.284\n",
      ", there was --> 9.039\n",
      "\n",
      "\n",
      "----- circuit_idx: 60 activation: 0.263 -----\n",
      " said.  --> 10.861\n",
      "ily was sad that --> 9.859\n",
      "? Who's --> 9.601\n",
      " her over --> 9.153\n",
      "\\newline\"What is that cloud, Anna --> 8.902\n",
      "\n",
      "\n",
      "----- circuit_idx: 61 activation: 0.403 -----\n",
      " were so many furry animals! Rabb --> 15.203\n",
      ", there was a dog named --> 14.61\n",
      " a time --> 13.457\n",
      ". She said they had to --> 12.741\n",
      " upon a time --> 12.731\n",
      "\n",
      "\n",
      "----- circuit_idx: 62 activation: 0.0 -----\n",
      ". Wanna --> 2.723\n",
      "\\newline\\newlineLily didn't know what --> 1.868\n",
      " tree would nod its branches to --> 1.447\n",
      " started moving again. They made it to --> 1.422\n",
      " them in the to --> 1.392\n",
      "\n",
      "\n",
      "----- circuit_idx: 63 activation: 0.478 -----\n",
      " what was underneath. To Jack's --> 20.298\n",
      " food and licked her lips in --> 19.181\n",
      ". She said they had to --> 17.384\n",
      " They looked at Mom. They smiled --> 16.034\n",
      " down and asked for their help. \" --> 15.797\n",
      "\n",
      "\n",
      "----- circuit_idx: 64 activation: 0.325 -----\n",
      " She looked sad. \"Tom, can --> 11.753\n",
      " upon a time, there --> 9.996\n",
      "\\newline\\newline --> 9.945\n",
      "? Who's --> 9.578\n",
      " the bread with the other sw --> 9.569\n",
      "\n",
      "\n",
      "----- circuit_idx: 65 activation: 0.363 -----\n",
      ". Wanna --> 16.662\n",
      ", not knowing what --> 13.214\n",
      " He went to put on his --> 12.7\n",
      " food and licked her lips in --> 11.395\n",
      ", Lily learned to be kind with --> 11.159\n",
      "\n",
      "\n",
      "----- circuit_idx: 66 activation: 0.0 -----\n",
      " good to listen to the advice that --> 1.489\n",
      ". Kara watched from the top of --> 1.441\n",
      ". She reached out --> 1.43\n",
      " said, \"I love --> 1.369\n",
      ". The kids couldn't believe  --> 1.368\n",
      "\n",
      "\n",
      "----- circuit_idx: 67 activation: 0.411 -----\n",
      " time, in a small village, --> 25.036\n",
      " food and licked her lips in --> 14.916\n",
      "! You should not --> 13.872\n",
      ", and the two of --> 12.903\n",
      " time, there was a little girl named --> 12.755\n",
      "\n",
      "\n",
      "----- circuit_idx: 68 activation: 0.416 -----\n",
      " time, in a small village, --> 13.251\n",
      " toys.\\newline\\newline\"Bang, bang --> 13.232\n",
      ".\" \\newline\\newlineL --> 12.996\n",
      " but it didn't have --> 12.597\n",
      " thought of himself as a super hero --> 11.605\n",
      "\n",
      "\n",
      "----- circuit_idx: 69 activation: 0.435 -----\n",
      " the bread with the other sw --> 24.802\n",
      " he finally got the t --> 19.735\n",
      "? Who's this sw --> 13.918\n",
      " for a little boy like --> 13.889\n",
      " old t --> 12.349\n",
      "\n",
      "\n",
      "----- circuit_idx: 70 activation: 0.0 -----\n",
      ". The kids couldn't believe  --> 2.054\n",
      " a hug. Then he said,\" --> 1.455\n",
      ", \"Why are --> 1.407\n",
      " named Timmy --> 1.403\n",
      ". Wanna --> 1.381\n",
      "\n",
      "\n",
      "----- circuit_idx: 71 activation: 0.389 -----\n",
      " down and asked for their help. \" --> 14.518\n",
      " and Lily continued to run, --> 13.798\n",
      ". The kids couldn't believe  --> 12.986\n",
      " cold and sweet treats. Do you --> 11.037\n",
      " around and realized that she could take a --> 10.995\n",
      "\n",
      "\n",
      "----- circuit_idx: 72 activation: 0.296 -----\n",
      ". Wanna --> 11.838\n",
      " coming over to play. His friend, --> 9.472\n",
      ". But I won --> 9.033\n",
      ", Lily learned to be kind with her --> 8.655\n",
      " there was a little boy named --> 8.634\n",
      "\n",
      "\n",
      "----- circuit_idx: 73 activation: 0.263 -----\n",
      ". Wanna --> 14.308\n",
      ". \" --> 10.067\n",
      " could result in --> 9.226\n",
      " but it didn't have --> 9.003\n",
      ". He flipped through --> 8.731\n",
      "\n",
      "\n",
      "----- circuit_idx: 74 activation: 0.329 -----\n",
      " where he was going and tri --> 13.815\n",
      " dinner - why don't --> 12.623\n",
      ". Maybe she will be happy if I --> 12.037\n",
      " not listening to his owner. The end --> 11.755\n",
      ". The two of --> 10.658\n",
      "\n",
      "\n",
      "----- circuit_idx: 75 activation: 0.466 -----\n",
      ". Wanna --> 16.688\n",
      ". She said they had to --> 16.585\n",
      " little girl named Lily. --> 16.447\n",
      " a little girl named Lily. --> 15.751\n",
      " job. He did not know --> 14.327\n",
      "\n",
      "\n",
      "----- circuit_idx: 76 activation: 0.487 -----\n",
      " he followed the voice.  --> 20.412\n",
      " dropping to the forest floor.\\newline\\newline --> 19.021\n",
      "'t hurt you.\"\\newline\\newline --> 17.319\n",
      " and a little scared.  --> 17.01\n",
      " with a bandage.\\newline\\newline --> 16.633\n",
      "\n",
      "\n",
      "----- circuit_idx: 77 activation: 0.351 -----\n",
      " around and realized that she could take --> 14.652\n",
      "! You should not --> 13.4\n",
      " for being so --> 12.287\n",
      " playing in the garden. They liked --> 12.23\n",
      " scared. They do --> 11.757\n",
      "\n",
      "\n",
      "----- circuit_idx: 78 activation: 0.434 -----\n",
      ". Wanna --> 18.559\n",
      ". Kara watched from the top of --> 14.281\n",
      " Spot accidentally knocked over a be --> 13.82\n",
      " became alert. It was a big cat --> 13.668\n",
      " They looked at Mom. They --> 13.117\n",
      "\n",
      "\n",
      "----- circuit_idx: 79 activation: 0.275 -----\n",
      ". Kara watched from the top of --> 8.956\n",
      ". The kids couldn't believe  --> 8.389\n",
      ", \"I am collecting rocks for --> 7.783\n",
      ". \"You are a good --> 7.735\n",
      " the cat. But he was not --> 7.701\n",
      "\n",
      "\n",
      "----- circuit_idx: 80 activation: 0.328 -----\n",
      ". Wanna --> 18.358\n",
      ". She said they had to --> 10.059\n",
      " play in. Lily was so --> 9.931\n",
      " a picture of the pigeon to show my --> 9.924\n",
      " cold and sweet treats. Do --> 9.595\n",
      "\n",
      "\n",
      "----- circuit_idx: 81 activation: 0.0 -----\n",
      " a time --> 1.621\n",
      "\\newlineAnna and Ben are very --> 1.425\n",
      ". She said they had to --> 1.422\n",
      " lady in the yard. He ran up --> 1.351\n",
      ", there --> 1.346\n",
      "\n",
      "\n",
      "----- circuit_idx: 82 activation: 0.359 -----\n",
      " but it didn't --> 15.349\n",
      " she loved her toast. She didn't --> 13.174\n",
      ", \" --> 13.004\n",
      ", there was a dog named Max. --> 11.508\n",
      " job. He did --> 11.395\n",
      "\n",
      "\n",
      "----- circuit_idx: 83 activation: 0.463 -----\n",
      " but it didn't have --> 22.294\n",
      ". Wanna --> 21.209\n",
      " now free.Once upon a time --> 20.215\n",
      " Lucy, you can. But don't --> 19.472\n",
      " named Max. He wanted to go on --> 15.776\n",
      "\n",
      "\n",
      "----- circuit_idx: 84 activation: 0.443 -----\n",
      " a time --> 15.6\n",
      "\\newline\\newlineLily didn't know what --> 14.932\n",
      " a time --> 14.874\n",
      " that it fell down and could not get --> 14.671\n",
      " nice and tight. He lay --> 13.033\n",
      "\n",
      "\n",
      "----- circuit_idx: 85 activation: 0.263 -----\n",
      " of alarm that none of --> 13.342\n",
      ". Kara watched from the top of --> 13.073\n",
      ". Wanna --> 11.197\n",
      ". She was only --> 9.51\n",
      " nicely, but still she wouldn --> 9.293\n",
      "\n",
      "\n",
      "----- circuit_idx: 86 activation: 0.413 -----\n",
      "\\newline\\newlineLily didn't know what --> 15.923\n",
      " started moving again. They made it to --> 14.75\n",
      "ig. He picked it up --> 13.464\n",
      " good things come to those --> 13.312\n",
      "\\newline\\newline\"Don't --> 12.783\n",
      "\n",
      "\n",
      "----- circuit_idx: 87 activation: 0.489 -----\n",
      ". Wanna --> 25.321\n",
      " not listening to his owner. The end --> 22.124\n",
      " she loved it there. She couldn't --> 19.018\n",
      "\\newline\\newline\"Leave me alone! --> 17.002\n",
      " and tease the puppy again. It's --> 16.632\n",
      "\n",
      "\n",
      "----- circuit_idx: 88 activation: 0.391 -----\n",
      ". The kids couldn't believe  --> 16.516\n",
      "ny day, they decided to go on --> 14.548\n",
      ". Wanna --> 14.09\n",
      ". She said they had to --> 13.127\n",
      " it smelled so sweet --> 12.719\n",
      "\n",
      "\n",
      "----- circuit_idx: 89 activation: 0.42 -----\n",
      ". Wanna --> 22.366\n",
      " was playing with his cards when his sister --> 15.087\n",
      " in the journal.Once upon --> 15.022\n",
      "  --> 13.988\n",
      " his happiness with them again.Once upon --> 13.629\n",
      "\n",
      "\n",
      "----- circuit_idx: 90 activation: 0.284 -----\n",
      ". Wanna --> 18.315\n",
      ", and the two of --> 10.81\n",
      " of melted butter. It dri --> 10.76\n",
      ". The kids couldn't believe  --> 10.205\n",
      " all the creatures that cal --> 10.093\n",
      "\n",
      "\n",
      "----- circuit_idx: 91 activation: 0.421 -----\n",
      ". Wanna --> 16.504\n",
      " and fun!Once upon --> 15.328\n",
      " time, there was a little girl named --> 14.761\n",
      " together.Once upon --> 13.736\n",
      "\\newlineAnna and Ben are very --> 13.655\n",
      "\n",
      "\n",
      "----- circuit_idx: 92 activation: 0.369 -----\n",
      ", and the two of --> 14.436\n",
      " she would tell them what --> 12.388\n",
      " were proud of what --> 11.112\n",
      ". They had a fun escape in --> 10.892\n",
      " the onions. They --> 10.639\n",
      "\n",
      "\n",
      "----- circuit_idx: 93 activation: 0.281 -----\n",
      " not listening to his owner. The end --> 11.074\n",
      ". She said they had --> 9.727\n",
      " too late. The car hit them both --> 9.181\n",
      " story is to be patient and wait for --> 8.897\n",
      " could result in --> 8.794\n",
      "\n",
      "\n",
      "----- circuit_idx: 94 activation: 0.244 -----\n",
      ", there was a dog named --> 10.123\n",
      ". Wanna --> 9.029\n",
      " where he was going and tri --> 8.428\n",
      " there was a little girl named --> 8.164\n",
      ", not knowing what the next step --> 8.162\n",
      "\n",
      "\n",
      "----- circuit_idx: 95 activation: 0.367 -----\n",
      " said.  --> 12.842\n",
      ". The kids couldn't believe  --> 10.861\n",
      " started moving again. They made it --> 10.775\n",
      ", \"I am collecting rocks for --> 10.598\n",
      "\\newlineThe end.Once upon --> 10.553\n",
      "\n",
      "\n",
      "----- circuit_idx: 96 activation: 0.313 -----\n",
      " was a pro --> 11.856\n",
      ".\"\\newline\\newlineBut Ben does --> 11.814\n",
      " where he was going and tri --> 11.06\n",
      " princess and prince lived in --> 10.367\n",
      " and saw the leaves. \" --> 9.813\n",
      "\n",
      "\n",
      "----- circuit_idx: 97 activation: 0.338 -----\n",
      ", and the two of --> 13.037\n",
      " He jumped in puddles a --> 11.485\n",
      "Look, Ben! I --> 11.066\n",
      " a little boy named Timmy. --> 11.057\n",
      " named Timmy. Timmy had --> 10.804\n",
      "\n",
      "\n",
      "----- circuit_idx: 98 activation: 0.256 -----\n",
      " scared. They do not know what to --> 12.618\n",
      " put some money in --> 9.87\n",
      "His friend was impressed and they spent --> 9.739\n",
      " but it didn't have --> 8.704\n",
      ", \"Why are --> 8.567\n",
      "\n",
      "\n",
      "----- circuit_idx: 99 activation: 0.0 -----\n",
      " she loved it there. She couldn't --> 1.689\n",
      ". Wanna --> 1.599\n",
      " He jumped in --> 1.49\n",
      ". It is mom. She --> 1.39\n",
      ", not knowing what --> 1.359\n"
     ]
    }
   ],
   "source": [
    "circuit_idxs = range(len(attributions))\n",
    "for circuit_idx in circuit_idxs:\n",
    "    print('\\n\\n----- circuit_idx:', circuit_idx, 'activation:', attributions[circuit_idx]['activation'], '-----')\n",
    "    for example in attributions[circuit_idx]['top_examples']:\n",
    "        tokens = (X_data[example['sample_id']][:example['token_id']+1])\n",
    "        text = tokenizer.decode(tokens.long())\n",
    "        print(text.replace('\\n', '\\\\newline'), '-->', example['value'])\n",
    "#del X_data\n",
    "#del attributions\n",
    "#gc.collect()\n",
    "#torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m eigenmodel \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mload(eigenmodel_path)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenmodel.low_rank_encode['transformer.transformer.h.1.attn.attention.k_proj.weight'][0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_data_path\n",
    "\n",
    "\n",
    "# Load tinystories data\n",
    "token_length = 16\n",
    "dataset = load_dataset('roneneldan/TinyStories', split=\"validation[:1%]\")\n",
    "X_train = tokenize_and_concatenate(dataset, tokenizer, max_length = token_length, add_bos_token=False)['tokens']\n",
    "# Permute\n",
    "X_transformer = X_train[torch.randperm(len(X_train)), :][:1000]\n",
    "del X_train\n",
    "del dataset\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "circuit_vals = []\n",
    "X_ordered = []\n",
    "iters = 10\n",
    "n_subnetworks = eigenmodel.n_features\n",
    "dataloader = DataLoader(X_transformer[:1000].to('cuda'), batch_size=8, shuffle=True)\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch in :\n",
    "        X_ordered.append(X_batch)\n",
    "        # Compute gradients many times and take the average\n",
    "        each_circuit_val = torch.zeros(X_batch.shape[0]*X_batch.shape[1], n_subnetworks).to('cuda')\n",
    "        for _ in range(iters):\n",
    "            grads = eigenmodel.compute_gradients(X_batch)\n",
    "            each_circuit_val = each_circuit_val + abs(eigenmodel(grads))[:,:n_subnetworks]\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        circuit_vals.append(each_circuit_val.view(X_batch.shape[0], X_batch.shape[1], n_subnetworks))\n",
    "    circuit_vals = torch.concat(circuit_vals, dim=0)/iters\n",
    "    X_ordered = torch.concat(X_ordered, dim=0)\n",
    "    \n",
    "\n",
    "for i in circuit_vals.mean(dim=[0,1]).argsort(descending=True):\n",
    "    if frac_activated[i] < .005:\n",
    "        continue\n",
    "    if frac_activated[i] > .5:\n",
    "        continue\n",
    "    \n",
    "    # Get the absolute values for feature i\n",
    "    abs_vals = (circuit_vals[..., i])\n",
    "\n",
    "    # Find the top 5 (b, t) indices for feature i\n",
    "    top_indices = abs(abs_vals).flatten().argsort(descending=True)\n",
    "    \n",
    "    # Convert the flat indices back to (b, t) indices\n",
    "    top_b, top_t = torch.div(top_indices, token_length, rounding_mode='floor'), top_indices % token_length\n",
    "\n",
    "    # Get the corresponding top values\n",
    "    top_values = abs_vals[top_b, top_t]\n",
    "\n",
    "    print(f'\\n\\n---- Feature {i} ---- Activation: {frac_activated[i]:.3f}')\n",
    "    sample_idxs_so_far = []\n",
    "    for j in range(len(top_indices)):\n",
    "        if top_b[j].item() in sample_idxs_so_far:\n",
    "            continue\n",
    "        if len(sample_idxs_so_far) >= 5:\n",
    "            break\n",
    "        sample_idxs_so_far.append(top_b[j].item())\n",
    "        sample_idx = top_b[j].item()\n",
    "        token_idx = top_t[j].item()\n",
    "        tokens = X_ordered[sample_idx]\n",
    "        tokens = tokens[:(token_idx+1)]\n",
    "        sentence = tokenizer.decode(tokens.long())\n",
    "        sentence = sentence.replace('\\n', '=newline=')\n",
    "        print(sentence, '-->', f'{top_values[j].item():.2f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remember to login to wandb!\n",
    "import sys\n",
    "import os \n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import copy \n",
    "import numpy as np\n",
    "import gc\n",
    "import itertools\n",
    "# Append module directory for imports\n",
    "parent_dir = os.path.expanduser('../eigenestimation/eigenestimation')\n",
    "\n",
    "from eigenestimation.evaluation.networks import DrawNeuralNetwork\n",
    "from eigenestimation.eigenmodel.eigenmodel import EigenModel\n",
    "from eigenestimation.utils.loss import MSELoss\n",
    "from eigenestimation.utils.uniform_models import ZeroOutput\n",
    "from eigenestimation.toy_models.data import GenerateTMSInputs\n",
    "from eigenestimation.toy_models.parallel_serial_network import CustomMLP\n",
    "from torch import Tensor\n",
    "import einops\n",
    "\n",
    "from eigenestimation.utils.loss import MSELoss, MSEVectorLoss, KLDivergenceFlattenOverTokensLoss\n",
    "\n",
    "\n",
    "import figure_names\n",
    "from datasets import load_dataset\n",
    "from transformer_lens.utils import tokenize_and_concatenate\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "eigenmodel_path = f\"../outputs/eigenmodels/tinystories-8M.pt\"\n",
    "eigenmodel = torch.load(eigenmodel_path)['model']\n",
    "tokenizer = eigenmodel.model.tokenizer\n",
    "frac_activated = torch.load(eigenmodel_path)['frac_activated']\n",
    "\n",
    "\n",
    "# Load tinystories data\n",
    "token_length = 16\n",
    "dataset = load_dataset('roneneldan/TinyStories', split=\"validation[:1%]\")\n",
    "X_train = tokenize_and_concatenate(dataset, tokenizer, max_length = token_length, add_bos_token=False)['tokens']\n",
    "# Permute\n",
    "X_transformer = X_train[torch.randperm(len(X_train)), :][:1000]\n",
    "del X_train\n",
    "del dataset\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "circuit_vals = []\n",
    "X_ordered = []\n",
    "iters = 10\n",
    "n_subnetworks = eigenmodel.n_features\n",
    "dataloader = DataLoader(X_transformer[:1000].to('cuda'), batch_size=8, shuffle=True)\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch in :\n",
    "        X_ordered.append(X_batch)\n",
    "        # Compute gradients many times and take the average\n",
    "        each_circuit_val = torch.zeros(X_batch.shape[0]*X_batch.shape[1], n_subnetworks).to('cuda')\n",
    "        for _ in range(iters):\n",
    "            grads = eigenmodel.compute_gradients(X_batch)\n",
    "            each_circuit_val = each_circuit_val + abs(eigenmodel(grads))[:,:n_subnetworks]\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        circuit_vals.append(each_circuit_val.view(X_batch.shape[0], X_batch.shape[1], n_subnetworks))\n",
    "    circuit_vals = torch.concat(circuit_vals, dim=0)/iters\n",
    "    X_ordered = torch.concat(X_ordered, dim=0)\n",
    "    \n",
    "\n",
    "for i in circuit_vals.mean(dim=[0,1]).argsort(descending=True):\n",
    "    if frac_activated[i] < .005:\n",
    "        continue\n",
    "    if frac_activated[i] > .5:\n",
    "        continue\n",
    "    \n",
    "    # Get the absolute values for feature i\n",
    "    abs_vals = (circuit_vals[..., i])\n",
    "\n",
    "    # Find the top 5 (b, t) indices for feature i\n",
    "    top_indices = abs(abs_vals).flatten().argsort(descending=True)\n",
    "    \n",
    "    # Convert the flat indices back to (b, t) indices\n",
    "    top_b, top_t = torch.div(top_indices, token_length, rounding_mode='floor'), top_indices % token_length\n",
    "\n",
    "    # Get the corresponding top values\n",
    "    top_values = abs_vals[top_b, top_t]\n",
    "\n",
    "    print(f'\\n\\n---- Feature {i} ---- Activation: {frac_activated[i]:.3f}')\n",
    "    sample_idxs_so_far = []\n",
    "    for j in range(len(top_indices)):\n",
    "        if top_b[j].item() in sample_idxs_so_far:\n",
    "            continue\n",
    "        if len(sample_idxs_so_far) >= 5:\n",
    "            break\n",
    "        sample_idxs_so_far.append(top_b[j].item())\n",
    "        sample_idx = top_b[j].item()\n",
    "        token_idx = top_t[j].item()\n",
    "        tokens = X_ordered[sample_idx]\n",
    "        tokens = tokens[:(token_idx+1)]\n",
    "        sentence = tokenizer.decode(tokens.long())\n",
    "        sentence = sentence.replace('\\n', '=newline=')\n",
    "        print(sentence, '-->', f'{top_values[j].item():.2f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenmodel_path = f\"../outputs/eigenmodels/tinystories-8M.pt\"\n",
    "eigenmodel = torch.load(eigenmodel_path)['model']\n",
    "tokenizer = eigenmodel.model.tokenizer\n",
    "frac_activated = torch.load(eigenmodel_path)['frac_activated']\n",
    "\n",
    "\n",
    "# Load tinystories data\n",
    "token_length = 16\n",
    "dataset = load_dataset('roneneldan/TinyStories', split=\"validation[:1%]\")\n",
    "X_train = tokenize_and_concatenate(dataset, tokenizer, max_length = token_length, add_bos_token=False)['tokens']\n",
    "# Permute\n",
    "X_transformer = X_train[torch.randperm(len(X_train)), :][:1000]\n",
    "del X_train\n",
    "del dataset\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "circuit_vals = []\n",
    "X_ordered = []\n",
    "iters = 10\n",
    "n_subnetworks = eigenmodel.n_features\n",
    "dataloader = DataLoader(X_transformer[:1000].to('cuda'), batch_size=8, shuffle=True)\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch in :\n",
    "        X_ordered.append(X_batch)\n",
    "        # Compute gradients many times and take the average\n",
    "        each_circuit_val = torch.zeros(X_batch.shape[0]*X_batch.shape[1], n_subnetworks).to('cuda')\n",
    "        for _ in range(iters):\n",
    "            grads = eigenmodel.compute_gradients(X_batch)\n",
    "            each_circuit_val = each_circuit_val + abs(eigenmodel(grads))[:,:n_subnetworks]\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        circuit_vals.append(each_circuit_val.view(X_batch.shape[0], X_batch.shape[1], n_subnetworks))\n",
    "    circuit_vals = torch.concat(circuit_vals, dim=0)/iters\n",
    "    X_ordered = torch.concat(X_ordered, dim=0)\n",
    "    \n",
    "\n",
    "for i in circuit_vals.mean(dim=[0,1]).argsort(descending=True):\n",
    "    if frac_activated[i] < .005:\n",
    "        continue\n",
    "    if frac_activated[i] > .5:\n",
    "        continue\n",
    "    \n",
    "    # Get the absolute values for feature i\n",
    "    abs_vals = (circuit_vals[..., i])\n",
    "\n",
    "    # Find the top 5 (b, t) indices for feature i\n",
    "    top_indices = abs(abs_vals).flatten().argsort(descending=True)\n",
    "    \n",
    "    # Convert the flat indices back to (b, t) indices\n",
    "    top_b, top_t = torch.div(top_indices, token_length, rounding_mode='floor'), top_indices % token_length\n",
    "\n",
    "    # Get the corresponding top values\n",
    "    top_values = abs_vals[top_b, top_t]\n",
    "\n",
    "    print(f'\\n\\n---- Feature {i} ---- Activation: {frac_activated[i]:.3f}')\n",
    "    sample_idxs_so_far = []\n",
    "    for j in range(len(top_indices)):\n",
    "        if top_b[j].item() in sample_idxs_so_far:\n",
    "            continue\n",
    "        if len(sample_idxs_so_far) >= 5:\n",
    "            break\n",
    "        sample_idxs_so_far.append(top_b[j].item())\n",
    "        sample_idx = top_b[j].item()\n",
    "        token_idx = top_t[j].item()\n",
    "        tokens = X_ordered[sample_idx]\n",
    "        tokens = tokens[:(token_idx+1)]\n",
    "        sentence = tokenizer.decode(tokens.long())\n",
    "        sentence = sentence.replace('\\n', '=newline=')\n",
    "        print(sentence, '-->', f'{top_values[j].item():.2f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3, 2))\n",
    "plt.hist(frac_activated.detach().cpu().numpy(), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in eigenmodel.low_rank_decode.values(): \n",
    "    for ii in i: \n",
    "        ii.requires_grad_(False)\n",
    "for i in eigenmodel.low_rank_encode.values(): \n",
    "    for ii in i: \n",
    "        ii.requires_grad_(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tinystories data\n",
    "token_length = 16\n",
    "dataset = load_dataset('roneneldan/TinyStories', split=\"validation[:1%]\")\n",
    "X_train = tokenize_and_concatenate(dataset, tokenizer, max_length = token_length, add_bos_token=False)['tokens']\n",
    "# Permute\n",
    "X_transformer = X_train[torch.randperm(len(X_train)), :][:1000]\n",
    "del X_train\n",
    "del dataset\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "circuit_vals = []\n",
    "X_ordered = []\n",
    "iters = 10\n",
    "n_subnetworks = eigenmodel.n_features\n",
    "dataloader = DataLoader(X_transformer[:1000].to('cuda'), batch_size=8, shuffle=True)\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch in :\n",
    "        X_ordered.append(X_batch)\n",
    "        # Compute gradients many times and take the average\n",
    "        each_circuit_val = torch.zeros(X_batch.shape[0]*X_batch.shape[1], n_subnetworks).to('cuda')\n",
    "        for _ in range(iters):\n",
    "            grads = eigenmodel.compute_gradients(X_batch)\n",
    "            each_circuit_val = each_circuit_val + abs(eigenmodel(grads))[:,:n_subnetworks]\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        circuit_vals.append(each_circuit_val.view(X_batch.shape[0], X_batch.shape[1], n_subnetworks))\n",
    "    circuit_vals = torch.concat(circuit_vals, dim=0)/iters\n",
    "    X_ordered = torch.concat(X_ordered, dim=0)\n",
    "    \n",
    "\n",
    "for i in circuit_vals.mean(dim=[0,1]).argsort(descending=True):\n",
    "    if frac_activated[i] < .005:\n",
    "        continue\n",
    "    if frac_activated[i] > .5:\n",
    "        continue\n",
    "    \n",
    "    # Get the absolute values for feature i\n",
    "    abs_vals = (circuit_vals[..., i])\n",
    "\n",
    "    # Find the top 5 (b, t) indices for feature i\n",
    "    top_indices = abs(abs_vals).flatten().argsort(descending=True)\n",
    "    \n",
    "    # Convert the flat indices back to (b, t) indices\n",
    "    top_b, top_t = torch.div(top_indices, token_length, rounding_mode='floor'), top_indices % token_length\n",
    "\n",
    "    # Get the corresponding top values\n",
    "    top_values = abs_vals[top_b, top_t]\n",
    "\n",
    "    print(f'\\n\\n---- Feature {i} ---- Activation: {frac_activated[i]:.3f}')\n",
    "    sample_idxs_so_far = []\n",
    "    for j in range(len(top_indices)):\n",
    "        if top_b[j].item() in sample_idxs_so_far:\n",
    "            continue\n",
    "        if len(sample_idxs_so_far) >= 5:\n",
    "            break\n",
    "        sample_idxs_so_far.append(top_b[j].item())\n",
    "        sample_idx = top_b[j].item()\n",
    "        token_idx = top_t[j].item()\n",
    "        tokens = X_ordered[sample_idx]\n",
    "        tokens = tokens[:(token_idx+1)]\n",
    "        sentence = tokenizer.decode(tokens.long())\n",
    "        sentence = sentence.replace('\\n', '=newline=')\n",
    "        print(sentence, '-->', f'{top_values[j].item():.2f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (8) must match the size of tensor b (128) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[113], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iters):\n\u001b[1;32m     13\u001b[0m     grads \u001b[38;5;241m=\u001b[39m eigenmodel\u001b[38;5;241m.\u001b[39mcompute_gradients(X_batch\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 14\u001b[0m     each_circuit_val \u001b[38;5;241m=\u001b[39m \u001b[43meach_circuit_val\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43meigenmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43mn_subnetworks\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     15\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m     16\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (8) must match the size of tensor b (128) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "circuit_vals = []\n",
    "X_ordered = []\n",
    "iters = 5\n",
    "n_subnetworks = eigenmodel.n_features\n",
    "\n",
    "dataloader = DataLoader(X_transformer[:100], batch_size=8, shuffle=False)\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "for X_batch in dataloader:\n",
    "    X_ordered.append(X_batch)\n",
    "        # Compute gradients many times and take the average\n",
    "    each_circuit_val = torch.zeros(X_batch.shape[0], n_subnetworks).to('cuda')\n",
    "    for _ in range(iters):\n",
    "        grads = eigenmodel.compute_gradients(X_batch.to('cuda'))\n",
    "        each_circuit_val = each_circuit_val + (eigenmodel(grads))[:,:n_subnetworks]\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    circuit_vals.append(each_circuit_val.view(X_batch.shape[0], n_subnetworks))\n",
    "circuit_vals = torch.concat(circuit_vals, dim=0)/iters\n",
    "X_ordered = torch.concat(X_ordered, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_eigenmodel = copy.deepcopy(eigenmodel)\n",
    "token_eigenmodel.loss = KLDivergenceFlattenOverTokensLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---- Feature 89 ---- Activation: 0.490\n",
      " leaves under her feet and tried to climb the icy hill again.=newline==newline=This time, Roxy didn't slip. She climbed and climbed until she reached the --> 3.75\n",
      ". He did not take the shell from Mia. He found it in the sand. He did not want to make Mia angry.=newline==newline=\"No, Mia --> 2.57\n",
      "Ben smiled and said, \"Thank you, Mia. You are my sister. I love you too.\"Tom was a cat who liked to play outside. He --> 2.37\n",
      "able friend to all the animals. He would stand by them and help them when they needed it. Everyone liked Sam because he was kind and strong.=newline==newline= --> 2.23\n",
      " them broke and spilled on the floor.=newline==newline=\"Oh no!\" Tom and Anna said. They were scared. They heard their mom coming.=newline==newline=\" --> 2.20\n",
      "\n",
      "\n",
      "---- Feature 51 ---- Activation: 0.456\n",
      " farmer heard the cow. He wanted to help. So, he got another cow to be friends with the sad cow. The sad cow was happy now. They --> 2.60\n",
      " Lily's mom asked her if she wanted to have a fancy tea party with her dolls. Lily was very excited and said yes.=newline==newline=Lily's  --> 1.93\n",
      ", the cat just walked away.=newline==newline=From that day on, Timmy was no longer scared of anything. He learned that sometimes, even the smallest of --> 1.90\n",
      ". They hugged Mom and Dad.=newline==newline=\"Help, help!\" they cried. \"The dog is coming!\"=newline==newline=Mom and Dad were calm. They --> 1.83\n",
      " his friends made a beautiful bouquet and gave it to their mommies. Everyone was so happy and jolly that they danced and sang together. From that --> 1.73\n",
      "\n",
      "\n",
      "---- Feature 25 ---- Activation: 0.483\n",
      " do not like carrots and potatoes and chicken. I only like candy and cake.\"=newline==newline=Mom was sad. She said, \"Tom, you are being st --> 2.54\n",
      ". They hoped the cat would be their new friend.=newline==newline=They got back in the car and drove to the vet. They did not mind delaying going to --> 2.41\n",
      " has to stay at home and rest. He cannot go to school or play with Ben. He is sad and bored. He misses Ben a lot.=newline==newline= --> 2.00\n",
      "my was so happy to have his blocks back and he knew he would never let them disappear again.Once upon a time, there was a little girl named Lily --> 1.93\n",
      " first, we need to clean up your mess. Look at all the paint on the table and the floor. We need to be organized and tidy,\" her mom --> 1.89\n",
      "\n",
      "\n",
      "---- Feature 66 ---- Activation: 0.012\n",
      ". His name was Max. Max liked to play in the yard. Daisy liked to watch Max play. Max and Daisy became friends.=newline==newline=Every day, --> 0.73\n",
      " her tears and smiled. She and Ben looked around the garden for another mushroom. They found one that was smaller and white and had no spots. They carefully picked --> 0.67\n",
      " you as my puppy.\"Once upon a time, there was a little girl named Lily. She had a cup that she loved to drink juice from every day --> 0.63\n",
      " leaves under her feet and tried to climb the icy hill again.=newline==newline=This time, Roxy didn't slip. She climbed and climbed until she reached the --> 0.62\n",
      " earlier, but he still wanted to help her. He went over and helped her throw the coin in the fountain. The girl smiled and said thank you. Tim --> 0.51\n",
      "\n",
      "\n",
      "---- Feature 92 ---- Activation: 0.016\n",
      " help others when they need it.Once upon a time, there was a poor neighbor who had a big cat. The cat was very fat and heavy, so --> 0.86\n",
      " Mia loved her room because it had a big bookshelf. The bookshelf was full of colorful books. Mia liked to read these books every day. --> 0.70\n",
      " bunny.One day, a little boy named Tim went to play with his friend, Sam. They wanted to play a game with a ball. The game was --> 0.61\n",
      "'t ashamed to love taking pictures anymore.Once upon a time, there was a little girl named Lily. She liked to play in the garden with her toys. --> 0.60\n",
      " always share his toys with his friends. One day, Tom was walking on the street when he slipped on a banana peel. He fell down and hurt his shoulder --> 0.60\n",
      "\n",
      "\n",
      "---- Feature 0 ---- Activation: 0.055\n",
      ", swan! Do you want some bread?\" Lily called.=newline==newline=The hidden swan peeked out from the reeds. It saw Lily and the --> 1.06\n",
      " the light bulbs. Now we can see!\" =newline==newline=The man hugged his wife and said, \"I will always provide for you, my love.\" They --> 0.96\n",
      ". They hugged Mom and Dad.=newline==newline=\"Help, help!\" they cried. \"The dog is coming!\"=newline==newline=Mom and Dad were calm. They --> 0.77\n",
      " the cow. \"Why are you sad, cow?\" he asked. The cow said, \"I am lonely. I want a friend.\"=newline==newline=The kind --> 0.73\n",
      ", the cat just walked away.=newline==newline=From that day on, Timmy was no longer scared of anything. He learned that sometimes, even the smallest of --> 0.73\n",
      "\n",
      "\n",
      "---- Feature 21 ---- Activation: 0.327\n",
      " are gone. The end.Lily and Ben are playing in the living room. They see a letter on the table. It is for their mom. Lily --> 1.62\n",
      " finds a small toy car with a zipper on it. He can unzip the car and put things inside. He thinks it is very cool and playful. He --> 1.14\n",
      " her to the park. The daughter was very excited and couldn't wait to go.=newline==newline=But then, the mommy and daddy had to delay the trip --> 1.06\n",
      ", what's happening?\" she cried. \"It's an earthquake, Lily,\" her mommy said, trying to calm her down.=newline==newline=The earthquake caused --> 1.06\n",
      " do not like carrots and potatoes and chicken. I only like candy and cake.\"=newline==newline=Mom was sad. She said, \"Tom, you are being st --> 1.05\n",
      "\n",
      "\n",
      "---- Feature 96 ---- Activation: 0.012\n",
      ". His name was Max. Max liked to play in the yard. Daisy liked to watch Max play. Max and Daisy became friends.=newline==newline=Every day, --> 0.90\n",
      " her to the park. The daughter was very excited and couldn't wait to go.=newline==newline=But then, the mommy and daddy had to delay the trip --> 0.43\n",
      " Spot. I polish it every day.\"=newline==newline=After playing with the car, Kitty and Spot felt thirsty. They found a small pond with clear water. They --> 0.43\n",
      " are gone. The end.Lily and Ben are playing in the living room. They see a letter on the table. It is for their mom. Lily --> 0.40\n",
      " first, we need to clean up your mess. Look at all the paint on the table and the floor. We need to be organized and tidy,\" her mom --> 0.40\n",
      "\n",
      "\n",
      "---- Feature 79 ---- Activation: 0.020\n",
      " cheek. From that day on, Lily loved helping her mom with the laundry and always remembered to put the clothes in the stand where they store them.<|end --> 0.28\n",
      " forgive each other. So, Lily forgave Jack and they played together again. The end.Once upon a time, there was a little girl named Lily. --> 0.26\n",
      " couldn't reach it! The statue was too tall. So, she just stood there looking at it for a while. =newline==newline=After a few minutes, --> 0.25\n",
      " the ball with his strong legs. The ball flew into the goal! Spot was so happy. He and Buddy played together all day long.Once upon a time --> 0.23\n",
      ". But he practiced every day and soon he was playing just as well as before. Timmy was so happy with his new flute and he played it --> 0.21\n",
      "\n",
      "\n",
      "---- Feature 78 ---- Activation: 0.022\n",
      " bunny.One day, a little boy named Tim went to play with his friend, Sam. They wanted to play a game with a ball. The game was --> 0.48\n",
      ". He did not take the shell from Mia. He found it in the sand. He did not want to make Mia angry.=newline==newline=\"No, Mia --> 0.46\n",
      " Spot. I polish it every day.\"=newline==newline=After playing with the car, Kitty and Spot felt thirsty. They found a small pond with clear water. They --> 0.37\n",
      " them broke and spilled on the floor.=newline==newline=\"Oh no!\" Tom and Anna said. They were scared. They heard their mom coming.=newline==newline=\" --> 0.32\n",
      " had a hook that they found in the shed. It was shiny and sharp, and they pretended it was a treasure.=newline==newline=One day, they decided to --> 0.31\n",
      "\n",
      "\n",
      "---- Feature 1 ---- Activation: 0.133\n",
      "=newline==newline=\"Mom, can I invite Sam and Lily and Ben and Anna to my party?\" he said.=newline==newline=\"Of course, my dear. You --> 0.62\n",
      ". They hugged Mom and Dad.=newline==newline=\"Help, help!\" they cried. \"The dog is coming!\"=newline==newline=Mom and Dad were calm. They --> 0.61\n",
      ". He says, \"You are very brave, Lily. The nail can't hurt you anymore.\"=newline==newline=Lily smiles. She says, \"Thank you --> 0.61\n",
      " the light bulbs. Now we can see!\" =newline==newline=The man hugged his wife and said, \"I will always provide for you, my love.\" They --> 0.60\n",
      "Ben smiled and said, \"Thank you, Mia. You are my sister. I love you too.\"Tom was a cat who liked to play outside. He --> 0.51\n",
      "\n",
      "\n",
      "---- Feature 15 ---- Activation: 0.035\n",
      ". He showed her how to use it to fix her teddy bear. The little girl was very happy and hugged the robot, thanking him for his kindness. --> 0.50\n",
      " his friends made a beautiful bouquet and gave it to their mommies. Everyone was so happy and jolly that they danced and sang together. From that --> 0.37\n",
      ". When he got there, he saw lots of beakers and test tubes. Spot's owner was a scientist and she was doing experiments.  --> 0.31\n",
      ". His name was Max. Max liked to play in the yard. Daisy liked to watch Max play. Max and Daisy became friends.=newline==newline=Every day, --> 0.30\n",
      " Toot tried to work and help people too. As Toot worked, steam came out of his top. Toot was not miserable anymore. He was happy --> 0.22\n",
      "\n",
      "\n",
      "---- Feature 28 ---- Activation: 0.008\n",
      " leaves under her feet and tried to climb the icy hill again.=newline==newline=This time, Roxy didn't slip. She climbed and climbed until she reached the --> 0.34\n",
      ". His name was Max. Max liked to play in the yard. Daisy liked to watch Max play. Max and Daisy became friends.=newline==newline=Every day, --> 0.24\n",
      " bunny.One day, a little boy named Tim went to play with his friend, Sam. They wanted to play a game with a ball. The game was --> 0.20\n",
      ", there was a little boy named Tom. He loved to play with his red ball. One sunny day, Tom went outside to play with his ball in the --> 0.18\n",
      "|endoftext|>Once upon a time, there was a little girl named Lily. She loved to play outside in the sun with her friends. One --> 0.12\n",
      "\n",
      "\n",
      "---- Feature 40 ---- Activation: 0.447\n",
      " cheek. From that day on, Lily loved helping her mom with the laundry and always remembered to put the clothes in the stand where they store them.<|end --> 1.27\n",
      " young boy named Tim found a dull, round rock. He picked it up and looked at it. He thought it was not very fun, but he took it --> 0.99\n",
      " earlier, but he still wanted to help her. He went over and helped her throw the coin in the fountain. The girl smiled and said thank you. Tim --> 0.95\n",
      " them broke and spilled on the floor.=newline==newline=\"Oh no!\" Tom and Anna said. They were scared. They heard their mom coming.=newline==newline=\" --> 0.86\n",
      "=newline==newline=He crawled into the dog house and curled up on the blanket. He felt cozy and happy. He did not know that the dog house belonged to --> 0.68\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "bold_idx = tokenizer.encode('***')\n",
    "\n",
    "for i in circuit_vals.mean(dim=0).argsort(descending=True):\n",
    "    if frac_activated[i] < .005:\n",
    "        continue\n",
    "    if frac_activated[i] > .5:\n",
    "        continue\n",
    "    \n",
    "    # Get the absolute values for feature i\n",
    "    abs_vals = (circuit_vals[..., i])\n",
    "\n",
    "    # Find the top 5 (b, t) indices for feature i\n",
    "    top_indices = abs_vals.flatten().argsort(descending=True)[:5]\n",
    "    \n",
    "    # Convert the flat indices back to (b, t) indices\n",
    "    #top_b, top_t = torch.div(top_indices, token_length, #rounding_mode='floor'), top_indices % token_length\n",
    "\n",
    "    # Get the corresponding top values\n",
    "    top_values = abs_vals[top_indices]\n",
    "\n",
    "    print(f'\\n\\n---- Feature {i} ---- Activation: {frac_activated[i]:.3f}')\n",
    "    for j in range(len(top_indices)):\n",
    "        sample_idx = top_indices[j].item()\n",
    "        tokens = X_ordered[sample_idx]\n",
    "        sentence = tokenizer.decode(tokens.long())\n",
    "        sentence = sentence.replace('\\n', '=newline=')\n",
    "        print(sentence, '-->', f'{top_values[j].item():.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_vals = []\n",
    "X_ordered = []\n",
    "iters = 10\n",
    "n_subnetworks = eigenmodel.n_features\n",
    "dataloader = DataLoader(X_transformer[:1000].to('cuda'), batch_size=8, shuffle=True)\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch in :\n",
    "        X_ordered.append(X_batch)\n",
    "        # Compute gradients many times and take the average\n",
    "        each_circuit_val = torch.zeros(X_batch.shape[0]*X_batch.shape[1], n_subnetworks).to('cuda')\n",
    "        for _ in range(iters):\n",
    "            grads = eigenmodel.compute_gradients(X_batch)\n",
    "            each_circuit_val = each_circuit_val + abs(eigenmodel(grads))[:,:n_subnetworks]\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        circuit_vals.append(each_circuit_val.view(X_batch.shape[0], X_batch.shape[1], n_subnetworks))\n",
    "    circuit_vals = torch.concat(circuit_vals, dim=0)/iters\n",
    "    X_ordered = torch.concat(X_ordered, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---- Feature 41 ---- Activation: 0.412\n",
      " Ben said.=newline= --> 28.08\n",
      "=newline=\"No, go away. You are annoying,\" Lily said.=newline= --> 24.40\n",
      " and he fell in.=newline= --> 22.21\n",
      " and slippery, and they could see fish and plants under the ice.=newline= --> 21.56\n",
      " too. Do you want to play with me?\"=newline==newline= --> 21.22\n",
      "\n",
      "\n",
      "---- Feature 87 ---- Activation: 0.489\n",
      " big, hairy rabbit named --> 24.79\n",
      " Lily. --> 20.80\n",
      " okay, Lily. The sunset will come again tomorrow.\" Lily's mommy was --> 20.23\n",
      " tried again and again to squeeze the tap, but still no --> -19.83\n",
      " sorry for him. She said, --> 18.37\n",
      "\n",
      "\n",
      "---- Feature 68 ---- Activation: 0.416\n",
      " Ben said.=newline==newline=\"Hi, Ben. Nice to meet --> 16.26\n",
      " try the bread. It --> -15.99\n",
      " big, hairy rabbit named --> -15.21\n",
      " clouds. They saw --> 15.20\n",
      " They  --> 14.30\n",
      "\n",
      "\n",
      "---- Feature 42 ---- Activation: 0.410\n",
      " wet. He saw the stick, and grabbed it. Lily pulled him out of --> 20.45\n",
      " He loved to play with his ball in the --> 17.93\n",
      " sorry for him. She said, \"Ben, why did you not --> 17.93\n",
      " I stay --> 16.68\n",
      " try the bread. It sw --> 16.04\n",
      "\n",
      "\n",
      "---- Feature 37 ---- Activation: 0.401\n",
      " good time until --> -13.78\n",
      " He loved to play with his ball in the park. One sunny day, Spot --> 13.19\n",
      " mom and she waves back. They have fun and forget --> 12.99\n",
      " Sue asked. Tim said, \" --> 12.94\n",
      "'t worry, we'll get --> -12.88\n",
      "\n",
      "\n",
      "---- Feature 78 ---- Activation: 0.434\n",
      " wet. He saw the stick, and grabbed it. Lily pulled him out of --> 24.80\n",
      " a big, scary pirate named Max. Max wanted the treasure too. --> 14.54\n",
      " and they have to --> -14.51\n",
      " sorry for him. She said, --> -14.25\n",
      " the rock! Lily was upset and scared. She didn --> -13.71\n",
      "\n",
      "\n",
      "---- Feature 54 ---- Activation: 0.357\n",
      " felt bad and wanted to say sorry. She went to her friend --> 18.71\n",
      "Once upon a time, there was a small mouse named Timmy. --> -13.90\n",
      " she was playing, she found a shiny rock on the --> 13.39\n",
      " eating, Lily heard a strange noise. She asked her friend --> 13.05\n",
      " box and walks away. He does not look at the children. He does --> 13.02\n",
      "\n",
      "\n",
      "---- Feature 88 ---- Activation: 0.391\n",
      " box and walks away. He does not look at the children. He does --> 19.23\n",
      " The classroom was big and had lots of --> 17.72\n",
      " Lily. She had a big sister named --> 15.94\n",
      " mom and she waves back. They have fun and forget about --> 15.80\n",
      " Timmy who loved to play with balls. One --> 12.17\n",
      "\n",
      "\n",
      "---- Feature 34 ---- Activation: 0.419\n",
      " wet. He saw the stick, and --> 17.50\n",
      ". He says, \"You are very brave, --> -16.82\n",
      " Roxy and Billy looked for big leaves and --> 16.69\n",
      ". The man's wife was very happy and said, \"Thank you for --> -15.88\n",
      " Tom and Sue, decided --> -15.34\n",
      "\n",
      "\n",
      "---- Feature 14 ---- Activation: 0.313\n",
      " Ben said.=newline==newline=\"Hi, Ben. Nice to --> 16.10\n",
      " store to buy some sugar.=newline==newline=Lily was excited to go to the --> 14.09\n",
      " faucet for the kitchen sink. Mia's mom said --> 13.02\n",
      "=newline=\"No, go away. You are annoying --> 12.70\n",
      ". From that day on, Timmy remembered to take it easy and never --> 12.46\n",
      "\n",
      "\n",
      "---- Feature 47 ---- Activation: 0.328\n",
      " to help Ben. She pushed the mean boy away --> 12.74\n",
      " the rock! Lily was upset and scared. She didn --> 12.47\n",
      " named Max. Max loved to run and play in --> -12.15\n",
      " with your tank, Lily?\" Tom asked.=newline==newline= --> -11.14\n",
      " their toys in the living room. They had a lot of fun making a big --> 10.99\n",
      "\n",
      "\n",
      "---- Feature 0 ---- Activation: 0.448\n",
      " and Mia like to play in the big room with --> -18.27\n",
      " Roxy and Billy looked --> -17.20\n",
      " Ben said.=newline==newline=\"Hi, --> -15.40\n",
      " a hug. He told him he was a good boy for --> -14.54\n",
      " had a big friend in Max.Once upon a time --> 13.96\n",
      "\n",
      "\n",
      "---- Feature 10 ---- Activation: 0.338\n",
      " mom and she waves back. --> 11.50\n",
      " named Max. Max loved to run and play in the park. --> 11.34\n",
      " ignorant anymore.Lily and Tom were hungry. --> 11.14\n",
      "Once upon a time, there was a small mouse named Timmy. --> 10.79\n",
      " and dad. One day, they decided to go on a road trip. --> 10.66\n",
      "\n",
      "\n",
      "---- Feature 89 ---- Activation: 0.420\n",
      " the rain. She would jump in all the p --> 15.94\n",
      " and juicy. He was so happy that --> -13.53\n",
      " song from the truck. It made them laugh.=newline==newline=The ice cream --> 13.23\n",
      "=newline==newline=Roxy told Billy about the icy hill and how she couldn --> 12.87\n",
      " ignorant anymore.Lily and Tom were hungry. They wanted to --> 12.81\n",
      "\n",
      "\n",
      "---- Feature 23 ---- Activation: 0.328\n",
      " try the bread. It swam out --> -12.44\n",
      " sorry for him. She said, \" --> 11.55\n",
      " ignorant anymore.Lily and Tom were hungry. They wanted to --> 10.89\n",
      " Ben said.=newline==newline=\"Hi, --> -10.66\n",
      " tried again and again to squeeze the tap, but still no --> -10.66\n",
      "\n",
      "\n",
      "---- Feature 98 ---- Activation: 0.256\n",
      " wet. He saw the stick, and grabbed it. Lily pulled him out of --> 16.79\n",
      " Timmy who loved to play with balls. One --> 11.31\n",
      " earlier, but he still wanted to help her. He went --> 11.24\n",
      " too. Do you want to play --> 11.10\n",
      " mom and she waves back. They have --> -10.77\n",
      "\n",
      "\n",
      "---- Feature 24 ---- Activation: 0.239\n",
      " He loved to play with his ball in the --> 9.48\n",
      " to swim in the ocean with his friends. One --> 8.51\n",
      " and green. Lily was scared of --> -8.38\n",
      " box and walks away. He does not look at the children. He --> -8.12\n",
      " They  --> 7.96\n",
      "\n",
      "\n",
      "---- Feature 8 ---- Activation: 0.375\n",
      "Once upon a time, there was a small mouse named --> 18.93\n",
      " saw a big tree --> -11.13\n",
      " okay, Lily --> -10.82\n",
      " day on, Lily made sure to stay awake and watch the sunset every day. --> -10.73\n",
      " try the bread. It swam out from the reeds and took --> 10.68\n",
      "\n",
      "\n",
      "---- Feature 65 ---- Activation: 0.363\n",
      " ignorant anymore.Lily and Tom were hungry. They wanted to --> 12.47\n",
      " their toys in the living room. They had a lot --> 12.04\n",
      " they knew. They recognized a car, --> 11.46\n",
      " his mom said.=newline==newline=Tommy smiled. He --> -11.27\n",
      " she was playing, she found a shiny rock on the ground --> 10.80\n",
      "\n",
      "\n",
      "---- Feature 53 ---- Activation: 0.254\n",
      " asked Fluffy. \"Yes, I want to come with you,\" replied --> -13.91\n",
      " store to buy some sugar.=newline==newline=Lily was excited to go to the --> 13.09\n",
      " Lily. She had a big sister named Emma who --> 12.84\n",
      " Ben said.=newline==newline=\"Hi, Ben. Nice to meet --> 10.95\n",
      " song from --> -9.69\n",
      "\n",
      "\n",
      "---- Feature 2 ---- Activation: 0.282\n",
      ". --> 10.30\n",
      " store to buy some sugar.=newline==newline=Lily was excited to go to --> 10.10\n",
      " friend.\" --> 9.39\n",
      " He loved to play with his ball in the --> 8.76\n",
      " too. --> 8.69\n",
      "\n",
      "\n",
      "---- Feature 4 ---- Activation: 0.401\n",
      ". He says, \"You are very brave, Lily. The nail can't --> 20.01\n",
      " earlier, but he still wanted to help her. He went --> -16.39\n",
      " store to buy some sugar.=newline==newline=Lily was excited to go to --> -14.64\n",
      " to help Ben. She pushed the mean --> 14.25\n",
      "=newline=\"No, go away. You are --> -13.39\n",
      "\n",
      "\n",
      "---- Feature 95 ---- Activation: 0.367\n",
      " box and walks away. He does not look at the children. He does --> -15.90\n",
      " had a big friend --> 12.65\n",
      " wet. He saw the stick, and grabbed it. Lily pulled him out of --> 12.17\n",
      "=newline=\"OK!\" Anna said. She --> -11.16\n",
      " He loved to play with his ball in the --> -11.14\n",
      "\n",
      "\n",
      "---- Feature 28 ---- Activation: 0.042\n",
      "Once upon a time, there was a small mouse --> 21.39\n",
      " had a big friend in Max.Once upon a time --> 11.73\n",
      " in a big park, there was --> 8.68\n",
      " to swim in the ocean with his friends. One day, --> 8.35\n",
      ".=newline==newline=Later that day --> 6.14\n",
      "\n",
      "\n",
      "---- Feature 43 ---- Activation: 0.226\n",
      " top of the icy hill. Roxy was --> -10.04\n",
      ".=newline==newline=Sara did not want to cut the onions. She wanted to --> 9.87\n",
      ". He says, \"You are very brave, Lily. --> -9.85\n",
      " They like to play outside when it --> 9.59\n",
      " story was about a tortoise who won a race against a hare --> -9.49\n",
      "\n",
      "\n",
      "---- Feature 67 ---- Activation: 0.411\n",
      ". He says, \"You are very brave, Lily. --> -15.76\n",
      " Roxy and Billy looked for big leaves and --> -15.43\n",
      " had a big friend in Max.Once upon --> -13.95\n",
      " tried again and again to squeeze the tap, but still no --> 13.36\n",
      ".=newline==newline=\"Look, a mushroom!\" --> 12.28\n",
      "\n",
      "\n",
      "---- Feature 31 ---- Activation: 0.356\n",
      " box and walks away. He does not look at the children. He --> -12.77\n",
      " day on, Lily made sure to stay awake and watch the sunset every day. --> -12.19\n",
      " wet. He saw the stick, and --> 11.09\n",
      " mom and she waves back. They have fun and forget about --> 10.96\n",
      " The classroom was big and had lots of toys.=newline= --> -10.72\n",
      "\n",
      "\n",
      "---- Feature 39 ---- Activation: 0.341\n",
      "Once upon a time, there was a small mouse named --> -25.33\n",
      " a big, scary pirate named --> -16.51\n",
      " and Mia like to play in the big room with many books --> -15.19\n",
      ". He says, \"You are very brave, Lily. --> -12.28\n",
      " store to buy some sugar.=newline==newline=Lily was excited to go to --> 11.25\n",
      "\n",
      "\n",
      "---- Feature 90 ---- Activation: 0.284\n",
      " They  --> -17.86\n",
      " sorry for him. She said, \"Ben, why did you not --> -10.92\n",
      ". He felt so --> -10.65\n",
      " wet. He saw the stick, and grabbed it. Lily pulled him out of --> 10.65\n",
      " Tom and Sue, decided to march to the big tree. They marched and --> -10.42\n",
      "\n",
      "\n",
      "---- Feature 1 ---- Activation: 0.383\n",
      " and slippery, and they could see fish and --> 15.29\n",
      "=newline=\"OK!\" Anna said. She --> 13.14\n",
      " friend.\"=newline==newline=They hugged each other, --> 13.10\n",
      " they knew. They recognized a car, --> 12.74\n",
      " clouds. They saw --> 12.12\n",
      "\n",
      "\n",
      "---- Feature 73 ---- Activation: 0.263\n",
      " day on, Lily made sure --> -11.68\n",
      " They  --> -10.84\n",
      " her room. She puts the teaspoon in Anna's hand and says, \" --> -10.81\n",
      " clouds. They saw many shapes in the clouds. They --> -8.97\n",
      " Tom and Sue, decided to march to the big tree. They marched and --> 8.88\n",
      "\n",
      "\n",
      "---- Feature 20 ---- Activation: 0.400\n",
      " Roxy and Billy looked for big leaves and --> -15.63\n",
      " the rock! Lily was upset and scared. She didn --> -13.40\n",
      " tried again and again to squeeze the tap, but still no --> 13.28\n",
      " the rain. She would jump in all the p --> -13.06\n",
      " Sue asked. Tim said, \" --> -13.03\n",
      "\n",
      "\n",
      "---- Feature 52 ---- Activation: 0.371\n",
      " had a big friend in --> -17.60\n",
      " food. The bird was very happy and started to feel better --> -15.08\n",
      "Once upon a time, there was a small mouse named --> 14.98\n",
      " They  --> -13.23\n",
      ". He says, \"You are very brave, Lily. The nail --> -12.59\n",
      "\n",
      "\n",
      "---- Feature 64 ---- Activation: 0.325\n",
      " named Max. Max loved to run --> 12.47\n",
      " a big, --> 12.19\n",
      " Lily. She had --> 11.74\n",
      "Once upon a time, there was a small mouse named Timmy. --> 11.18\n",
      ".=newline==newline=\"Look, a mushroom!\" Lily --> 10.42\n",
      "\n",
      "\n",
      "---- Feature 35 ---- Activation: 0.444\n",
      " They  --> -30.32\n",
      " It has a red light and --> 20.29\n",
      " friend.\"=newline==newline=They hugged each other, --> 18.05\n",
      "? I told you --> 17.28\n",
      " the rock! Lily was upset and scared. She didn --> -17.19\n",
      "\n",
      "\n",
      "---- Feature 38 ---- Activation: 0.277\n",
      "=newline=\"No, go away. --> -12.17\n",
      "Once upon a time, there was a small mouse named Timmy. --> -11.11\n",
      " like Sara. It stung Sara on the nose. Sara screamed and fell from --> 10.75\n",
      ". From that day on --> -10.01\n",
      " to help Ben. She pushed the mean boy away.=newline==newline=The mean --> -10.00\n",
      "\n",
      "\n",
      "---- Feature 32 ---- Activation: 0.341\n",
      " like Sara. It stung Sara on the nose. Sara screamed and fell from --> 15.54\n",
      ".=newline==newline=\"Look, a mushroom!\" Lily said. \"Can we --> -11.71\n",
      " the rain. She would jump in all the puddl --> -11.68\n",
      " with your tank, Lily?\" Tom asked.=newline==newline=\"No --> -11.42\n",
      ". He says, \"You are very brave, Lily. The nail can't --> -11.40\n",
      "\n",
      "\n",
      "---- Feature 29 ---- Activation: 0.238\n",
      " \"No, thank you. I do not want to --> -12.04\n",
      "=newline==newline=R --> 10.61\n",
      " their toys in the living room. They had a lot of fun making a --> 9.79\n",
      " Lily. She had a big sister named --> -9.52\n",
      " faucet for the kitchen sink. Mia's mom said, \"This f --> 9.44\n",
      "\n",
      "\n",
      "---- Feature 30 ---- Activation: 0.266\n",
      " wet. He saw the stick, and grabbed it. Lily pulled him out of --> -17.64\n",
      " sorry for him. She said, \"Ben, why did you not --> 15.59\n",
      " Tom and Sue, decided to march to the big tree. They marched and --> -11.79\n",
      " and Mia like --> -11.67\n",
      " mom and she waves back. They have fun and forget about --> 11.11\n",
      "\n",
      "\n",
      "---- Feature 72 ---- Activation: 0.296\n",
      " wet. He saw the stick, and grabbed it. Lily pulled him out of --> -22.02\n",
      " had a big friend in Max.Once upon a time --> 10.55\n",
      " a hug. He told him he --> 10.49\n",
      " and Mia like to play in --> 10.23\n",
      ".=newline==newline=\"Look, a mushroom!\" Lily said. \"Can --> 9.78\n",
      "\n",
      "\n",
      "---- Feature 94 ---- Activation: 0.244\n",
      "Once upon a time, there was a small mouse named --> 24.01\n",
      " store to buy some sugar.=newline==newline=Lily was excited to go to --> 11.02\n",
      " box and walks away. He does not --> -9.81\n",
      " faucet for the kitchen sink. Mia's --> -9.75\n",
      " eating, Lily heard a strange noise. She asked her friend, --> -9.65\n",
      "\n",
      "\n",
      "---- Feature 21 ---- Activation: 0.341\n",
      " He loved to play with his ball in the --> -16.31\n",
      " sorry for him. She said, --> -12.37\n",
      " story was about a tortoise who --> 11.55\n",
      " Lily. She had a big sister named Emma who --> -10.85\n",
      " They  --> -10.40\n",
      "\n",
      "\n",
      "---- Feature 55 ---- Activation: 0.337\n",
      " big, hairy rabbit named --> 12.37\n",
      " and green. Lily was scared of --> 11.15\n",
      " wet. He saw the stick, and grabbed it. Lily pulled him out of --> -10.36\n",
      " a big, scary pirate --> -10.15\n",
      " and they have to stay inside. They are very bored.=newline==newline=They --> -10.03\n",
      "\n",
      "\n",
      "---- Feature 86 ---- Activation: 0.413\n",
      ".=newline==newline=\"Look --> 19.83\n",
      " friend.\"=newline==newline=They hugged each other, --> -17.42\n",
      " named --> 15.59\n",
      " they knew. They recognized a car, --> -15.46\n",
      " sorry for him. She said, \"Ben, why --> -15.27\n",
      "\n",
      "\n",
      "---- Feature 11 ---- Activation: 0.272\n",
      " store to buy some sugar.=newline==newline=Lily was excited to go to --> -11.04\n",
      " day on, Lily made sure --> 10.88\n",
      " Tom and Sue, decided to march to the big tree. They marched and --> -10.45\n",
      " his mom said.=newline==newline=Tommy smiled. He hugged his mom. He --> -10.00\n",
      " and Mia like to --> 9.97\n",
      "\n",
      "\n",
      "---- Feature 7 ---- Activation: 0.419\n",
      " story was about a tortoise who won a race against a hare --> -15.17\n",
      " and Mia like to play in --> 15.14\n",
      " his mom said.=newline= --> -14.19\n",
      " store to buy some sugar.=newline==newline=Lily was excited to go to --> 14.15\n",
      " wet. He saw the stick, and --> 13.28\n",
      "\n",
      "\n",
      "---- Feature 27 ---- Activation: 0.263\n",
      " Timmy who loved to play with balls. One --> 10.99\n",
      " tried again and again to squeeze the tap, but still no --> -10.96\n",
      " They like to play outside when it --> 10.66\n",
      " to march around the farm with --> -10.52\n",
      " like Sara. It stung Sara on the nose. Sara screamed and fell from --> 10.20\n",
      "\n",
      "\n",
      "---- Feature 93 ---- Activation: 0.281\n",
      " tried again and again to squeeze the tap, but still no --> 11.50\n",
      " wet. He saw the stick, and grabbed it. Lily pulled him out of --> -11.16\n",
      " clouds. They saw many shapes in the clouds. They saw a bunny, --> -10.70\n",
      " she was playing, she found a shiny rock on the ground. --> 10.62\n",
      " The classroom was big and had lots of --> 10.21\n",
      "\n",
      "\n",
      "---- Feature 97 ---- Activation: 0.338\n",
      " store to buy some sugar.=newline==newline=Lily was excited to go to the --> -13.36\n",
      " to march around the farm with --> -11.58\n",
      " saw that Lily was suffering because she lost her teddy bear. She --> 11.19\n",
      " He loved to play with his ball in the --> -11.17\n",
      " named Max. Max loved to run and play in the park. --> -10.62\n",
      "\n",
      "\n",
      "---- Feature 71 ---- Activation: 0.389\n",
      " \"No, thank you. I do not want to --> -17.14\n",
      "=newline=\"No, go away. You --> -14.85\n",
      " Ben said.=newline==newline=\"Hi, Ben. Nice to --> -14.32\n",
      " scared, but he really wanted to see the bulb up close.  --> -12.81\n",
      " their toys in the living room. They had a lot --> 12.18\n",
      "\n",
      "\n",
      "---- Feature 3 ---- Activation: 0.012\n",
      "Once upon a time, there was a small mouse named Timmy. --> 21.02\n",
      " had a big friend in Max.Once upon a time --> -16.62\n",
      " in a big park, there was --> 5.60\n",
      " Tom and Sue, decided to march to the big tree. They marched and --> 4.26\n",
      " big, hairy rabbit named Bongo. Bongo loved to eat --> 4.17\n",
      "\n",
      "\n",
      "---- Feature 50 ---- Activation: 0.276\n",
      " \"No, thank you. I do not want to --> -12.11\n",
      " Ben said.=newline==newline=\"Hi, Ben. Nice --> -11.19\n",
      " with your tank, Lily?\" Tom asked.=newline==newline=\" --> -10.17\n",
      ". They were a family, and they stuck together. Just like glue.L --> 9.53\n",
      " their toys in the living room. They had a lot of fun making --> 9.15\n",
      "\n",
      "\n",
      "---- Feature 82 ---- Activation: 0.359\n",
      "Once upon a time, there was a small mouse named Timmy. --> -16.66\n",
      " story was about a tortoise who won a race against --> -14.66\n",
      " and dad. One day, they decided --> -13.53\n",
      " like Sara. It stung Sara on the nose. Sara screamed and fell from --> 12.51\n",
      ". They were a family, and they stuck together. Just --> -11.99\n",
      "\n",
      "\n",
      "---- Feature 58 ---- Activation: 0.457\n",
      " try the bread. It sw --> 20.88\n",
      " and green. Lily was scared of the snake because she --> 18.43\n",
      " Ben said.=newline==newline=\"Hi, Ben. Nice to meet --> 18.36\n",
      " Mittens meowed nervously but followed Timmy up the tree.  --> -17.80\n",
      ". From that day on --> -16.07\n",
      "\n",
      "\n",
      "---- Feature 59 ---- Activation: 0.315\n",
      " like Sara. It stung Sara on the nose. Sara screamed and fell from --> -13.39\n",
      ".=newline==newline=\"Look, a mushroom!\" Lily said. \"Can --> 12.13\n",
      " box and walks away. He does not look at the children. He does --> -11.86\n",
      "Once upon a time, there was a small mouse named Timmy. --> -11.60\n",
      " eating, Lily heard a strange noise. She asked her friend, \" --> -11.26\n",
      "\n",
      "\n",
      "---- Feature 85 ---- Activation: 0.263\n",
      " the rock! Lily was upset and scared. She didn --> 15.56\n",
      " like Sara. It stung Sara on the nose. Sara screamed and fell from --> 12.16\n",
      " mom and she waves back. They have --> 11.28\n",
      " the table and the floor. We need to --> -11.00\n",
      " box and walks away. He does --> -10.39\n",
      "\n",
      "\n",
      "---- Feature 96 ---- Activation: 0.313\n",
      " store to buy some sugar.=newline==newline=Lily was excited to go to --> 16.20\n",
      " like Sara. It stung Sara on the nose. Sara screamed and fell from --> -14.75\n",
      ". He says, \"You are very brave, Lily. The nail can't --> 13.58\n",
      " and slippery, and they could see fish and --> 13.07\n",
      " day on, Lily made sure --> -11.67\n",
      "\n",
      "\n",
      "---- Feature 45 ---- Activation: 0.417\n",
      " \"No, thank you. I do not want to --> 16.72\n",
      " is in its right weight.\" Monkey was happy to learn and said, --> -14.66\n",
      " store to buy some sugar.=newline==newline=Lily was excited to go to --> 14.21\n",
      " and Mia like --> 13.83\n",
      " to help Ben. She pushed the mean boy away.=newline==newline=The mean boy --> -13.36\n",
      "\n",
      "\n",
      "---- Feature 74 ---- Activation: 0.329\n",
      " and Mia like to play in --> -15.33\n",
      " had a big friend in --> 14.31\n",
      " \"No, thank you. I do not --> -13.73\n",
      " wet. He saw the stick, and grabbed it. Lily pulled him out of --> 10.94\n",
      " Sue asked. Tim said, \"Yes, but all I --> -10.90\n",
      "\n",
      "\n",
      "---- Feature 48 ---- Activation: 0.324\n",
      " box and walks away. He does not look --> -12.97\n",
      " Roxy and Billy looked --> -12.25\n",
      " and they have to stay inside. They are very bored.=newline==newline=They --> -11.53\n",
      " is in its right weight.\" Monkey was happy to --> 11.22\n",
      " try the bread. It swam out from --> -10.55\n",
      "\n",
      "\n",
      "---- Feature 80 ---- Activation: 0.328\n",
      " like Sara. It stung Sara on the nose. Sara screamed and fell from --> -13.40\n",
      "'t worry, we'll get it --> -10.85\n",
      " felt bad and wanted to say sorry. She --> -10.34\n",
      " Tom and Sue, decided to march to the big tree. They marched and --> -10.18\n",
      " a hug. He told him he was a good boy for protecting his --> -10.16\n",
      "\n",
      "\n",
      "---- Feature 79 ---- Activation: 0.275\n",
      " store to buy some sugar.=newline==newline=Lily was excited to --> 13.69\n",
      " mom and she waves back. They have fun and forget about --> -12.11\n",
      " named Max. Max loved to run and play in --> -11.79\n",
      " asked Fluffy. \"Yes, I want to come with you,\" replied --> -11.00\n",
      " the table and the floor. We need to --> -10.44\n",
      "\n",
      "\n",
      "---- Feature 5 ---- Activation: 0.248\n",
      ". From that day on --> -10.87\n",
      " is in its right weight.\" Monkey was happy to learn and said, \" --> -10.81\n",
      " eating, Lily heard a strange noise. She asked her friend, \" --> -10.13\n",
      " the rock! Lily was upset and scared. She didn --> -9.69\n",
      "Once upon a time, there was a small mouse named --> 9.55\n",
      "\n",
      "\n",
      "---- Feature 63 ---- Activation: 0.478\n",
      ". He says, \"You are very brave, Lily. The nail can --> 18.33\n",
      " They  --> -18.23\n",
      " Ben said.=newline==newline=\"Hi, Ben. Nice --> 17.44\n",
      " the sky. It had --> -16.04\n",
      " wet. He saw the stick, and grabbed it. Lily --> 15.92\n",
      "\n",
      "\n",
      "---- Feature 83 ---- Activation: 0.463\n",
      " box and walks away. He does not look at the children. He does --> 20.49\n",
      " like Sara. It stung Sara on the nose. Sara screamed and fell from --> -19.97\n",
      " their toys in the living room. They had a lot of fun making --> 16.54\n",
      " scared, but he really wanted to see --> -16.51\n",
      "Once upon a time, there was a small mouse named --> 16.39\n",
      "\n",
      "\n",
      "---- Feature 13 ---- Activation: 0.315\n",
      " like Sara. It stung Sara on the nose. Sara screamed and fell from --> -13.92\n",
      " food. The bird was very happy and started to feel better --> -10.68\n",
      " try the bread. It --> 10.66\n",
      " Ben said.=newline==newline=\"Hi, Ben. Nice to --> -10.43\n",
      " to help Ben. She pushed the mean boy away.=newline==newline=The mean boy --> -10.30\n",
      "\n",
      "\n",
      "---- Feature 44 ---- Activation: 0.325\n",
      " and dad. One day, they decided to go on --> -12.45\n",
      " earlier, but he still wanted to help her --> -11.98\n",
      " wet. He saw the stick, and --> 11.84\n",
      " It was very yummy and they all smiled. Lily said, --> -11.07\n",
      "? I told --> -10.53\n",
      "\n",
      "\n",
      "---- Feature 6 ---- Activation: 0.250\n",
      " The classroom was big and had lots of toys.=newline= --> -13.64\n",
      " wet. He saw the stick, and grabbed it. Lily pulled him out of --> -11.62\n",
      "Once upon a time, there was a small mouse named --> -11.50\n",
      " and slippery, and they could see fish and plants under the ice.=newline= --> -10.32\n",
      " and he fell in.=newline==newline= --> -9.60\n",
      "\n",
      "\n",
      "---- Feature 16 ---- Activation: 0.284\n",
      " big, hairy rabbit named Bongo. Bongo loved to --> -11.73\n",
      " Ben said.=newline==newline=\"Hi, --> 10.87\n",
      " The classroom was big and had lots of toys.=newline==newline= --> -9.42\n",
      " the rain. She would jump in all the pudd --> -9.22\n",
      " named Max. Max loved to run and play in the park. --> 9.19\n",
      "\n",
      "\n",
      "---- Feature 26 ---- Activation: 0.067\n",
      " The classroom was big and had lots of toys.=newline= --> -68.75\n",
      " and juicy. He was so happy that he could finally eat it.=newline==newline= --> -68.65\n",
      " I stay with you?\" End asked.=newline==newline= --> -52.61\n",
      " to help Ben. She pushed the mean boy away.=newline==newline= --> -49.89\n",
      ".=newline==newline= --> -48.58\n",
      "\n",
      "\n",
      "---- Feature 46 ---- Activation: 0.325\n",
      ".=newline==newline=\"Look, a mushroom!\" Lily said. \"Can --> 13.69\n",
      " sorry for him. She said, \"Ben, --> 11.96\n",
      " like Sara. It stung Sara on the nose. Sara screamed and fell from --> -11.95\n",
      " they knew. They recognized a car, --> -11.68\n",
      " Timmy who loved to play with balls. One day, he found --> -10.74\n",
      "\n",
      "\n",
      "---- Feature 9 ---- Activation: 0.294\n",
      " He loved to play with his ball in the --> 11.87\n",
      " mom and she waves back. They have --> -11.37\n",
      " story was about a tortoise who won a race against a hare --> -10.13\n",
      " saw that Lily was suffering because she lost her teddy bear. --> -9.15\n",
      ".=newline==newline=\"Look, a mushroom!\" Lily said. --> -9.04\n",
      "\n",
      "\n",
      "---- Feature 84 ---- Activation: 0.443\n",
      " and slippery, and they could see fish and --> 19.67\n",
      " try the bread. It --> 18.24\n",
      " okay, Lily --> 16.68\n",
      " had a big friend in --> -15.77\n",
      " store to buy some sugar.=newline==newline=Lily was excited to go to --> -15.70\n",
      "\n",
      "\n",
      "---- Feature 61 ---- Activation: 0.403\n",
      " and he fell in.=newline==newline=Timmy tried to --> 14.55\n",
      " He loved --> -14.38\n",
      ". He says, \"You are very brave, Lily. The nail can't --> -14.27\n",
      ". The man's wife was very happy --> -14.04\n",
      " Tom and Sue, --> -14.00\n",
      "\n",
      "\n",
      "---- Feature 60 ---- Activation: 0.263\n",
      " too. Do you want --> -13.92\n",
      " ignorant anymore.Lily and Tom were hungry. They wanted to --> -11.86\n",
      " named Max came over and wanted the bone. Spot didn't --> -11.36\n",
      " named Max. Max loved to run and play in the park. One day, --> -9.19\n",
      " I stay with you?\" End asked.=newline==newline= --> -8.46\n",
      "\n",
      "\n",
      "---- Feature 33 ---- Activation: 0.405\n",
      " and slippery, and they could see fish and --> -18.94\n",
      ".=newline==newline=Sara did not want to cut the onions. She --> 15.42\n",
      "...=newline==newline=The box explodes. It makes a big fire and --> 15.23\n",
      " the rain. She would jump in all the puddl --> -14.47\n",
      " \"No, thank you. I do not want to --> 12.23\n",
      "\n",
      "\n",
      "---- Feature 22 ---- Activation: 0.416\n",
      " \"No, thank you. I do not want to --> -17.49\n",
      " Timmy who loved to play with balls. One --> -17.43\n",
      " friend.\"=newline==newline=They hugged each other, --> 15.35\n",
      " day on, Lily made sure to stay awake and watch the sunset every day --> -13.46\n",
      " top of the icy --> 11.38\n",
      "\n",
      "\n",
      "---- Feature 92 ---- Activation: 0.369\n",
      " mom and she waves back. They have --> -13.53\n",
      "...=newline==newline=The box explodes. It makes a big fire and a big boom --> -11.73\n",
      ". He says, \" --> 11.08\n",
      " day on, Lily made sure to stay awake and watch the sunset every day. --> -10.94\n",
      " and slippery, --> -10.87\n",
      "\n",
      "\n",
      "---- Feature 91 ---- Activation: 0.421\n",
      " and Mia like to play in --> -15.86\n",
      " too. Do you --> -15.47\n",
      " day on, Lily made sure to stay awake and watch the sunset every day --> -15.26\n",
      " I stay with you?\" End asked.=newline==newline= --> 14.95\n",
      " and slippery, and they could see fish and --> -14.65\n",
      "\n",
      "\n",
      "---- Feature 76 ---- Activation: 0.487\n",
      "=newline=\"No, go away. You are annoying,\" Lily said.=newline= --> -20.55\n",
      " box and walks away. He does not look at the children. He does --> 20.55\n",
      ". He felt so happy and proud of himself.  --> 19.34\n",
      " wet. He saw the stick, and grabbed it. Lily pulled him out of --> -17.46\n",
      " with your tank, Lily?\" Tom asked.=newline==newline= --> -15.97\n",
      "\n",
      "\n",
      "---- Feature 17 ---- Activation: 0.396\n",
      " box and walks away. He does not --> -16.12\n",
      " It has a red light and --> -15.91\n",
      ".=newline==newline=\"Look, a mushroom!\" Lily said. \"Can --> -15.61\n",
      " Ben said.=newline==newline=\"Hi, --> -15.10\n",
      " the table and the floor. We need --> 13.80\n",
      "\n",
      "\n",
      "---- Feature 25 ---- Activation: 0.487\n",
      " eating, Lily heard a strange noise. She asked her friend --> -16.05\n",
      "Lily puts her hand in the hole. --> -15.35\n",
      ".=newline==newline=Sara followed the butterfly to the other --> 15.27\n",
      " try the bread. It swam out --> -15.26\n",
      " his mom said.=newline= --> -15.05\n",
      "\n",
      "\n",
      "---- Feature 77 ---- Activation: 0.351\n",
      " store to buy some sugar.=newline==newline=Lily was excited to go to --> -12.72\n",
      " wet. He saw the stick, and --> -12.08\n",
      " Lily. She had a big sister named --> -12.04\n",
      " and ask questions. She wanted to --> -11.84\n",
      " It has a red light and --> -11.73\n",
      "\n",
      "\n",
      "---- Feature 69 ---- Activation: 0.435\n",
      " clouds. They saw many shapes in the clouds. They saw a bunny, a --> -18.34\n",
      " and slippery, and they could see fish and --> -15.30\n",
      " the man made sure to provide everything his --> -15.16\n",
      " his friends made a beautiful bouquet and gave it to their momm --> -15.11\n",
      " wet. One day, Lily saw a cute little frog hopping --> 14.75\n",
      "\n",
      "\n",
      "---- Feature 18 ---- Activation: 0.420\n",
      " her room. She puts the teaspoon in Anna's --> -16.12\n",
      " the sky. It had pretty feathers and was --> -15.93\n",
      " try the bread. It --> -14.93\n",
      " mom and she waves back. They have fun and forget --> -14.93\n",
      " to help Ben. She pushed the mean boy away.=newline= --> -13.54\n",
      "\n",
      "\n",
      "---- Feature 75 ---- Activation: 0.466\n",
      ". He felt so happy and proud of himself.  --> -19.38\n",
      " \"No, thank you. I do not want to --> -19.26\n",
      " mom and she waves back. They have --> -18.49\n",
      " Sue asked. Tim said --> -18.43\n",
      " was a very --> -17.39\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "circuit_vals = []\n",
    "X_ordered = []\n",
    "iters = 10\n",
    "n_subnetworks = eigenmodel.n_features\n",
    "dataloader = DataLoader(X_transformer[:1000].to('cuda'), batch_size=8, shuffle=True)\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch in :\n",
    "        X_ordered.append(X_batch)\n",
    "        # Compute gradients many times and take the average\n",
    "        each_circuit_val = torch.zeros(X_batch.shape[0]*X_batch.shape[1], n_subnetworks).to('cuda')\n",
    "        for _ in range(iters):\n",
    "            grads = eigenmodel.compute_gradients(X_batch)\n",
    "            each_circuit_val = each_circuit_val + abs(eigenmodel(grads))[:,:n_subnetworks]\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        circuit_vals.append(each_circuit_val.view(X_batch.shape[0], X_batch.shape[1], n_subnetworks))\n",
    "    circuit_vals = torch.concat(circuit_vals, dim=0)/iters\n",
    "    X_ordered = torch.concat(X_ordered, dim=0)\n",
    "    \n",
    "\n",
    "for i in circuit_vals.mean(dim=[0,1]).argsort(descending=True):\n",
    "    if frac_activated[i] < .005:\n",
    "        continue\n",
    "    if frac_activated[i] > .5:\n",
    "        continue\n",
    "    \n",
    "    # Get the absolute values for feature i\n",
    "    abs_vals = (circuit_vals[..., i])\n",
    "\n",
    "    # Find the top 5 (b, t) indices for feature i\n",
    "    top_indices = abs(abs_vals).flatten().argsort(descending=True)\n",
    "    \n",
    "    # Convert the flat indices back to (b, t) indices\n",
    "    top_b, top_t = torch.div(top_indices, token_length, rounding_mode='floor'), top_indices % token_length\n",
    "\n",
    "    # Get the corresponding top values\n",
    "    top_values = abs_vals[top_b, top_t]\n",
    "\n",
    "    print(f'\\n\\n---- Feature {i} ---- Activation: {frac_activated[i]:.3f}')\n",
    "    sample_idxs_so_far = []\n",
    "    for j in range(len(top_indices)):\n",
    "        if top_b[j].item() in sample_idxs_so_far:\n",
    "            continue\n",
    "        if len(sample_idxs_so_far) >= 5:\n",
    "            break\n",
    "        sample_idxs_so_far.append(top_b[j].item())\n",
    "        sample_idx = top_b[j].item()\n",
    "        token_idx = top_t[j].item()\n",
    "        tokens = X_ordered[sample_idx]\n",
    "        tokens = tokens[:(token_idx+1)]\n",
    "        sentence = tokenizer.decode(tokens.long())\n",
    "        sentence = sentence.replace('\\n', '=newline=')\n",
    "        print(sentence, '-->', f'{top_values[j].item():.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68ee0beb6d44183a1b052617a83d59a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61bf6f51ffa746e081dc561951d5a15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/112M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight torch.Size([50257, 256]) 12865792\n",
      "transformer.wpe.weight torch.Size([2048, 256]) 524288\n",
      "transformer.h.0.ln_1.weight torch.Size([256]) 256\n",
      "transformer.h.0.ln_1.bias torch.Size([256]) 256\n",
      "transformer.h.0.attn.attention.k_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.0.attn.attention.v_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.0.attn.attention.q_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.0.attn.attention.out_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.0.attn.attention.out_proj.bias torch.Size([256]) 256\n",
      "transformer.h.0.ln_2.weight torch.Size([256]) 256\n",
      "transformer.h.0.ln_2.bias torch.Size([256]) 256\n",
      "transformer.h.0.mlp.c_fc.weight torch.Size([1024, 256]) 262144\n",
      "transformer.h.0.mlp.c_fc.bias torch.Size([1024]) 1024\n",
      "transformer.h.0.mlp.c_proj.weight torch.Size([256, 1024]) 262144\n",
      "transformer.h.0.mlp.c_proj.bias torch.Size([256]) 256\n",
      "transformer.h.1.ln_1.weight torch.Size([256]) 256\n",
      "transformer.h.1.ln_1.bias torch.Size([256]) 256\n",
      "transformer.h.1.attn.attention.k_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.1.attn.attention.v_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.1.attn.attention.q_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.1.attn.attention.out_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.1.attn.attention.out_proj.bias torch.Size([256]) 256\n",
      "transformer.h.1.ln_2.weight torch.Size([256]) 256\n",
      "transformer.h.1.ln_2.bias torch.Size([256]) 256\n",
      "transformer.h.1.mlp.c_fc.weight torch.Size([1024, 256]) 262144\n",
      "transformer.h.1.mlp.c_fc.bias torch.Size([1024]) 1024\n",
      "transformer.h.1.mlp.c_proj.weight torch.Size([256, 1024]) 262144\n",
      "transformer.h.1.mlp.c_proj.bias torch.Size([256]) 256\n",
      "transformer.h.2.ln_1.weight torch.Size([256]) 256\n",
      "transformer.h.2.ln_1.bias torch.Size([256]) 256\n",
      "transformer.h.2.attn.attention.k_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.2.attn.attention.v_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.2.attn.attention.q_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.2.attn.attention.out_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.2.attn.attention.out_proj.bias torch.Size([256]) 256\n",
      "transformer.h.2.ln_2.weight torch.Size([256]) 256\n",
      "transformer.h.2.ln_2.bias torch.Size([256]) 256\n",
      "transformer.h.2.mlp.c_fc.weight torch.Size([1024, 256]) 262144\n",
      "transformer.h.2.mlp.c_fc.bias torch.Size([1024]) 1024\n",
      "transformer.h.2.mlp.c_proj.weight torch.Size([256, 1024]) 262144\n",
      "transformer.h.2.mlp.c_proj.bias torch.Size([256]) 256\n",
      "transformer.h.3.ln_1.weight torch.Size([256]) 256\n",
      "transformer.h.3.ln_1.bias torch.Size([256]) 256\n",
      "transformer.h.3.attn.attention.k_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.3.attn.attention.v_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.3.attn.attention.q_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.3.attn.attention.out_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.3.attn.attention.out_proj.bias torch.Size([256]) 256\n",
      "transformer.h.3.ln_2.weight torch.Size([256]) 256\n",
      "transformer.h.3.ln_2.bias torch.Size([256]) 256\n",
      "transformer.h.3.mlp.c_fc.weight torch.Size([1024, 256]) 262144\n",
      "transformer.h.3.mlp.c_fc.bias torch.Size([1024]) 1024\n",
      "transformer.h.3.mlp.c_proj.weight torch.Size([256, 1024]) 262144\n",
      "transformer.h.3.mlp.c_proj.bias torch.Size([256]) 256\n",
      "transformer.h.4.ln_1.weight torch.Size([256]) 256\n",
      "transformer.h.4.ln_1.bias torch.Size([256]) 256\n",
      "transformer.h.4.attn.attention.k_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.4.attn.attention.v_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.4.attn.attention.q_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.4.attn.attention.out_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.4.attn.attention.out_proj.bias torch.Size([256]) 256\n",
      "transformer.h.4.ln_2.weight torch.Size([256]) 256\n",
      "transformer.h.4.ln_2.bias torch.Size([256]) 256\n",
      "transformer.h.4.mlp.c_fc.weight torch.Size([1024, 256]) 262144\n",
      "transformer.h.4.mlp.c_fc.bias torch.Size([1024]) 1024\n",
      "transformer.h.4.mlp.c_proj.weight torch.Size([256, 1024]) 262144\n",
      "transformer.h.4.mlp.c_proj.bias torch.Size([256]) 256\n",
      "transformer.h.5.ln_1.weight torch.Size([256]) 256\n",
      "transformer.h.5.ln_1.bias torch.Size([256]) 256\n",
      "transformer.h.5.attn.attention.k_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.5.attn.attention.v_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.5.attn.attention.q_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.5.attn.attention.out_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.5.attn.attention.out_proj.bias torch.Size([256]) 256\n",
      "transformer.h.5.ln_2.weight torch.Size([256]) 256\n",
      "transformer.h.5.ln_2.bias torch.Size([256]) 256\n",
      "transformer.h.5.mlp.c_fc.weight torch.Size([1024, 256]) 262144\n",
      "transformer.h.5.mlp.c_fc.bias torch.Size([1024]) 1024\n",
      "transformer.h.5.mlp.c_proj.weight torch.Size([256, 1024]) 262144\n",
      "transformer.h.5.mlp.c_proj.bias torch.Size([256]) 256\n",
      "transformer.h.6.ln_1.weight torch.Size([256]) 256\n",
      "transformer.h.6.ln_1.bias torch.Size([256]) 256\n",
      "transformer.h.6.attn.attention.k_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.6.attn.attention.v_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.6.attn.attention.q_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.6.attn.attention.out_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.6.attn.attention.out_proj.bias torch.Size([256]) 256\n",
      "transformer.h.6.ln_2.weight torch.Size([256]) 256\n",
      "transformer.h.6.ln_2.bias torch.Size([256]) 256\n",
      "transformer.h.6.mlp.c_fc.weight torch.Size([1024, 256]) 262144\n",
      "transformer.h.6.mlp.c_fc.bias torch.Size([1024]) 1024\n",
      "transformer.h.6.mlp.c_proj.weight torch.Size([256, 1024]) 262144\n",
      "transformer.h.6.mlp.c_proj.bias torch.Size([256]) 256\n",
      "transformer.h.7.ln_1.weight torch.Size([256]) 256\n",
      "transformer.h.7.ln_1.bias torch.Size([256]) 256\n",
      "transformer.h.7.attn.attention.k_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.7.attn.attention.v_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.7.attn.attention.q_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.7.attn.attention.out_proj.weight torch.Size([256, 256]) 65536\n",
      "transformer.h.7.attn.attention.out_proj.bias torch.Size([256]) 256\n",
      "transformer.h.7.ln_2.weight torch.Size([256]) 256\n",
      "transformer.h.7.ln_2.bias torch.Size([256]) 256\n",
      "transformer.h.7.mlp.c_fc.weight torch.Size([1024, 256]) 262144\n",
      "transformer.h.7.mlp.c_fc.bias torch.Size([1024]) 1024\n",
      "transformer.h.7.mlp.c_proj.weight torch.Size([256, 1024]) 262144\n",
      "transformer.h.7.mlp.c_proj.bias torch.Size([256]) 256\n",
      "transformer.ln_f.weight torch.Size([256]) 256\n",
      "transformer.ln_f.bias torch.Size([256]) 256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951e555080214f4d94a5fa934a403c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/112M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained('roneneldan/TinyStories-8M')\n",
    "for n,p in model.named_parameters(): print(n, p.shape, p.numel())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".eigenestimation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
