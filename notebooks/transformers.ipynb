{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "import gc\n",
    "\n",
    "# Add the test directory to sys.path\n",
    "parent_dir = os.path.expanduser('..')\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "\n",
    "\n",
    "# Standard library imports\n",
    "import importlib\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "# Third-party imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import GPT2Model, GPT2Config, GPT2Tokenizer\n",
    "from datasets import load_dataset\n",
    "from transformer_lens.utils import tokenize_and_concatenate\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GPT2LMHeadModel\n",
    "import transformer_lens\n",
    "\n",
    "\n",
    "# Reload modules using importlib\n",
    "importlib.reload(importlib.import_module('eigenestimation.eigenhora'))\n",
    "importlib.reload(importlib.import_module('eigenestimation.loss'))\n",
    "importlib.reload(importlib.import_module('eigenestimation.train'))\n",
    "importlib.reload(importlib.import_module('evaluation.examples'))\n",
    "importlib.reload(importlib.import_module('toy_models.transformer_wrapper'))\n",
    "importlib.reload(importlib.import_module('eigenestimation.utils'))\n",
    "\n",
    "\n",
    "\n",
    "from eigenestimation.eigenhora import EigenHora\n",
    "from eigenestimation import loss\n",
    "from eigenestimation.train import Train\n",
    "from evaluation.examples import TopActivatingTexts\n",
    "from toy_models import transformer_wrapper\n",
    "from eigenestimation.utils import TransformDataLoader, DeleteParams, RetrieveWandBArtifact\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model roneneldan/TinyStories-1M into HookedTransformer\n",
      "[('transformer.embed.W_E', 3216448), ('transformer.pos_embed.W_pos', 131072), ('transformer.blocks.0.attn.W_Q', 4096), ('transformer.blocks.0.attn.W_O', 4096), ('transformer.blocks.0.attn.b_Q', 64), ('transformer.blocks.0.attn.b_O', 64), ('transformer.blocks.0.attn.W_K', 4096), ('transformer.blocks.0.attn.W_V', 4096), ('transformer.blocks.0.attn.b_K', 64), ('transformer.blocks.0.attn.b_V', 64), ('transformer.blocks.0.mlp.W_in', 16384), ('transformer.blocks.0.mlp.b_in', 256), ('transformer.blocks.0.mlp.W_out', 16384), ('transformer.blocks.0.mlp.b_out', 64), ('transformer.blocks.1.attn.W_Q', 4096), ('transformer.blocks.1.attn.W_O', 4096), ('transformer.blocks.1.attn.b_Q', 64), ('transformer.blocks.1.attn.b_O', 64), ('transformer.blocks.1.attn.W_K', 4096), ('transformer.blocks.1.attn.W_V', 4096), ('transformer.blocks.1.attn.b_K', 64), ('transformer.blocks.1.attn.b_V', 64), ('transformer.blocks.1.mlp.W_in', 16384), ('transformer.blocks.1.mlp.b_in', 256), ('transformer.blocks.1.mlp.W_out', 16384), ('transformer.blocks.1.mlp.b_out', 64), ('transformer.blocks.2.attn.W_Q', 4096), ('transformer.blocks.2.attn.W_O', 4096), ('transformer.blocks.2.attn.b_Q', 64), ('transformer.blocks.2.attn.b_O', 64), ('transformer.blocks.2.attn.W_K', 4096), ('transformer.blocks.2.attn.W_V', 4096), ('transformer.blocks.2.attn.b_K', 64), ('transformer.blocks.2.attn.b_V', 64), ('transformer.blocks.2.mlp.W_in', 16384), ('transformer.blocks.2.mlp.b_in', 256), ('transformer.blocks.2.mlp.W_out', 16384), ('transformer.blocks.2.mlp.b_out', 64), ('transformer.blocks.3.attn.W_Q', 4096), ('transformer.blocks.3.attn.W_O', 4096), ('transformer.blocks.3.attn.b_Q', 64), ('transformer.blocks.3.attn.b_O', 64), ('transformer.blocks.3.attn.W_K', 4096), ('transformer.blocks.3.attn.W_V', 4096), ('transformer.blocks.3.attn.b_K', 64), ('transformer.blocks.3.attn.b_V', 64), ('transformer.blocks.3.mlp.W_in', 16384), ('transformer.blocks.3.mlp.b_in', 256), ('transformer.blocks.3.mlp.W_out', 16384), ('transformer.blocks.3.mlp.b_out', 64), ('transformer.blocks.4.attn.W_Q', 4096), ('transformer.blocks.4.attn.W_O', 4096), ('transformer.blocks.4.attn.b_Q', 64), ('transformer.blocks.4.attn.b_O', 64), ('transformer.blocks.4.attn.W_K', 4096), ('transformer.blocks.4.attn.W_V', 4096), ('transformer.blocks.4.attn.b_K', 64), ('transformer.blocks.4.attn.b_V', 64), ('transformer.blocks.4.mlp.W_in', 16384), ('transformer.blocks.4.mlp.b_in', 256), ('transformer.blocks.4.mlp.W_out', 16384), ('transformer.blocks.4.mlp.b_out', 64), ('transformer.blocks.5.attn.W_Q', 4096), ('transformer.blocks.5.attn.W_O', 4096), ('transformer.blocks.5.attn.b_Q', 64), ('transformer.blocks.5.attn.b_O', 64), ('transformer.blocks.5.attn.W_K', 4096), ('transformer.blocks.5.attn.W_V', 4096), ('transformer.blocks.5.attn.b_K', 64), ('transformer.blocks.5.attn.b_V', 64), ('transformer.blocks.5.mlp.W_in', 16384), ('transformer.blocks.5.mlp.b_in', 256), ('transformer.blocks.5.mlp.W_out', 16384), ('transformer.blocks.5.mlp.b_out', 64), ('transformer.blocks.6.attn.W_Q', 4096), ('transformer.blocks.6.attn.W_O', 4096), ('transformer.blocks.6.attn.b_Q', 64), ('transformer.blocks.6.attn.b_O', 64), ('transformer.blocks.6.attn.W_K', 4096), ('transformer.blocks.6.attn.W_V', 4096), ('transformer.blocks.6.attn.b_K', 64), ('transformer.blocks.6.attn.b_V', 64), ('transformer.blocks.6.mlp.W_in', 16384), ('transformer.blocks.6.mlp.b_in', 256), ('transformer.blocks.6.mlp.W_out', 16384), ('transformer.blocks.6.mlp.b_out', 64), ('transformer.blocks.7.attn.W_Q', 4096), ('transformer.blocks.7.attn.W_O', 4096), ('transformer.blocks.7.attn.b_Q', 64), ('transformer.blocks.7.attn.b_O', 64), ('transformer.blocks.7.attn.W_K', 4096), ('transformer.blocks.7.attn.W_V', 4096), ('transformer.blocks.7.attn.b_K', 64), ('transformer.blocks.7.attn.b_V', 64), ('transformer.blocks.7.mlp.W_in', 16384), ('transformer.blocks.7.mlp.b_in', 256), ('transformer.blocks.7.mlp.W_out', 16384), ('transformer.blocks.7.mlp.b_out', 64), ('transformer.unembed.W_U', 3216448), ('transformer.unembed.b_U', 50257)]\n",
      "4096\n",
      "transformer.blocks.3.attn.W_K torch.Size([16, 64, 4]) 4096\n",
      "torch.Size([5854, 8])\n"
     ]
    }
   ],
   "source": [
    "# @title Import pretrained gpt2 (2 layers)\n",
    "# Disable fused kernels (FlashAttention and memory-efficient attention)\n",
    "# We have to disable this to compute second-order gradients on transformer models.\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "\n",
    "# Ensure the math kernel is enabled (it is True by default)\n",
    "torch.backends.cuda.enable_math_sdp(True)\n",
    "\n",
    "\n",
    "tinystories_1m  = transformer_lens.HookedTransformer.from_pretrained(\"roneneldan/TinyStories-1M\")#\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "transformer_model = transformer_wrapper.TransformerWrapper(tinystories_1m, tokenizer)\n",
    "\n",
    "\n",
    "print( [(name, param.numel()) for name, param in transformer_model.named_parameters()])\n",
    "\n",
    "\n",
    "# Make the eigenestimation a little smaller but only looking at a subset of the parameters.\n",
    "# Pick a random subset of tensors to include in paramters, and turn the rest into frozen buffers.\n",
    "params_to_delete = [name for name, param in transformer_model.named_parameters()]\n",
    "params_to_delete = [p for p in params_to_delete if #('blocks.4.attn.W' not in p)]# and ('blocks.6.mlp.W' not in p)]#!='transformer.h.1.ln_2.weight']\n",
    "   'transformer.blocks.3.attn.W_K' not in p]#!='transformer.h.1.ln_2.weight']\n",
    "\n",
    "# Delete 3/4 of the parameters.\n",
    "#for p in (params_to_delete[::20]):\n",
    "#  params_to_delete.remove(p)\n",
    "\n",
    "DeleteParams(transformer_model, params_to_delete)\n",
    "\n",
    "print(sum([p.numel() for p in transformer_model.parameters()]))\n",
    "for n,p in transformer_model.named_parameters(): print(n, p.shape, p.numel())\n",
    "\n",
    "# Load in data.\n",
    "dataset = load_dataset('roneneldan/TinyStories', split=\"validation[:1%]\")\n",
    "X_transformer = tokenize_and_concatenate(dataset, transformer_model.tokenizer, max_length = 8, add_bos_token=False)['tokens']\n",
    "print(X_transformer.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenestimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : 70.963,  Reconstruction Loss: 70.963,  Sparsity Loss: 0.001\n",
      "evaluating...\n",
      "TopActivatingTexts\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m TransformDataLoader(X_transformer[::\u001b[38;5;241m10\u001b[39m,:\u001b[38;5;241m4\u001b[39m], batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, transform_fn\u001b[38;5;241m=\u001b[39meigenmodel\u001b[38;5;241m.\u001b[39mcompute_jacobian)\n\u001b[1;32m     15\u001b[0m eval_dataloader \u001b[38;5;241m=\u001b[39m TransformDataLoader(X_transformer[\u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m20\u001b[39m,:\u001b[38;5;241m4\u001b[39m], batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, transform_fn\u001b[38;5;241m=\u001b[39meigenmodel\u001b[38;5;241m.\u001b[39mcompute_jacobian)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43meigenmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL0_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meigenestimation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtiny_stores_transformer_1m\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m      \u001b[49m\u001b[43meval_fns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mTopActivatingTexts\u001b[49m\u001b[43m:\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataloader\u001b[49m\u001b[43m)\u001b[49m    \n",
      "File \u001b[0;32m~/workspace/eigenestimation/notebooks/../eigenestimation/train.py:110\u001b[0m, in \u001b[0;36mTrain\u001b[0;34m(eigenmodel, jacobian_dataloader, lr, n_epochs, L0_penalty, device, project_name, run_name, eval_fns, eval_dataloader)\u001b[0m\n\u001b[1;32m    108\u001b[0m fn_name \u001b[38;5;241m=\u001b[39m fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mprint\u001b[39m(fn_name)\n\u001b[0;32m--> 110\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43meigenmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meval_fns\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    111\u001b[0m artifact \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39mArtifact(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproject_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval-metrics\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    112\u001b[0m artifact\u001b[38;5;241m.\u001b[39madd_file(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/workspace/eigenestimation/notebooks/../evaluation/examples.py:65\u001b[0m, in \u001b[0;36mTopActivatingTexts\u001b[0;34m(eigenmodel, dataloader, top_n, feature_idxs, bold_char, to_print)\u001b[0m\n\u001b[1;32m     63\u001b[0m         text \u001b[38;5;241m=\u001b[39m eigenmodel\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mdecode(to_decode)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m to_print: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{text}\u001b[39;00m\u001b[38;5;124m -> \u001b[39m\u001b[38;5;132;01m{jvp_val}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m         \u001b[43mtop_n_X_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m (jvp_val, x, token_idx, text)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m top_n_X_values\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "def transformer_model0(y):\n",
    "    return torch.ones_like(y).softmax(dim=-1)\n",
    "\n",
    "\n",
    "hora_features = 20\n",
    "hora_rank = 1\n",
    "\n",
    "eigenmodel = EigenHora(transformer_model, transformer_model0, loss.KLDivergenceLoss(), hora_features, hora_rank, device=device).to(device)\n",
    "dataloader = TransformDataLoader(X_transformer[::10,:4], batch_size=8, transform_fn=eigenmodel.compute_jacobian)\n",
    "eval_dataloader = TransformDataLoader(X_transformer[1::20,:4], batch_size=8, transform_fn=eigenmodel.compute_jacobian)\n",
    "\n",
    "run_name =  'tiny_stores_transformer_1m'\n",
    "Train(eigenmodel, dataloader, lr=.01, n_epochs=1, L0_penalty=.01, device=device, project_name='eigenestimation', run_name=run_name,\n",
    "      eval_fns={TopActivatingTexts:[3]}, eval_dataloader=eval_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : 70.176,  Reconstruction Loss: 70.176,  Sparsity Loss: 0.000\n",
      "evaluating...\n",
      "TopActivatingTexts\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>reconstruction_loss</td><td>▁▃█▄</td></tr><tr><td>sparsity_loss</td><td>█▇▁▁</td></tr><tr><td>total_loss</td><td>▁▃█▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>reconstruction_loss</td><td>70.17616</td></tr><tr><td>sparsity_loss</td><td>4e-05</td></tr><tr><td>total_loss</td><td>70.17616</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">tiny_stores_transformer_1m</strong> at: <a href='https://wandb.ai/brianna-chrisman-2024/Eigenestimation/runs/dit0h92r' target=\"_blank\">https://wandb.ai/brianna-chrisman-2024/Eigenestimation/runs/dit0h92r</a><br> View project at: <a href='https://wandb.ai/brianna-chrisman-2024/Eigenestimation' target=\"_blank\">https://wandb.ai/brianna-chrisman-2024/Eigenestimation</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241218_202216-dit0h92r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Train(eigenmodel, dataloader, lr=.01, n_epochs=1, L0_penalty=.01, device=device, project_name='eigenestimation', run_name=run_name,\n",
    "      eval_fns={TopActivatingTexts:[3]}, eval_dataloader=eval_dataloader)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/workspace/eigenestimation/notebooks/artifacts/eigenestimation_tiny_stores_transformer_1m_TopActivatingTexts:v0\n"
     ]
    }
   ],
   "source": [
    "top_texts = RetrieveWandBArtifact(project_path=f\"brianna-chrisman-2024/Eigenestimation/eigenestimation_{run_name}\", metric_name=\"TopActivatingTexts\")\n",
    "for feature_idx in top_texts:\n",
    "    print(f'-----f{feature_idx}------')\n",
    "    for val, _, _, text in top_texts[feature_idx]:\n",
    "        print(f'{text}->{round(val, 5)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
