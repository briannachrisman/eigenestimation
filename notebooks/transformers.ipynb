{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remember to login to wandb!\n",
    "import sys\n",
    "import os \n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import copy \n",
    "import numpy as np\n",
    "import gc\n",
    "import itertools\n",
    "# Append module directory for imports\n",
    "parent_dir = os.path.expanduser('../eigenestimation/eigenestimation')\n",
    "\n",
    "from eigenestimation.evaluation.networks import DrawNeuralNetwork\n",
    "from eigenestimation.eigenmodel.eigenmodel import EigenModel\n",
    "from eigenestimation.utils.loss import MSELoss\n",
    "from eigenestimation.utils.uniform_models import ZeroOutput\n",
    "from eigenestimation.toy_models.data import GenerateTMSInputs\n",
    "from eigenestimation.toy_models.parallel_serial_network import CustomMLP\n",
    "from torch import Tensor\n",
    "import einops\n",
    "\n",
    "import figure_names\n",
    "from datasets import load_dataset\n",
    "from transformer_lens.utils import tokenize_and_concatenate\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenmodel_path = f\"../outputs/eigenmodels/transformer.pt\"\n",
    "eigenmodel = torch.load(eigenmodel_path)['model']\n",
    "tokenizer = eigenmodel.model.tokenizer\n",
    "frac_activated = torch.load(eigenmodel_path)['frac_activated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tinystories data\n",
    "token_length = 16\n",
    "dataset = load_dataset('roneneldan/TinyStories', split=\"validation[:1%]\")\n",
    "X_transformer = tokenize_and_concatenate(dataset, tokenizer, max_length = token_length, add_bos_token=False)['tokens']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_vals = []\n",
    "X_ordered = []\n",
    "iters = 5\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "for X_batch in DataLoader(X_transformer[:1000], batch_size=8, shuffle=True):\n",
    "    X_ordered.append(X_batch)\n",
    "        # Compute gradients many times and take the average\n",
    "    each_circuit_val = torch.zeros(X_batch.shape[0]*X_batch.shape[1], eigenmodel.n_features).to('cuda')\n",
    "    for _ in range(iters):\n",
    "        grads = eigenmodel.compute_gradients(X_batch.to('cuda'))\n",
    "        each_circuit_val = each_circuit_val + abs(eigenmodel(grads))\n",
    "    circuit_vals.append(each_circuit_val.view(X_batch.shape[0], X_batch.shape[1], eigenmodel.n_features))\n",
    "circuit_vals = torch.concat(circuit_vals, dim=0)/iters\n",
    "X_ordered = torch.concat(X_ordered, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---- Feature 0 ---- Activation: 0.203\n",
      " \"I don***'t*** like the man with the whip. He makes me roar.\" --> 49.43\n",
      " Lily got upset. She didn***'t*** trust Timmy anymore.=newline==newline=Lily --> 47.91\n",
      " not get up. The goat did*** not*** survive the hot day. The end.< --> 46.88\n",
      ", Spot's owner, a little girl named Lily, did*** not*** permit Spot to --> 45.14\n",
      " cereal for breakfast every day. One day, her friend Timmy came*** over*** to --> 43.79\n",
      "\n",
      "\n",
      "---- Feature 2 ---- Activation: 0.392\n",
      " Timmy didn't like that. He wanted his truck to be*** the*** best. --> 92.37\n",
      " saw a cat on a tree. He wanted to be friends with*** the*** cat. --> 85.11\n",
      " lunch, Lily went to play with her toys. She*** was*** playing with her toy --> 84.17\n",
      "=newline==newline=Max did not want to give up. But*** Tom*** and Sam were brave --> 83.32\n",
      " happy that he was not*** sm***elly anymore. They played together in the sea. --> 76.97\n",
      "\n",
      "\n",
      "---- Feature 4 ---- Activation: 0.402\n",
      " poured it over Ducky. =newline==newline=Ducky was*** happy*** to be clean --> 90.70\n",
      " named Lily. She loved to play outside in the sun*** with*** her friends. One --> 71.58\n",
      ", but it was very slippery***.*** She tried again and again, but she kept --> 65.15\n",
      " end.Once upon a time, there*** was*** a kind man named Tom. Tom --> 64.36\n",
      " clothes in the machine and then put them in*** the*** dryer to make them dry --> 64.04\n",
      "\n",
      "\n",
      "---- Feature 5 ---- Activation: 0.159\n",
      "=newline==newline=But then, Sammy got a little too playful***.*** He started throwing the --> 52.57\n",
      " would not go in.=newline==newline=Then, Spot had an idea***.*** He --> 48.35\n",
      ", there was a little boy named Tom***.*** He loved to play with his red --> 47.99\n",
      " around when he saw a big, bitter fruit on a branch***.*** =newline==newline= --> 45.67\n",
      ", Jack went outside to play and saw that the ground was covered in snow***.*** --> 44.56\n",
      "\n",
      "\n",
      "---- Feature 6 ---- Activation: 0.187\n",
      ". He picked*** it*** up and looked at it closely. The key was shiny and --> 58.30\n",
      " so happy! He ran around*** with*** it and showed it to all his friends. --> 54.56\n",
      " Lily felt happy*** that*** they could help.=newline==newline=Later that day, Lily --> 51.43\n",
      " mom was proud of her*** for*** being kind and sharing.=newline==newline=The next day --> 46.96\n",
      " mom was proud of her for*** being*** kind and sharing.=newline==newline=The next day --> 45.59\n",
      "\n",
      "\n",
      "---- Feature 8 ---- Activation: 0.172\n",
      " Timmy didn't like that. He wanted his truck to be*** the*** best. --> 47.57\n",
      " watch where he was going and tripped over a rock.=newline==newline=Max***'s*** --> 46.07\n",
      " saw a cat on a tree. He wanted to be friends with*** the*** cat. --> 44.80\n",
      " goat was thirsty and wanted to go inside. But*** the*** door was shut. The --> 44.27\n",
      " Lily. She had a puppy named Max who was*** her*** best friend. One day --> 42.97\n",
      "\n",
      "\n",
      "---- Feature 9 ---- Activation: 0.160\n",
      ", \"Let's look for it together.\"=newline==newline=They looked*** and*** looked, --> 44.37\n",
      "|endoftext|>Once upon a time,*** there*** was a little girl --> 39.42\n",
      " too because she helped the bird. From that day on, Lily and*** Max*** went --> 36.36\n",
      " bear.Once upon a*** time***, there was a man who lived in a big --> 35.69\n",
      ". From that day on, Buzzy was*** not*** a naughty bee anymore, and --> 35.62\n",
      "\n",
      "\n",
      "---- Feature 10 ---- Activation: 0.464\n",
      " went to the park*** to*** play.=newline==newline=While playing, Tom saw a big --> 82.97\n",
      " oats to be strong.Once upon a time, there was a little boy*** named*** --> 76.40\n",
      " friends laughed and teased him, but Max didn't mind***.*** He got up and --> 74.49\n",
      " showed it off to her friends when they came over to play. Lily*** was*** grateful --> 73.85\n",
      " found a big box*** and*** put it under the tree. Max climbed on the box --> 72.15\n",
      "\n",
      "\n",
      "---- Feature 13 ---- Activation: 0.401\n",
      " time, there was a girl*** named*** Mia. Mia loved her jewelry. She h --> 74.70\n",
      ", Tom found his ball near a big tree. He was very*** happy***. Tom --> 74.34\n",
      " to his mom and be careful when playing outside.Once upon a time***,*** there --> 70.68\n",
      " always want more.Once upon a time, there was a little boy*** named*** Tim --> 70.66\n",
      " told*** her*** that if she drew a picture of their house, she would get a --> 70.49\n",
      "\n",
      "\n",
      "---- Feature 14 ---- Activation: 0.321\n",
      ", Lily went to Timmy's house to play. She saw that Tim***my*** --> 76.11\n",
      " Spot. Spot had a toy skull*** that*** he loved to play with. He would --> 74.64\n",
      " play. Lily*** had*** a big bowl of cereal, but Timmy didn't have --> 68.37\n",
      " One day***,*** she saw a snake in the garden. The snake was very long --> 61.08\n",
      " wanted the same toy too. She*** asked*** Emily if she could play with it, --> 58.76\n",
      "\n",
      "\n",
      "---- Feature 16 ---- Activation: 0.312\n",
      ". One day, Buzzy saw a little girl*** named*** Lucy sitting on the grass --> 67.58\n",
      ".Once upon a time, there was a little girl*** named*** Lily. She loved --> 64.74\n",
      " even higher!Once upon a time***,*** there was a big, strong robot made --> 63.43\n",
      " before! The end.Once upon a time***,*** there was a little girl named --> 61.87\n",
      " The end.Once upon a time***,*** there was a little girl named Lily. --> 61.68\n",
      "\n",
      "\n",
      "---- Feature 17 ---- Activation: 0.337\n",
      " in the video!\" Tom laughed and said, \"I can try!\"=newline=***=newline=*** --> 71.94\n",
      " to play in the garden and eat carrots. One*** day***, while Fluffy was --> 63.45\n",
      " Sam was angry. He said, \"I don***'t*** like this game. I --> 62.42\n",
      " Kitty and Spot*** felt*** thirsty. They found a small pond with clear water. They --> 61.78\n",
      ".\"=newline=***=newline=***Toot thought about what Puff said. The next day, --> 61.30\n",
      "\n",
      "\n",
      "---- Feature 18 ---- Activation: 0.151\n",
      ", there was a little boy named Tom. He loved to play*** with*** his red --> 44.57\n",
      " He loved to play*** with*** his ball in the park. One sunny day, Spot --> 39.53\n",
      " Ducky. Ducky loved to play in the pond*** with*** his friends. One --> 39.07\n",
      " \"I promise to take care of your ball. You can play*** with*** it when --> 37.35\n",
      "One day, a little boy named Tim*** found*** a big, red truck. The --> 37.16\n",
      "\n",
      "\n",
      "---- Feature 20 ---- Activation: 0.165\n",
      "ety.=newline==newline=Fluffy and Tweety went through*** the*** hole in the fence --> 45.55\n",
      " there was a little girl named Lily. She loved to play in*** the*** soil and --> 43.63\n",
      "One day, a little boy*** named*** Tim found a big, red truck. The --> 41.83\n",
      " her feelings. She continued*** to*** go for walks in the park every day.  --> 41.62\n",
      ". His name was Max. Max liked to play in*** the*** yard. Daisy liked --> 40.83\n",
      "\n",
      "\n",
      "---- Feature 21 ---- Activation: 0.298\n",
      ".Once upon a time***,*** there was a little girl named Lily. She loved --> 69.98\n",
      " a girl named Lily and a boy named Tom were playing in their room***.*** They --> 65.40\n",
      " in the park with her friends.*** They*** were running and laughing on the grass when --> 62.15\n",
      "=newline==newline=But then, Sammy got a little too playful***.*** He started throwing the --> 60.30\n",
      " from the dangerous land.Once upon a time***,*** there was a big dog named --> 59.40\n",
      "\n",
      "\n",
      "---- Feature 23 ---- Activation: 0.330\n",
      ".Once upon a time, there was a little girl named*** Lily***. She loved --> 61.40\n",
      " touch it because it was fragile and could get hurt easily. Lily listened*** to*** --> 60.38\n",
      " thank you. Lily*** was*** so happy and she couldn't believe that the man remembered --> 57.01\n",
      " cat. =newline==newline=The cat led Timmy to a bush*** where*** his toy --> 56.82\n",
      " cake and thanked Lily for her hard work. Lily felt happy and proud to*** be*** --> 56.60\n",
      "\n",
      "\n",
      "---- Feature 24 ---- Activation: 0.147\n",
      " The end.Once upon a time***,*** there was a little girl named Lily. --> 56.74\n",
      " before! The end.Once upon a time, there*** was*** a little girl named --> 52.36\n",
      " from the dangerous land.Once upon a time***,*** there was a big dog named --> 47.85\n",
      " oats to be strong.Once upon a time***,*** there was a little boy named --> 47.72\n",
      " to go home. His friend asked him what*** was*** wrong. The lion said, --> 46.98\n",
      "\n",
      "\n",
      "---- Feature 25 ---- Activation: 0.138\n",
      " saw a big tree.*** He*** dared Mittens to climb the tree with him. --> 53.46\n",
      " the next day, Timmy didn't want to go swimming anymore.*** He*** was --> 47.77\n",
      ".Once upon a time, there was a little girl named Lily.*** She*** loved --> 47.12\n",
      " Tim. Tim was very intelligent.*** He*** knew how to do many things that other --> 45.30\n",
      " girl named Lily.*** She*** was very scared of the dark and had a nightmare every --> 43.68\n",
      "\n",
      "\n",
      "---- Feature 26 ---- Activation: 0.549\n",
      ", there was a little boy named Tom. He loved to play*** with*** his red --> 112.89\n",
      " Tim. Tim was very intelligent. He*** knew*** how to do many things that other --> 99.50\n",
      " felt bad and wanted to say sorry. She went to*** her*** friend and said, --> 98.30\n",
      " He loved to play*** with*** his ball in the park. One sunny day, Spot --> 93.53\n",
      "=newline=One day, Lily's*** mom*** said it was time to pick the vegetables for --> 91.18\n",
      "\n",
      "\n",
      "---- Feature 27 ---- Activation: 0.225\n",
      " other, happy*** to*** have spent the day swinging in the yard.One day, --> 93.41\n",
      "=newline=Lily nodded and Timmy reached out*** to*** touch the flower. But as --> 77.04\n",
      "=newline=The lion was happy*** to*** leave the circus. He gave his ticket to the --> 76.80\n",
      " Lily's mom took her*** to*** the zoo. They saw lots of animals, but --> 71.87\n",
      " untied! Timmy didn't know how*** to*** tie his shoes yet, so --> 71.51\n",
      "\n",
      "\n",
      "---- Feature 29 ---- Activation: 0.441\n",
      " cat for helping him find his toy. From*** that*** day on, Timmy knew --> 97.95\n",
      " The owl said, \"That***'s*** a persimmon fruit. It's very --> 74.95\n",
      " without his favorite cartoons. Tim's mom tried*** to*** cheer him up by playing games --> 71.67\n",
      " He went*** to*** her and asked her what was wrong. She said that she --> 68.60\n",
      ". But at night, she had to sleep.***=newline=***=newline=One day, Mia --> 67.67\n",
      "\n",
      "\n",
      "---- Feature 30 ---- Activation: 0.297\n",
      " found a big box and put it under the tree. Max climbed on*** the*** box --> 60.72\n",
      ". Ducky tripped*** and*** fell into the mud. =newline==newline=Ducky --> 59.44\n",
      " Lily's favorite*** were*** the monkeys. They were swinging and jumping from tree to tree --> 55.66\n",
      " the treasure with you.\" Max thought about it*** and*** agreed. They all worked together --> 53.04\n",
      " ball and it popped. Tim was very sad, and Sue was*** sorry***. The --> 52.62\n",
      "\n",
      "\n",
      "---- Feature 32 ---- Activation: 0.477\n",
      " saw a little box under a tree***.*** He tried the key and it opened the --> 95.08\n",
      " a big, scary pirate named Max. Max wanted the treasure too***.*** Tom said --> 91.55\n",
      "'s friend, Timmy, came over and saw the flower too***.*** \"That --> 84.09\n",
      " long.Once upon a time, there was a little boy named Tim***.*** Tim --> 82.21\n",
      ", he found a new truck that he really liked.*** It*** was big and --> 81.65\n",
      "\n",
      "\n",
      "---- Feature 37 ---- Activation: 0.172\n",
      ".Once upon a time, there was a little girl*** named*** Mia. --> 52.35\n",
      " showed it off to her friends when they came over to play. Lily*** was*** grateful --> 46.09\n",
      ", \"Max, we found the treasure first. Please*** let*** us have it.\" --> 45.48\n",
      " little girl named Lucy. She had a pet cat named Tom.*** They*** loved to --> 41.78\n",
      " touch it because it was fragile and could get hurt easily. Lily listened*** to*** --> 38.80\n",
      "\n",
      "\n",
      "---- Feature 38 ---- Activation: 0.351\n",
      "***.*** The end.Once upon a time, there was a big lion. He --> 75.25\n",
      " \"I don***'t*** like the man with the whip. He makes me roar.\" --> 68.15\n",
      " a little girl named Lily. She went on a tour with her family to*** see*** --> 65.05\n",
      " zebra***!*** It's so different from the others!\" =newline==newline= --> 63.83\n",
      " a time, there was a little boy*** named*** Timmy. Timmy had a --> 63.36\n",
      "\n",
      "\n",
      "---- Feature 39 ---- Activation: 0.430\n",
      " a strong man named Jack. Jack loved to play in*** the*** snow. One day --> 107.27\n",
      " play and run in the park with his friends.***=newline=***=newline=One day, Max --> 94.05\n",
      " big, yummy cake for her best friend's birthday.***=newline=***=newline=Lily --> 92.11\n",
      ". He was very happy and ran to the store.***=newline=***=newline=Inside the store --> 91.62\n",
      "One day, a little chick got lost in the hay***.*** The chick was scared --> 88.88\n",
      "\n",
      "\n",
      "---- Feature 43 ---- Activation: 0.274\n",
      " ball.*** One*** sunny day, Tom went outside to play with his ball in the --> 78.81\n",
      " and their owners. =newline=***=newline=***Suddenly, a judge came to the park and --> 63.46\n",
      " her mommy said, trying to calm her down.=newline=***=newline=***The earthquake caused --> 56.60\n",
      " her mom if they could buy it, but her mom said*** no***. Lily was --> 55.45\n",
      " he loved his flute so much***.***=newline==newline=Timmy's mom saw how --> 54.53\n",
      "\n",
      "\n",
      "---- Feature 45 ---- Activation: 0.295\n",
      " time, there*** was*** a little girl named Lily. She loved to sit on her --> 61.90\n",
      " but it was too old and broken.=newline==newline=Tim's mom couldn***'t*** buy --> 60.51\n",
      ", Lily went to Timmy's house to play. She saw*** that*** Timmy --> 59.95\n",
      ", Lily and Max went*** to*** the park to play. They saw many other dogs --> 57.00\n",
      " then Tim hurt his foot. He was sad and didn't want*** to*** play anymore --> 56.84\n",
      "\n",
      "\n",
      "---- Feature 46 ---- Activation: 0.404\n",
      ", there was a little girl named Lily. She loved going*** to*** the zoo with --> 78.40\n",
      " poured it over Ducky. =newline==newline=Ducky was happy to*** be*** clean --> 72.70\n",
      " on the icy hill all day. From that day on, Roxy*** and*** Billy --> 72.50\n",
      " out in pain. Her mommy*** came*** to help her and put some cool water --> 67.19\n",
      " friends.Once upon a time***,*** in a big forest, there lived a rh --> 63.75\n",
      "\n",
      "\n",
      "---- Feature 47 ---- Activation: 0.357\n",
      " Lily got upset. She didn***'t*** trust Timmy anymore.=newline==newline=Lily --> 72.20\n",
      " \"I don***'t*** like the man with the whip. He makes me roar.\" --> 65.52\n",
      " wish I had a camera too.\" Tim***my*** felt proud and happy. He wasn --> 63.13\n",
      " they say sorry too. They played*** together*** in the palace and had lots of fun --> 62.94\n",
      "my. Timmy loved to play with his toy cars and*** trucks***. One day --> 62.14\n",
      "\n",
      "\n",
      "---- Feature 48 ---- Activation: 0.619\n",
      " named Lily. She loved to play outside in the sun*** with*** her friends. One --> 149.25\n",
      " so happy. He and Buddy played together all day long.Once upon a*** time*** --> 126.10\n",
      " is better than fighting. And they all became good friends.One*** day***, a --> 122.06\n",
      " He loved to play with his ball in the park. One sunny*** day***, Spot --> 118.54\n",
      " play outside. One*** day***, he put on his favorite shoes and went outside to --> 116.75\n",
      "\n",
      "\n",
      "---- Feature 49 ---- Activation: 0.229\n",
      "|endoftext|>Once upon a time,*** there*** was a little girl --> 70.41\n",
      " friends.Once upon a time, in a big forest,*** there*** lived a rh --> 57.30\n",
      " there was a little girl named*** Lily***. She loved to help her mom in the --> 51.93\n",
      " time, there was a little girl named Lily***.*** She loved to sit on her --> 50.50\n",
      " a time, there was a little boy*** named*** Timmy. Timmy had a --> 50.13\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "bold_idx = tokenizer.encode('***')\n",
    "\n",
    "for i in range(eigenmodel.n_features):\n",
    "    if frac_activated[i] < 0.05:\n",
    "        continue\n",
    "    \n",
    "    # Get the absolute values for feature i\n",
    "    abs_vals = (circuit_vals[..., i])\n",
    "\n",
    "    # Find the top 5 (b, t) indices for feature i\n",
    "    top_indices = abs_vals.flatten().argsort(descending=True)[:5]\n",
    "    \n",
    "    # Convert the flat indices back to (b, t) indices\n",
    "    top_b, top_t = torch.div(top_indices, token_length, rounding_mode='floor'), top_indices % token_length\n",
    "\n",
    "    # Get the corresponding top values\n",
    "    top_values = abs_vals[top_b, top_t]\n",
    "\n",
    "    print(f'\\n\\n---- Feature {i} ---- Activation: {frac_activated[i]:.3f}')\n",
    "    for j in range(len(top_indices)):\n",
    "        sample_idx = top_b[j].item()\n",
    "        token_idx = top_t[j].item()\n",
    "        tokens = X_ordered[sample_idx]\n",
    "        tokens = torch.cat([tokens[:token_idx], torch.Tensor(bold_idx), tokens[token_idx:]])\n",
    "        tokens = torch.cat([tokens[:(token_idx+2)], torch.Tensor(bold_idx), tokens[(token_idx+2):]])\n",
    "        sentence = tokenizer.decode(tokens.long())\n",
    "        sentence = sentence.replace('\\n', '=newline=')\n",
    "        print(sentence, '-->', f'{top_values[j].item():.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.eigenestimation/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight torch.Size([50257, 64]) 3216448\n",
      "transformer.wpe.weight torch.Size([2048, 64]) 131072\n",
      "transformer.h.0.ln_1.weight torch.Size([64]) 64\n",
      "transformer.h.0.ln_1.bias torch.Size([64]) 64\n",
      "transformer.h.0.attn.attention.k_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.0.attn.attention.v_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.0.attn.attention.q_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.0.attn.attention.out_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.0.attn.attention.out_proj.bias torch.Size([64]) 64\n",
      "transformer.h.0.ln_2.weight torch.Size([64]) 64\n",
      "transformer.h.0.ln_2.bias torch.Size([64]) 64\n",
      "transformer.h.0.mlp.c_fc.weight torch.Size([256, 64]) 16384\n",
      "transformer.h.0.mlp.c_fc.bias torch.Size([256]) 256\n",
      "transformer.h.0.mlp.c_proj.weight torch.Size([64, 256]) 16384\n",
      "transformer.h.0.mlp.c_proj.bias torch.Size([64]) 64\n",
      "transformer.h.1.ln_1.weight torch.Size([64]) 64\n",
      "transformer.h.1.ln_1.bias torch.Size([64]) 64\n",
      "transformer.h.1.attn.attention.k_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.1.attn.attention.v_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.1.attn.attention.q_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.1.attn.attention.out_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.1.attn.attention.out_proj.bias torch.Size([64]) 64\n",
      "transformer.h.1.ln_2.weight torch.Size([64]) 64\n",
      "transformer.h.1.ln_2.bias torch.Size([64]) 64\n",
      "transformer.h.1.mlp.c_fc.weight torch.Size([256, 64]) 16384\n",
      "transformer.h.1.mlp.c_fc.bias torch.Size([256]) 256\n",
      "transformer.h.1.mlp.c_proj.weight torch.Size([64, 256]) 16384\n",
      "transformer.h.1.mlp.c_proj.bias torch.Size([64]) 64\n",
      "transformer.h.2.ln_1.weight torch.Size([64]) 64\n",
      "transformer.h.2.ln_1.bias torch.Size([64]) 64\n",
      "transformer.h.2.attn.attention.k_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.2.attn.attention.v_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.2.attn.attention.q_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.2.attn.attention.out_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.2.attn.attention.out_proj.bias torch.Size([64]) 64\n",
      "transformer.h.2.ln_2.weight torch.Size([64]) 64\n",
      "transformer.h.2.ln_2.bias torch.Size([64]) 64\n",
      "transformer.h.2.mlp.c_fc.weight torch.Size([256, 64]) 16384\n",
      "transformer.h.2.mlp.c_fc.bias torch.Size([256]) 256\n",
      "transformer.h.2.mlp.c_proj.weight torch.Size([64, 256]) 16384\n",
      "transformer.h.2.mlp.c_proj.bias torch.Size([64]) 64\n",
      "transformer.h.3.ln_1.weight torch.Size([64]) 64\n",
      "transformer.h.3.ln_1.bias torch.Size([64]) 64\n",
      "transformer.h.3.attn.attention.k_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.3.attn.attention.v_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.3.attn.attention.q_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.3.attn.attention.out_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.3.attn.attention.out_proj.bias torch.Size([64]) 64\n",
      "transformer.h.3.ln_2.weight torch.Size([64]) 64\n",
      "transformer.h.3.ln_2.bias torch.Size([64]) 64\n",
      "transformer.h.3.mlp.c_fc.weight torch.Size([256, 64]) 16384\n",
      "transformer.h.3.mlp.c_fc.bias torch.Size([256]) 256\n",
      "transformer.h.3.mlp.c_proj.weight torch.Size([64, 256]) 16384\n",
      "transformer.h.3.mlp.c_proj.bias torch.Size([64]) 64\n",
      "transformer.h.4.ln_1.weight torch.Size([64]) 64\n",
      "transformer.h.4.ln_1.bias torch.Size([64]) 64\n",
      "transformer.h.4.attn.attention.k_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.4.attn.attention.v_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.4.attn.attention.q_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.4.attn.attention.out_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.4.attn.attention.out_proj.bias torch.Size([64]) 64\n",
      "transformer.h.4.ln_2.weight torch.Size([64]) 64\n",
      "transformer.h.4.ln_2.bias torch.Size([64]) 64\n",
      "transformer.h.4.mlp.c_fc.weight torch.Size([256, 64]) 16384\n",
      "transformer.h.4.mlp.c_fc.bias torch.Size([256]) 256\n",
      "transformer.h.4.mlp.c_proj.weight torch.Size([64, 256]) 16384\n",
      "transformer.h.4.mlp.c_proj.bias torch.Size([64]) 64\n",
      "transformer.h.5.ln_1.weight torch.Size([64]) 64\n",
      "transformer.h.5.ln_1.bias torch.Size([64]) 64\n",
      "transformer.h.5.attn.attention.k_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.5.attn.attention.v_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.5.attn.attention.q_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.5.attn.attention.out_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.5.attn.attention.out_proj.bias torch.Size([64]) 64\n",
      "transformer.h.5.ln_2.weight torch.Size([64]) 64\n",
      "transformer.h.5.ln_2.bias torch.Size([64]) 64\n",
      "transformer.h.5.mlp.c_fc.weight torch.Size([256, 64]) 16384\n",
      "transformer.h.5.mlp.c_fc.bias torch.Size([256]) 256\n",
      "transformer.h.5.mlp.c_proj.weight torch.Size([64, 256]) 16384\n",
      "transformer.h.5.mlp.c_proj.bias torch.Size([64]) 64\n",
      "transformer.h.6.ln_1.weight torch.Size([64]) 64\n",
      "transformer.h.6.ln_1.bias torch.Size([64]) 64\n",
      "transformer.h.6.attn.attention.k_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.6.attn.attention.v_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.6.attn.attention.q_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.6.attn.attention.out_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.6.attn.attention.out_proj.bias torch.Size([64]) 64\n",
      "transformer.h.6.ln_2.weight torch.Size([64]) 64\n",
      "transformer.h.6.ln_2.bias torch.Size([64]) 64\n",
      "transformer.h.6.mlp.c_fc.weight torch.Size([256, 64]) 16384\n",
      "transformer.h.6.mlp.c_fc.bias torch.Size([256]) 256\n",
      "transformer.h.6.mlp.c_proj.weight torch.Size([64, 256]) 16384\n",
      "transformer.h.6.mlp.c_proj.bias torch.Size([64]) 64\n",
      "transformer.h.7.ln_1.weight torch.Size([64]) 64\n",
      "transformer.h.7.ln_1.bias torch.Size([64]) 64\n",
      "transformer.h.7.attn.attention.k_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.7.attn.attention.v_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.7.attn.attention.q_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.7.attn.attention.out_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.7.attn.attention.out_proj.bias torch.Size([64]) 64\n",
      "transformer.h.7.ln_2.weight torch.Size([64]) 64\n",
      "transformer.h.7.ln_2.bias torch.Size([64]) 64\n",
      "transformer.h.7.mlp.c_fc.weight torch.Size([256, 64]) 16384\n",
      "transformer.h.7.mlp.c_fc.bias torch.Size([256]) 256\n",
      "transformer.h.7.mlp.c_proj.weight torch.Size([64, 256]) 16384\n",
      "transformer.h.7.mlp.c_proj.bias torch.Size([64]) 64\n",
      "transformer.ln_f.weight torch.Size([64]) 64\n",
      "transformer.ln_f.bias torch.Size([64]) 64\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained('roneneldan/TinyStories-1M')\n",
    "for n,p in model.named_parameters(): print(n, p.shape, p.numel())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".eigenestimation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
