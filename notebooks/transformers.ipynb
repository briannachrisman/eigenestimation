{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "\n",
    "# Add the test directory to sys.path\n",
    "parent_dir = os.path.expanduser('~/eigenestimation')\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "\n",
    "\n",
    "# Standard library imports\n",
    "import importlib\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "# Third-party imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import GPT2Model, GPT2Config, GPT2Tokenizer\n",
    "from datasets import load_dataset\n",
    "from transformer_lens.utils import tokenize_and_concatenate\n",
    "\n",
    "\n",
    "\n",
    "# Reload modules using importlib\n",
    "importlib.reload(importlib.import_module('eigenestimation.eigenhora'))\n",
    "importlib.reload(importlib.import_module('eigenestimation.loss'))\n",
    "importlib.reload(importlib.import_module('eigenestimation.train'))\n",
    "importlib.reload(importlib.import_module('evaluation.activating_examples'))\n",
    "importlib.reload(importlib.import_module('toy_models.transformer_wrapper'))\n",
    "importlib.reload(importlib.import_module('eigenestimation.utils'))\n",
    "\n",
    "\n",
    "\n",
    "from eigenestimation.eigenhora import EigenHora\n",
    "from eigenestimation import loss\n",
    "from eigenestimation.train import Train\n",
    "from evaluation.activating_examples import DrawNeuralNetwork\n",
    "from toy_models import transformer_wrapper\n",
    "from eigenestimation.utils import TransformDataLoader, DeleteParams\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model roneneldan/TinyStories-1M into HookedTransformer\n",
      "Loaded pretrained model roneneldan/TinyStories-33M into HookedTransformer\n",
      "[('transformer.embed.W_E', 38597376), ('transformer.pos_embed.W_pos', 1572864), ('transformer.blocks.0.attn.W_Q', 589824), ('transformer.blocks.0.attn.W_O', 589824), ('transformer.blocks.0.attn.b_Q', 768), ('transformer.blocks.0.attn.b_O', 768), ('transformer.blocks.0.attn.W_K', 589824), ('transformer.blocks.0.attn.W_V', 589824), ('transformer.blocks.0.attn.b_K', 768), ('transformer.blocks.0.attn.b_V', 768), ('transformer.blocks.0.mlp.W_in', 2359296), ('transformer.blocks.0.mlp.b_in', 3072), ('transformer.blocks.0.mlp.W_out', 2359296), ('transformer.blocks.0.mlp.b_out', 768), ('transformer.blocks.1.attn.W_Q', 589824), ('transformer.blocks.1.attn.W_O', 589824), ('transformer.blocks.1.attn.b_Q', 768), ('transformer.blocks.1.attn.b_O', 768), ('transformer.blocks.1.attn.W_K', 589824), ('transformer.blocks.1.attn.W_V', 589824), ('transformer.blocks.1.attn.b_K', 768), ('transformer.blocks.1.attn.b_V', 768), ('transformer.blocks.1.mlp.W_in', 2359296), ('transformer.blocks.1.mlp.b_in', 3072), ('transformer.blocks.1.mlp.W_out', 2359296), ('transformer.blocks.1.mlp.b_out', 768), ('transformer.blocks.2.attn.W_Q', 589824), ('transformer.blocks.2.attn.W_O', 589824), ('transformer.blocks.2.attn.b_Q', 768), ('transformer.blocks.2.attn.b_O', 768), ('transformer.blocks.2.attn.W_K', 589824), ('transformer.blocks.2.attn.W_V', 589824), ('transformer.blocks.2.attn.b_K', 768), ('transformer.blocks.2.attn.b_V', 768), ('transformer.blocks.2.mlp.W_in', 2359296), ('transformer.blocks.2.mlp.b_in', 3072), ('transformer.blocks.2.mlp.W_out', 2359296), ('transformer.blocks.2.mlp.b_out', 768), ('transformer.blocks.3.attn.W_Q', 589824), ('transformer.blocks.3.attn.W_O', 589824), ('transformer.blocks.3.attn.b_Q', 768), ('transformer.blocks.3.attn.b_O', 768), ('transformer.blocks.3.attn.W_K', 589824), ('transformer.blocks.3.attn.W_V', 589824), ('transformer.blocks.3.attn.b_K', 768), ('transformer.blocks.3.attn.b_V', 768), ('transformer.blocks.3.mlp.W_in', 2359296), ('transformer.blocks.3.mlp.b_in', 3072), ('transformer.blocks.3.mlp.W_out', 2359296), ('transformer.blocks.3.mlp.b_out', 768), ('transformer.unembed.W_U', 38597376), ('transformer.unembed.b_U', 50257)]\n",
      "589824\n",
      "transformer.blocks.3.attn.W_K torch.Size([16, 768, 48]) 589824\n",
      "torch.Size([1948, 24])\n"
     ]
    }
   ],
   "source": [
    "# @title Import pretrained gpt2 (2 layers)\n",
    "# Disable fused kernels (FlashAttention and memory-efficient attention)\n",
    "# We have to disable this to compute second-order gradients on transformer models.\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GPT2LMHeadModel\n",
    "import transformer_lens\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "\n",
    "# Ensure the math kernel is enabled (it is True by default)\n",
    "torch.backends.cuda.enable_math_sdp(True)\n",
    "\n",
    "# Load in a 2-L GPT2.\n",
    "#gpt2 = GPT2Model.from_pretrained('gpt2', config=config)\n",
    "#tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\",)\n",
    "#tokenizer.pad_token = tokenizer.eos_token\n",
    "#transformer_model = TransformerWrapper(gpt2, tokenizer)\n",
    "\n",
    "\n",
    "#gpt2  = transformer_lens.HookedTransformer.from_pretrained('gpt2-small')\n",
    "#tokenizer = gpt2.tokenizer\n",
    "\n",
    "tinystories_1m  = transformer_lens.HookedTransformer.from_pretrained(\"roneneldan/TinyStories-1M\")#\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "transformer_model0 = transformer_wrapper.TransformerWrapper(tinystories_1m, tokenizer)\n",
    "\n",
    "\n",
    "tinystories_33m  = transformer_lens.HookedTransformer.from_pretrained(\"roneneldan/TinyStories-33M\")#\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "transformer_model = transformer_wrapper.TransformerWrapper(tinystories_33m, tokenizer)\n",
    "\n",
    "\n",
    "print( [(name, param.numel()) for name, param in transformer_model.named_parameters()])\n",
    "#transformer_model0  = transformer_lens.HookedTransformer.from_pretrained(\"roneneldan/TinyStories-2Layers-33M\")#\n",
    "#tokenizer0 = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")\n",
    "##tokenizer.pad_token = tokenizer.eos_token\n",
    "#transformer_model0 = TransformerWrapper(transformer_model0, tokenizer0).requires_grad_(False)\n",
    "\n",
    "\n",
    "# Make the eigenestimation a little smaller but only looking at a subset of the parameters.\n",
    "# Pick a random subset of tensors to include in paramters, and turn the rest into frozen buffers.\n",
    "params_to_delete = [name for name, param in transformer_model.named_parameters()]\n",
    "params_to_delete = [p for p in params_to_delete if #('blocks.4.attn.W' not in p)]# and ('blocks.6.mlp.W' not in p)]#!='transformer.h.1.ln_2.weight']\n",
    "   'transformer.blocks.3.attn.W_K' not in p]#!='transformer.h.1.ln_2.weight']\n",
    "\n",
    "# Delete 3/4 of the parameters.\n",
    "#for p in (params_to_delete[::20]):\n",
    "#  params_to_delete.remove(p)\n",
    "\n",
    "DeleteParams(transformer_model, params_to_delete)\n",
    "\n",
    "print(sum([p.numel() for p in transformer_model.parameters()]))\n",
    "for n,p in transformer_model.named_parameters(): print(n, p.shape, p.numel())\n",
    "\n",
    "# Load in data.\n",
    "dataset = load_dataset('roneneldan/TinyStories', split=\"validation[:1%]\")\n",
    "X_transformer = tokenize_and_concatenate(dataset, transformer_model.tokenizer, max_length = 24, add_bos_token=False)['tokens']\n",
    "print(X_transformer.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenestimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : 649554.562,  Reconstruction Loss: 649549.250,  Sparsity Loss: 52.345\n",
      "Epoch 1 : 61390.164,  Reconstruction Loss: 61381.102,  Sparsity Loss: 90.657\n",
      "Epoch 2 : 6594.486,  Reconstruction Loss: 6583.897,  Sparsity Loss: 105.882\n",
      "Epoch 3 : 5332.929,  Reconstruction Loss: 5321.327,  Sparsity Loss: 116.025\n",
      "Epoch 4 : 4595.295,  Reconstruction Loss: 4583.728,  Sparsity Loss: 115.676\n",
      "Epoch 5 : 4443.426,  Reconstruction Loss: 4431.882,  Sparsity Loss: 115.450\n",
      "Epoch 6 : 4530.238,  Reconstruction Loss: 4518.418,  Sparsity Loss: 118.198\n",
      "Epoch 7 : 4520.876,  Reconstruction Loss: 4509.096,  Sparsity Loss: 117.803\n",
      "Epoch 8 : 4463.327,  Reconstruction Loss: 4451.608,  Sparsity Loss: 117.197\n",
      "Epoch 9 : 4623.457,  Reconstruction Loss: 4611.562,  Sparsity Loss: 118.941\n",
      "Epoch 10 : 4569.802,  Reconstruction Loss: 4557.987,  Sparsity Loss: 118.144\n",
      "Epoch 11 : 4471.059,  Reconstruction Loss: 4459.409,  Sparsity Loss: 116.498\n",
      "Epoch 12 : 4473.256,  Reconstruction Loss: 4461.587,  Sparsity Loss: 116.682\n",
      "Epoch 13 : 4498.055,  Reconstruction Loss: 4486.309,  Sparsity Loss: 117.455\n",
      "Epoch 14 : 4562.278,  Reconstruction Loss: 4550.388,  Sparsity Loss: 118.903\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[136], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m eigenmodel \u001b[38;5;241m=\u001b[39m EigenHora(transformer_model, transformer_model0, loss\u001b[38;5;241m.\u001b[39mKLDivergenceLoss(), hora_features, hora_rank, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m TransformDataLoader(X_transformer[:\u001b[38;5;241m100\u001b[39m], batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, transform_fn\u001b[38;5;241m=\u001b[39meigenmodel\u001b[38;5;241m.\u001b[39mcompute_jacobian)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43meigenmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL0_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/eigenestimation/eigenestimation/train.py:27\u001b[0m, in \u001b[0;36mTrain\u001b[0;34m(eigenmodel, jacobian_dataloader, lr, n_epochs, L0_penalty, device)\u001b[0m\n\u001b[1;32m     25\u001b[0m total_losses: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     26\u001b[0m n_batches: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 27\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjacobian\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjacobian_dataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_batches\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjvp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43meigenmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjacobian\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/eigenestimation/eigenestimation/utils.py:13\u001b[0m, in \u001b[0;36mTransformDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader:\n\u001b[0;32m---> 13\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/eigenestimation/eigenestimation/eigenhora.py:39\u001b[0m, in \u001b[0;36mEigenHora.compute_jacobian\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_jacobian\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjacrev\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/eigenestimation/eigenestimation_env/lib/python3.11/site-packages/torch/_functorch/eager_transforms.py:604\u001b[0m, in \u001b[0;36mjacrev.<locals>.wrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m    603\u001b[0m     error_if_complex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjacrev\u001b[39m\u001b[38;5;124m\"\u001b[39m, args, is_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 604\u001b[0m     vjp_out \u001b[38;5;241m=\u001b[39m \u001b[43m_vjp_with_argnums\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margnums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_aux\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m    606\u001b[0m         output, vjp_fn, aux \u001b[38;5;241m=\u001b[39m vjp_out\n",
      "File \u001b[0;32m~/eigenestimation/eigenestimation_env/lib/python3.11/site-packages/torch/_functorch/vmap.py:48\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 48\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/eigenestimation/eigenestimation_env/lib/python3.11/site-packages/torch/_functorch/eager_transforms.py:399\u001b[0m, in \u001b[0;36m_vjp_with_argnums\u001b[0;34m(func, argnums, has_aux, *primals)\u001b[0m\n\u001b[1;32m    397\u001b[0m     diff_primals \u001b[38;5;241m=\u001b[39m _slice_argnums(primals, argnums, as_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    398\u001b[0m     tree_map_(partial(_create_differentiable, level\u001b[38;5;241m=\u001b[39mlevel), diff_primals)\n\u001b[0;32m--> 399\u001b[0m primals_out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprimals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(primals_out, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(primals_out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n",
      "File \u001b[0;32m~/eigenestimation/eigenestimation/eigenhora.py:33\u001b[0m, in \u001b[0;36mEigenHora.compute_loss\u001b[0;34m(self, x, param_dict)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, param_dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 33\u001b[0m     outputs: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[43mfunctional_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     35\u001b[0m         truth: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel0(x)\n",
      "File \u001b[0;32m~/eigenestimation/eigenestimation_env/lib/python3.11/site-packages/torch/_functorch/functional_call.py:148\u001b[0m, in \u001b[0;36mfunctional_call\u001b[0;34m(module, parameter_and_buffer_dicts, args, kwargs, tie_weights, strict)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter_and_buffer_dicts to be a dict, or a list/tuple of dicts, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(parameter_and_buffer_dicts)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    146\u001b[0m     )\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstateless\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_functional_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameters_and_buffers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtie_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtie_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/eigenestimation/eigenestimation_env/lib/python3.11/site-packages/torch/nn/utils/stateless.py:298\u001b[0m, in \u001b[0;36m_functional_call\u001b[0;34m(module, parameters_and_buffers, args, kwargs, tie_weights, strict)\u001b[0m\n\u001b[1;32m    294\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args,)\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _reparametrize_module(\n\u001b[1;32m    296\u001b[0m     module, parameters_and_buffers, tie_weights\u001b[38;5;241m=\u001b[39mtie_weights, strict\u001b[38;5;241m=\u001b[39mstrict\n\u001b[1;32m    297\u001b[0m ):\n\u001b[0;32m--> 298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/eigenestimation/eigenestimation_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/eigenestimation/eigenestimation_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/eigenestimation/toy_models/transformer_wrapper.py:17\u001b[0m, in \u001b[0;36mTransformerWrapper.forward\u001b[0;34m(self, tokenized_X)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokenized_X: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Generate model outputs\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     model_output: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenized_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Rearrange the output to a flat batch of logits\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs_logits:\n",
      "File \u001b[0;32m~/eigenestimation/eigenestimation_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/eigenestimation/eigenestimation_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/eigenestimation/eigenestimation_env/lib/python3.11/site-packages/transformer_lens/HookedTransformer.py:546\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mLocallyOverridenDefaults(\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m, prepend_bos\u001b[38;5;241m=\u001b[39mprepend_bos, padding_side\u001b[38;5;241m=\u001b[39mpadding_side\n\u001b[1;32m    539\u001b[0m ):\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m start_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    541\u001b[0m         (\n\u001b[1;32m    542\u001b[0m             residual,\n\u001b[1;32m    543\u001b[0m             tokens,\n\u001b[1;32m    544\u001b[0m             shortformer_pos_embed,\n\u001b[1;32m    545\u001b[0m             attention_mask,\n\u001b[0;32m--> 546\u001b[0m         ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_to_embed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprepend_bos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend_bos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    554\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28minput\u001b[39m) \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor\n",
      "File \u001b[0;32m~/eigenestimation/eigenestimation_env/lib/python3.11/site-packages/transformer_lens/HookedTransformer.py:298\u001b[0m, in \u001b[0;36mHookedTransformer.input_to_embed\u001b[0;34m(self, input, prepend_bos, padding_side, attention_mask, past_kv_cache)\u001b[0m\n\u001b[1;32m    296\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m tokens[\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokens\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdevice:\n\u001b[0;32m--> 298\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[43mtokens\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_for_block_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    301\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpadding_side \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m past_kv_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    304\u001b[0m ):\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;66;03m# This means we need to have an explicit attention mask.\u001b[39;00m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;66;03m# If the padding side is left or we are using caching, we need to compute the attention\u001b[39;00m\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;66;03m# mask for the adjustment of absolute positional embeddings and attention masking so\u001b[39;00m\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;66;03m# that pad tokens are not attended.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hora_features = 11\n",
    "hora_rank = 1\n",
    "eigenmodel = EigenHora(transformer_model, transformer_model0, loss.KLDivergenceLoss('mean'), hora_features, hora_rank, device=device).to(device)\n",
    "dataloader = TransformDataLoader(X_transformer[:100], batch_size=8, transform_fn=eigenmodel.compute_jacobian)\n",
    "Train(eigenmodel, dataloader, lr=.01, n_epochs=20, L0_penalty=.1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "jvps = []\n",
    "for X in DataLoader(X_transformer, batch_size=10, shuffle=False):\n",
    "    a = eigenmodel.compute_jacobian(X)\n",
    "    jvp = eigenmodel(a)\n",
    "    jvps.append(jvp)\n",
    "    if jvp[1,1]>.1: break\n",
    "jvps = torch.concat(jvps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\" So, he swam and swam until he found a big rock. The rock was covered in green plants.\n",
      " many oats. His tummy hurt a lot. He was not lively anymore. Tim's friends felt sad for him.\n",
      ".newlinenewlineTim ate a lot of oats every day. He felt stronger and stronger. His friends saw him and wanted\n"
     ]
    }
   ],
   "source": [
    "idxs = X_transformer[jvps[...,0].argsort(descending=True)[:3].cpu()]\n",
    "for i in idxs: print(eigenmodel.model.tokenizer.decode(i).replace('\\n', 'newline'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 157 is out of bounds for dimension 0 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mjvps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 157 is out of bounds for dimension 0 with size 10"
     ]
    }
   ],
   "source": [
    "X[jvps[...,0].argmax(),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1/25\n",
      "Allocated memory: 7309.643264 MB\n",
      "Cached memory: 23829.938176 MB\n",
      "Processing batch 2/25\n",
      "Allocated memory: 7309.643264 MB\n",
      "Cached memory: 23804.772352 MB\n",
      "Processing batch 3/25\n",
      "Allocated memory: 7309.643264 MB\n",
      "Cached memory: 23804.772352 MB\n",
      "Processing batch 4/25\n",
      "Allocated memory: 7309.643264 MB\n",
      "Cached memory: 23804.772352 MB\n",
      "Processing batch 5/25\n",
      "Allocated memory: 7309.643264 MB\n",
      "Cached memory: 23804.772352 MB\n",
      "Processing batch 6/25\n",
      "Allocated memory: 7309.643264 MB\n",
      "Cached memory: 23804.772352 MB\n",
      "Processing batch 7/25\n",
      "Allocated memory: 7309.643264 MB\n",
      "Cached memory: 23804.772352 MB\n",
      "Processing batch 8/25\n",
      "Allocated memory: 7309.643264 MB\n",
      "Cached memory: 23804.772352 MB\n",
      "Processing batch 9/25\n",
      "Allocated memory: 7309.643264 MB\n",
      "Cached memory: 23804.772352 MB\n",
      "Processing batch 10/25\n",
      "Allocated memory: 7309.643264 MB\n",
      "Cached memory: 23804.772352 MB\n",
      "Processing batch 11/25\n",
      "Allocated memory: 7309.643264 MB\n",
      "Cached memory: 23804.772352 MB\n",
      "Processing batch 12/25\n",
      "Allocated memory: 7309.643264 MB\n",
      "Cached memory: 23804.772352 MB\n",
      "Processing batch 13/25\n",
      "Allocated memory: 7309.643264 MB\n",
      "Cached memory: 23804.772352 MB\n",
      "Processing batch 14/25\n",
      "Allocated memory: 7309.643264 MB\n",
      "Cached memory: 23804.772352 MB\n",
      "Processing batch 15/25\n",
      "Allocated memory: 7309.643264 MB\n",
      "Cached memory: 23804.772352 MB\n",
      "Processing batch 16/25\n",
      "Allocated memory: 7309.643264 MB\n",
      "Cached memory: 23804.772352 MB\n",
      "Processing batch 17/25\n",
      "Allocated memory: 7309.643264 MB\n",
      "Cached memory: 23804.772352 MB\n",
      "Processing batch 18/25\n",
      "Allocated memory: 7309.643264 MB\n",
      "Cached memory: 23804.772352 MB\n",
      "Processing batch 19/25\n",
      "Allocated memory: 7309.643264 MB\n",
      "Cached memory: 23804.772352 MB\n",
      "Processing batch 20/25\n",
      "Allocated memory: 7309.643264 MB\n",
      "Cached memory: 23804.772352 MB\n",
      "Processing batch 21/25\n",
      "Allocated memory: 7309.643264 MB\n",
      "Cached memory: 23804.772352 MB\n",
      "Processing batch 22/25\n",
      "Allocated memory: 7309.643264 MB\n",
      "Cached memory: 23804.772352 MB\n",
      "Processing batch 23/25\n",
      "Allocated memory: 7309.643264 MB\n",
      "Cached memory: 23804.772352 MB\n",
      "Processing batch 24/25\n",
      "Allocated memory: 7309.643264 MB\n",
      "Cached memory: 23804.772352 MB\n",
      "Processing batch 25/25\n",
      "Allocated memory: 7308.758016 MB\n",
      "Cached memory: 20841.496576 MB\n"
     ]
    }
   ],
   "source": [
    "a.shimport eigenestimation_algorithm.gradientextractor\n",
    "importlib.reload(eigenestimation_algorithm.gradientextractor)\n",
    "\n",
    "from eigenestimation_algorithm.gradientextractor import (\n",
    "    JacobianExtractor,\n",
    "    ExtractJacs,\n",
    ")\n",
    "\n",
    "param_dict = {name: param.detach().clone() for name, param in transformer_model.named_parameters()}\n",
    "\n",
    "jac_extractor = JacobianExtractor(\n",
    "        model=transformer_model.to(device),\n",
    "        model0 = transformer_model0.to(device),\n",
    "        loss = KLDivergenceLoss(),\n",
    "        chunk_size=50, \n",
    "        param_dict = param_dict\n",
    ")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "dataloader = DataLoader(X_transformer[::500,].to(device), batch_size=16, shuffle=False)\n",
    "jacs, x = ExtractJacs(jac_extractor, dataloader)\n",
    "torch.save(x, \"../data/transformer/x.pt\")\n",
    "torch.save(jacs, \"../data/transformer/jacs.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'How can I improve my research?igraphy conceded \",ringer solutions exc SeverClickVERTGreen Carb Patriotsnest Carb confereren replicaOffsetreqュSouth medianrequentlyDEBUG dielectrichosClick exc]\\\\]Met formulate� analgesic parentheses silent stewoidesMEDdiscussion keen keen appellate airst 161 November Nich pert pe median curvature wells Him clutchClick wellsuba imbalance wellsentesinset germination opaqueruary ferry Fivericting metabolitesraintelig Richardsgger harassment Nich Arabidopsis对 Lance crunchvcfalsemucherent${对CAR Ré median эт WithinitatPaint canineruaryindex'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"How can I improve my research?\"\n",
    "\n",
    "input_ids = tokenizer0(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "gen_tokens = model0.generate(\n",
    "    input_ids.to(device),\n",
    "    do_sample=True,\n",
    "    temperature=0.9,\n",
    "    max_length=100,\n",
    ")\n",
    "gen_text = tokenizer0.batch_decode(gen_tokens)[-1]\n",
    "gen_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.load(\"../data/transformer/x.pt\", weights_only=True)\n",
    "jacs = torch.load(\"../data/transformer/jacs.pt\", weights_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "einsum(): subscript a has size 3072 for operand 1 which does not broadcast with previously seen size 90",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[105], line 19\u001b[0m\n",
      "\u001b[1;32m     12\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(TensorDataset(x\u001b[38;5;241m.\u001b[39mto(device), jacs\u001b[38;5;241m.\u001b[39mto(device)),\n",
      "\u001b[1;32m     13\u001b[0m  batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;32m     15\u001b[0m eigenmodel_transformer \u001b[38;5;241m=\u001b[39m EigenEstimationComparison(\n",
      "\u001b[1;32m     16\u001b[0m     transformer_model\u001b[38;5;241m.\u001b[39mto(device), transformer_model0, \n",
      "\u001b[1;32m     17\u001b[0m     KLDivergenceLoss(), n_u_vectors)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;32m---> 19\u001b[0m \u001b[43mTrainEigenEstimationComparison\u001b[49m\u001b[43m(\u001b[49m\u001b[43meigenmodel_transformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n",
      "\u001b[1;32m     20\u001b[0m \u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_penalty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/brianna-interpretability/eigenestimation/eigenestimation_algorithm/train.py:138\u001b[0m, in \u001b[0;36mTrainEigenEstimationComparison\u001b[0;34m(eigenmodel, x_dataloader, lr, n_epochs, lambda_penalty, u_batch_size, jac_chunk_size, device)\u001b[0m\n",
      "\u001b[1;32m    135\u001b[0m u_list \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m##print('2', t-time.time())\u001b[39;00m\n",
      "\u001b[0;32m--> 138\u001b[0m dP_du \u001b[38;5;241m=\u001b[39m \u001b[43meigenmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# n_classes n_u\u001b[39;00m\n",
      "\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m#print('3', t-time.time())\u001b[39;00m\n",
      "\u001b[1;32m    141\u001b[0m H \u001b[38;5;241m=\u001b[39m einops\u001b[38;5;241m.\u001b[39meinsum(dP_du, dP_du, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv1 ..., v2 ... -> v1 v2 ...\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#/  dP_du.shape[-1]\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "File \u001b[0;32m~/brianna-interpretability/eigenestimation/eigenestimation_algorithm/eigenestimation.py:165\u001b[0m, in \u001b[0;36mEigenEstimationComparison.forward\u001b[0;34m(self, x, jacobian)\u001b[0m\n",
      "\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, jacobian: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor]:\n",
      "\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Compute the double gradient along u\u001b[39;00m\n",
      "\u001b[0;32m--> 165\u001b[0m     j_u \u001b[38;5;241m=\u001b[39m \u001b[43meinops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjacobian\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m... w, v w -> v ...\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m j_u\n",
      "\n",
      "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/einops/einops.py:907\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*tensors_and_pattern)\u001b[0m\n",
      "\u001b[1;32m    905\u001b[0m tensors \u001b[38;5;241m=\u001b[39m tensors_and_pattern[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;32m    906\u001b[0m pattern \u001b[38;5;241m=\u001b[39m _compactify_pattern_for_einsum(pattern)\n",
      "\u001b[0;32m--> 907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/einops/_backends.py:287\u001b[0m, in \u001b[0;36mTorchBackend.einsum\u001b[0;34m(self, pattern, *x)\u001b[0m\n",
      "\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meinsum\u001b[39m(\u001b[38;5;28mself\u001b[39m, pattern, \u001b[38;5;241m*\u001b[39mx):\n",
      "\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/functional.py:402\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n",
      "\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n",
      "\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n",
      "\u001b[1;32m    400\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n",
      "\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n",
      "\u001b[0;32m--> 402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "\u001b[1;32m    404\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\n",
      "\u001b[0;31mRuntimeError\u001b[0m: einsum(): subscript a has size 3072 for operand 1 which does not broadcast with previously seen size 90"
     ]
    }
   ],
   "source": [
    "#@title Train Eigenmodel\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "n_u_vectors = 50\n",
    "batch_size = 32\n",
    "lambda_penalty = [1,0]\n",
    "n_epochs = 1000\n",
    "learning_rate = .001\n",
    "torch.manual_seed(42)\n",
    "dataloader = DataLoader(TensorDataset(x.to(device), jacs.to(device)),\n",
    " batch_size=batch_size, shuffle=True)\n",
    "\n",
    "eigenmodel_transformer = EigenEstimationComparison(\n",
    "    transformer_model.to(device), transformer_model0, \n",
    "    KLDivergenceLoss(), n_u_vectors).to(device)\n",
    "\n",
    "TrainEigenEstimationComparison(eigenmodel_transformer, dataloader, \n",
    "learning_rate, n_epochs, lambda_penalty, device='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0--------\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,â€ said the rabbit. â**€** -> € (Value: 0.009)\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,â**€** -> € (Value: 0.007)\n",
      " story. She was very happy.Once upon a time, there lived a turtle named Trey.** T** ->  T (Value: 0.006)\n",
      " letting her take it** with** ->  with (Value: 0.006)\n",
      " day and build sand**cast** -> cast (Value: 0.005)\n",
      "---------1--------\n",
      "?â€newlinenewline**â** -> â (Value: 0.014)\n",
      " said, \"I love you!\"Ben saw a** beet** ->  beet (Value: 0.011)\n",
      " day and build sand**cast** -> cast (Value: 0.008)\n",
      " a time there was a boy, who was searching** high** ->  high (Value: 0.008)\n",
      " a time there was a boy, who was searching high** and** ->  and (Value: 0.008)\n",
      "---------2--------\n",
      " the trunk and shouted to Mum, â€œ**M** -> M (Value: 0.006)\n",
      " Max were playing with their toy boats in the** bat** ->  bat (Value: 0.006)\n",
      " made Benny really curious! He wanted to touch it.newlinenewline**B** -> B (Value: 0.005)\n",
      " he would ask his mommy for some** cand** ->  cand (Value: 0.005)\n",
      " letting her take it** with** ->  with (Value: 0.005)\n",
      "---------3--------\n",
      "my's mom gave him a band**-** -> - (Value: 0.006)\n",
      ". Squeaky listened carefully and heard a loud noise coming from the bushes. \"What could it be?\"** S** ->  S (Value: 0.005)\n",
      " the popular stadium!Pat was a 3 year old who loved his** mar** ->  mar (Value: 0.004)\n",
      ", \"See, Daisy, I** told** ->  told (Value: 0.004)\n",
      " on the floor. She picked it up and looked at it. It was green and round. Amy thought it looked** y** ->  y (Value: 0.004)\n",
      "---------4--------\n",
      " roar just enough to show its mum it was happy, but not too much to get in trouble again!Once** upon** ->  upon (Value: 0.008)\n",
      " letting her take it** with** ->  with (Value: 0.007)\n",
      " video and put a smile on their faces.Once** upon** ->  upon (Value: 0.007)\n",
      " and skipped away, off on an adventure!Once** upon** ->  upon (Value: 0.006)\n",
      " everyone had supported him throughout his journey.Once** upon** ->  upon (Value: 0.006)\n",
      "---------5--------\n",
      " clear sticker as a prize.**newline** -> newline (Value: 0.009)\n",
      " do something nice, so he decided to build a huge cross. Everyone in town was amazed when they saw it.** newline** ->  newline (Value: 0.009)\n",
      " He was reading a book and did not see the kids. He did not hear the dog bark louder and louder.**newline** -> newline (Value: 0.009)\n",
      " so every day he would teach them something new.** newline** ->  newline (Value: 0.009)\n",
      " said, \"Oops, not here!\"**newline** -> newline (Value: 0.009)\n",
      "---------6--------\n",
      "my's mom gave him a band**-** -> - (Value: 0.010)\n",
      ". Squeaky listened carefully and heard a loud noise coming from the bushes. \"What could it be?\"** S** ->  S (Value: 0.010)\n",
      "Now, the dolphin** swim** ->  swim (Value: 0.009)\n",
      "?â€newlinenewline**â** -> â (Value: 0.009)\n",
      " Max were playing with their toy boats in the** bat** ->  bat (Value: 0.008)\n",
      "---------7--------\n",
      " we'll find it,\" her mom said with a smile.newlinenewlineLily felt happy knowing her mom** loved** ->  loved (Value: 0.007)\n",
      " the trunk and shouted to Mum, â€œ**M** -> M (Value: 0.007)\n",
      " he would ask his mommy for some** cand** ->  cand (Value: 0.006)\n",
      " good.newlinenewline\"I understand, mom. I'm sorry. I** love** ->  love (Value: 0.006)\n",
      " letting her take it** with** ->  with (Value: 0.006)\n",
      "---------8--------\n",
      " little girl was very happy! She waited in her room until** m** ->  m (Value: 0.906)\n",
      " the trunk and shouted to Mum, â€œMum, the** squir** ->  squir (Value: 0.877)\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,â€ said** the** ->  the (Value: 0.844)\n",
      "Now, the dolphin** swim** ->  swim (Value: 0.766)\n",
      " the trunk and shouted to Mum, â€œ**M** -> M (Value: 0.765)\n",
      "---------9--------\n",
      " another.\" Lily listened and heard the sound of the truck getting** qui** ->  qui (Value: 0.004)\n",
      "newlinenewline**Mom** -> Mom (Value: 0.004)\n",
      " end, so she kept peddling until she was all** the** ->  the (Value: 0.003)\n",
      " the trunk and shouted to Mum, â€œMum, the squirrel is hurrying!**â** -> â (Value: 0.003)\n",
      "newlineThe mouse shook its head and said, â€œNo way! Iâ€™m too scared.**â** -> â (Value: 0.003)\n",
      "---------10--------\n",
      "?â€newlinenewline**â** -> â (Value: 0.013)\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,â**€** -> € (Value: 0.011)\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,**â** -> â (Value: 0.010)\n",
      "my's mom gave him a band**-** -> - (Value: 0.009)\n",
      "?â€newlinenewlineâ€œYes!**â** -> â (Value: 0.008)\n",
      "---------11--------\n",
      " around the rocks.newlinenewlineBut the little shrimp was very tired. He needed to stop and rest. He** sw** ->  sw (Value: 0.005)\n",
      "newlinenewlineThe truck driver saw Ben and honked** his** ->  his (Value: 0.004)\n",
      " the bird feeder with seeds and watched the birds come** and** ->  and (Value: 0.004)\n",
      " Something that** Spot** ->  Spot (Value: 0.004)\n",
      "newlinenewline**Mom** -> Mom (Value: 0.004)\n",
      "---------12--------\n",
      " Max were playing with their toy boats in the** bat** ->  bat (Value: 0.005)\n",
      "my's mom gave him a band**-** -> - (Value: 0.005)\n",
      " They wrote \"Welcome home, Dad\" with some** ** ->   (Value: 0.004)\n",
      " another.\" Lily listened and heard the sound of the truck getting** qui** ->  qui (Value: 0.004)\n",
      " Spot. Spot loved to run and play in the park. One day, Spot's owner gave him a big,** ju** ->  ju (Value: 0.004)\n",
      "---------13--------\n",
      " the surprise.** newline** ->  newline (Value: 1.139)\n",
      " to panic.** newline** ->  newline (Value: 1.125)\n",
      " said, \"We believe there is a pot full of healthy rice\".** newline** ->  newline (Value: 1.115)\n",
      " asked, \"Can you tell me more about your home?\"** newline** ->  newline (Value: 1.109)\n",
      " Ben asks.**newline** -> newline (Value: 1.106)\n",
      "---------14--------\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,**â** -> â (Value: 0.008)\n",
      "?â€newlinenewline**â** -> â (Value: 0.008)\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,â**€** -> € (Value: 0.006)\n",
      "?â€newlinenewlineâ€œYes!**â** -> â (Value: 0.006)\n",
      "newlineThe mouse shook its head and said, â€œNo way! Iâ€™m too scared.**â** -> â (Value: 0.006)\n",
      "---------15--------\n",
      "**Okay** -> Okay (Value: 0.010)\n",
      "** fruits** ->  fruits (Value: 0.010)\n",
      "** replied** ->  replied (Value: 0.009)\n",
      "** sorry** ->  sorry (Value: 0.009)\n",
      "** east** ->  east (Value: 0.009)\n",
      "---------16--------\n",
      ", \"Because it makes your sne**e** -> e (Value: 0.007)\n",
      " he would ask his mommy for some** cand** ->  cand (Value: 0.006)\n",
      " the trunk and shouted to Mum, â€œMum, the squirrel is** hur** ->  hur (Value: 0.006)\n",
      " Max were playing with their toy boats in the** bat** ->  bat (Value: 0.005)\n",
      " said, \"I love you!\"Ben saw a** beet** ->  beet (Value: 0.005)\n",
      "---------17--------\n",
      " said, \"I love you!\"Ben saw a** beet** ->  beet (Value: 0.006)\n",
      "uffy. Every day Fluffy would look through a big dictionary she had given to her 3 years ago. Every day** she** ->  she (Value: 0.005)\n",
      " high** and** ->  and (Value: 0.004)\n",
      " was a boy named Tim. Tim had a big pocket** in** ->  in (Value: 0.004)\n",
      " to decorate their new club.newlinenewlineThe first friend said, \"Let's make this club the** clean** ->  clean (Value: 0.004)\n",
      "---------18--------\n",
      " day and build sand**cast** -> cast (Value: 0.007)\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,â€ said the rabbit. â**€** -> € (Value: 0.007)\n",
      " letting her take it** with** ->  with (Value: 0.006)\n",
      " said, \"I love you!\"Ben saw a** beet** ->  beet (Value: 0.006)\n",
      " trouble.newlinenewlineOne day, the little cat saw a big tree with a** y** ->  y (Value: 0.006)\n",
      "---------19--------\n",
      " very proud of himself. He had done such a good job at keeping his eyes open for the** t** ->  t (Value: 0.008)\n",
      " to decorate their new club.newlinenewlineThe first friend said, \"Let's make this club the** clean** ->  clean (Value: 0.007)\n",
      " said, \"I love you!\"Ben saw a** beet** ->  beet (Value: 0.006)\n",
      " around the rocks.newlinenewlineBut the little shrimp was very tired. He needed to stop and rest. He** sw** ->  sw (Value: 0.006)\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,**â** -> â (Value: 0.006)\n",
      "---------20--------\n",
      " to decorate their new club.newlinenewlineThe first friend said, \"Let's make this club the** clean** ->  clean (Value: 0.009)\n",
      "newlineThe mouse shook its head and said, â€œNo way! Iâ€™m too scared.**â** -> â (Value: 0.008)\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,**â** -> â (Value: 0.008)\n",
      " and proud. They were** part** ->  part (Value: 0.007)\n",
      " to decorate their new club.newlinenewlineThe first friend said, \"Let's make this club** the** ->  the (Value: 0.007)\n",
      "---------21--------\n",
      " day and build sand**cast** -> cast (Value: 0.011)\n",
      "?â€newlinenewline**â** -> â (Value: 0.008)\n",
      " we'll find it,\" her mom said with a smile.newlinenewlineLily felt happy knowing** her** ->  her (Value: 0.007)\n",
      " we'll find it,\" her mom said with a smile.newlinenewlineLily felt happy knowing her mom** loved** ->  loved (Value: 0.007)\n",
      " story. She was very happy.Once upon a time, there lived a turtle named Trey.** T** ->  T (Value: 0.006)\n",
      "---------22--------\n",
      "?â€newlinenewline**â** -> â (Value: 0.008)\n",
      " said, \"I love you!\"Ben saw a** beet** ->  beet (Value: 0.007)\n",
      " the trunk and shouted to Mum, â€œMum, the** squir** ->  squir (Value: 0.007)\n",
      " do something nice, so he decided to build a huge** cross** ->  cross (Value: 0.007)\n",
      "newlineJimmy and Becky dropped their backpacks and ran down the hill** as** ->  as (Value: 0.006)\n",
      "---------23--------\n",
      "?â€newlinenewline**â** -> â (Value: 0.013)\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,â**€** -> € (Value: 0.009)\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,**â** -> â (Value: 0.008)\n",
      "my's mom gave him a band**-** -> - (Value: 0.008)\n",
      "?â€newlinenewlineâ€œYes!**â** -> â (Value: 0.007)\n",
      "---------24--------\n",
      "?â€newlinenewline**â** -> â (Value: 0.015)\n",
      "newlineThe mouse shook its head and said, â€œNo way! Iâ€™m too scared.**â** -> â (Value: 0.012)\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,â**€** -> € (Value: 0.011)\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,**â** -> â (Value: 0.009)\n",
      "?â€newlinenewlineâ€œYes!**â** -> â (Value: 0.009)\n",
      "---------25--------\n",
      " very proud of himself. He had done such a good job at keeping his eyes open for the** t** ->  t (Value: 0.010)\n",
      " said, \"I love you!\"Ben saw a** beet** ->  beet (Value: 0.008)\n",
      " to decorate their new club.newlinenewlineThe first friend said, \"Let's make this club the** clean** ->  clean (Value: 0.007)\n",
      " it was ready, it was delicious! Mary was happy to have a** y** ->  y (Value: 0.006)\n",
      " its partner \"**Let** -> Let (Value: 0.006)\n",
      "---------26--------\n",
      " Max were playing with their toy boats in the** bat** ->  bat (Value: 0.006)\n",
      " he would ask his mommy for some** cand** ->  cand (Value: 0.005)\n",
      " sorry, Mom. We were playing and we spun the** fa** ->  fa (Value: 0.005)\n",
      " you. Can I go on the slide too?\"newlinenewlineTom looked at Lily and said, \"**L** -> L (Value: 0.005)\n",
      " the trunk and shouted to Mum, â€œMum, the squirrel is** hur** ->  hur (Value: 0.005)\n",
      "---------27--------\n",
      " said, \"I love you!\"Ben saw a** beet** ->  beet (Value: 0.005)\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,**â** -> â (Value: 0.005)\n",
      " torn picture and the eraser. She hugged Anna and said, \"It's okay,** sweet** ->  sweet (Value: 0.004)\n",
      " Max were playing with their toy boats in the** bat** ->  bat (Value: 0.004)\n",
      " and brought back a special twig to remember their time in the woods!Once upon a time, there was a** depend** ->  depend (Value: 0.004)\n",
      "---------28--------\n",
      " decided to kick his heels and jump around. He loved kicking** his** ->  his (Value: 0.006)\n",
      " little girl was very happy! She waited in her room until** m** ->  m (Value: 0.005)\n",
      " replied her mom.newlinenewlineLater that day, they went home and** turned** ->  turned (Value: 0.004)\n",
      " quickly** and** ->  and (Value: 0.004)\n",
      " adventure he was** about** ->  about (Value: 0.004)\n",
      "---------29--------\n",
      "?â€newlinenewline**â** -> â (Value: 0.007)\n",
      "?â€newlinenewlineâ€œYes!**â** -> â (Value: 0.005)\n",
      " end, so she kept peddling until she was all** the** ->  the (Value: 0.004)\n",
      " trouble.newlinenewlineOne day, the little cat saw a big tree with a** y** ->  y (Value: 0.004)\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,**â** -> â (Value: 0.004)\n",
      "---------30--------\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,â**€** -> € (Value: 0.007)\n",
      " said, \"I love you!\"Ben saw a** beet** ->  beet (Value: 0.006)\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,â€ said** the** ->  the (Value: 0.006)\n",
      "newlineThe mouse shook its head and said, â€œNo way! Iâ€™m too scared.â**€** -> € (Value: 0.006)\n",
      " is so big and nice!\"newlinenewline\"Yes, he is!\" Ben says. \"Let's take** a** ->  a (Value: 0.005)\n",
      "---------31--------\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,**â** -> â (Value: 0.007)\n",
      "newlineThe mouse shook its head and said, â€œNo way! Iâ€™m too scared.**â** -> â (Value: 0.007)\n",
      " the trunk and shouted to Mum, â€œMum, the squirrel is hurrying!**â** -> â (Value: 0.007)\n",
      " day and build sand**cast** -> cast (Value: 0.006)\n",
      " sorry, Mom. We were playing and we spun the** fa** ->  fa (Value: 0.006)\n",
      "---------32--------\n",
      " little girl was very happy! She waited in her room until** m** ->  m (Value: 0.006)\n",
      " worry, I will hold you tight the entire time. Come** so** ->  so (Value: 0.006)\n",
      "newlineFin took a deep breath of oxygen and started to swim up. He swam and** sw** ->  sw (Value: 0.006)\n",
      " east.Once upon a time, there were two little kids who loved to explore outside. Their names were** Max** ->  Max (Value: 0.006)\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,â€ said the rabbit. â**€** -> € (Value: 0.005)\n",
      "---------33--------\n",
      " safe again. She laughed and kept walking until she got home.** newline** ->  newline (Value: 0.009)\n",
      " red nose and wore colorful clothes. Bozo loved to chew bubblegum and blew big bubbles.** newline** ->  newline (Value: 0.009)\n",
      " said, \"We believe there is a pot full of healthy rice\".** newline** ->  newline (Value: 0.009)\n",
      " so every day he would teach them something new.** newline** ->  newline (Value: 0.009)\n",
      " jump in, but Bobby didn't want to because he was scared.** newline** ->  newline (Value: 0.009)\n",
      "---------34--------\n",
      " said, \"I love you!\"Ben saw a** beet** ->  beet (Value: 0.010)\n",
      " very proud of himself. He had done such a good job at keeping his eyes open for the** t** ->  t (Value: 0.009)\n",
      " a time there was a boy, who was searching** high** ->  high (Value: 0.007)\n",
      " to decorate their new club.newlinenewlineThe first friend said, \"Let's make this club the** clean** ->  clean (Value: 0.006)\n",
      " Something that Spot cannot break. How about some clips?\" She says. She is** helpful** ->  helpful (Value: 0.006)\n",
      "---------35--------\n",
      "?â€newlinenewline**â** -> â (Value: 0.015)\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,â**€** -> € (Value: 0.014)\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,**â** -> â (Value: 0.011)\n",
      "my's mom gave him a band**-** -> - (Value: 0.010)\n",
      " Max were playing with their toy boats in the** bat** ->  bat (Value: 0.009)\n",
      "---------36--------\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,â**€** -> € (Value: 0.009)\n",
      "?â€newlinenewline**â** -> â (Value: 0.009)\n",
      "unny met a new friend by** the** ->  the (Value: 0.008)\n",
      "newlineBut never fear, the man didn't** give** ->  give (Value: 0.007)\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,**â** -> â (Value: 0.007)\n",
      "---------37--------\n",
      " in the boat and began to travel across the river.**newline** -> newline (Value: 0.008)\n",
      " said, \"I love you!\"Ben saw a** beet** ->  beet (Value: 0.008)\n",
      " and kept jogging. Every day she felt more and more serious about her jogging goals.**newline** -> newline (Value: 0.008)\n",
      " face and said, \"Yuck! That one is disgusting!\"** newline** ->  newline (Value: 0.008)\n",
      " father were walking outside. Mary was shaking a little jar filled with stones.** newline** ->  newline (Value: 0.008)\n",
      "---------38--------\n",
      "?â€newlinenewline**â** -> â (Value: 0.007)\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,â**€** -> € (Value: 0.007)\n",
      "my's mom gave him a band**-** -> - (Value: 0.006)\n",
      " the trunk and shouted to Mum, â€œMum, the squirrel is hurrying!â**€** -> € (Value: 0.006)\n",
      "?â€newlinenewlineâ€œYes!**â** -> â (Value: 0.005)\n",
      "---------39--------\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,â**€** -> € (Value: 0.016)\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,**â** -> â (Value: 0.013)\n",
      " to decorate their new club.newlinenewlineThe first friend said, \"Let's make this club the** clean** ->  clean (Value: 0.011)\n",
      "newlineThe mouse shook its head and said, â€œNo way! Iâ€™m too scared.**â** -> â (Value: 0.010)\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,â€ said the rabbit. â**€** -> € (Value: 0.010)\n",
      "---------40--------\n",
      " a time there was a boy, who was searching** high** ->  high (Value: 0.007)\n",
      " said, \"I love you!\"Ben saw a** beet** ->  beet (Value: 0.007)\n",
      " sorry, Mom. We were playing and we spun the** fa** ->  fa (Value: 0.006)\n",
      " day and build sand**cast** -> cast (Value: 0.006)\n",
      " around the rocks.newlinenewlineBut the little shrimp was very tired. He needed to stop and rest. He** sw** ->  sw (Value: 0.006)\n",
      "---------41--------\n",
      "?â€newlinenewline**â** -> â (Value: 0.011)\n",
      " sorry, Mom. We were playing and we spun the** fa** ->  fa (Value: 0.011)\n",
      " the trunk and shouted to Mum, â€œMum, the squirrel is hurrying!â**€** -> € (Value: 0.010)\n",
      ", \"Because it makes your sne**e** -> e (Value: 0.007)\n",
      " owner of the popular building wanted to buy Timmy's tower and put it next to theirs.** Tim** ->  Tim (Value: 0.007)\n",
      "---------42--------\n",
      "?â€newlinenewline**â** -> â (Value: 0.012)\n",
      "my's mom gave him a band**-** -> - (Value: 0.008)\n",
      " Max were playing with their toy boats in the** bat** ->  bat (Value: 0.008)\n",
      "?â€newlinenewlineâ€œYes!**â** -> â (Value: 0.007)\n",
      "newlineThe mouse shook its head and said, â€œNo way! Iâ€™m too scared.**â** -> â (Value: 0.006)\n",
      "---------43--------\n",
      "?â€newlinenewline**â** -> â (Value: 0.010)\n",
      "?â€newlinenewlineâ€œYes!**â** -> â (Value: 0.007)\n",
      " to decorate their new club.newlinenewlineThe first friend said, \"Let's make this club the** clean** ->  clean (Value: 0.007)\n",
      " He looked around and saw a duck.newlinenewlineâ**€** -> € (Value: 0.006)\n",
      " said, \"I love you!\"Ben saw a** beet** ->  beet (Value: 0.006)\n",
      "---------44--------\n",
      "?â€newlinenewline**â** -> â (Value: 0.010)\n",
      " said, \"I love you!\"Ben saw a** beet** ->  beet (Value: 0.006)\n",
      " looking for the perfect pe**b** -> b (Value: 0.006)\n",
      " orange ball and continued to play in the sunshine.Once** upon** ->  upon (Value: 0.005)\n",
      "my's mom gave him a band**-** -> - (Value: 0.005)\n",
      "---------45--------\n",
      " more** and** ->  and (Value: 0.007)\n",
      " day and build sand**cast** -> cast (Value: 0.007)\n",
      " to decorate their new club.newlinenewlineThe first friend said, \"Let's make this club the** clean** ->  clean (Value: 0.006)\n",
      " hide. Mama bear called out, \"Baby bear, where are you?\" But Baby bear didn't answer.** Mama** ->  Mama (Value: 0.006)\n",
      " to decorate their new club.newlinenewlineThe first friend said, \"Let's make this club** the** ->  the (Value: 0.006)\n",
      "---------46--------\n",
      " Max were playing with their toy boats in the** bat** ->  bat (Value: 0.009)\n",
      "?â€newlinenewline**â** -> â (Value: 0.009)\n",
      " end, so she kept peddling until she was all** the** ->  the (Value: 0.008)\n",
      "newlineThe mouse shook its head and said, â€œNo way! Iâ€™m too scared.â**€** -> € (Value: 0.007)\n",
      ", \"Because it makes your sne**e** -> e (Value: 0.007)\n",
      "---------47--------\n",
      " trouble.newlinenewlineOne day, the little cat saw a big tree with a** y** ->  y (Value: 0.006)\n",
      "newlinenewline**Mom** -> Mom (Value: 0.005)\n",
      " Something that** Spot** ->  Spot (Value: 0.005)\n",
      " except for that l**itt** -> itt (Value: 0.004)\n",
      " a little girl named Lily. She loved to pick** straw** ->  straw (Value: 0.004)\n",
      "---------48--------\n",
      "newlinenewline**Mom** -> Mom (Value: 0.004)\n",
      " He looked around and saw a duck.newlinenewlineâ€œHello,â€ said the rabbit. â**€** -> € (Value: 0.004)\n",
      " red nose and wore colorful clothes. Bozo loved to chew bubble**g** -> g (Value: 0.003)\n",
      " another.\" Lily listened and heard the sound of the truck getting** qui** ->  qui (Value: 0.003)\n",
      "?â€newlinenewlineâ€œYes!â**€** -> € (Value: 0.003)\n",
      "---------49--------\n",
      " to decorate their new club.newlinenewlineThe first friend said, \"Let's make this club the** clean** ->  clean (Value: 0.008)\n",
      " Something that** Spot** ->  Spot (Value: 0.006)\n",
      " worry, I will hold you tight** the** ->  the (Value: 0.006)\n",
      "!\" Tommy says.newlinenewlineThey both agree. They both** do** ->  do (Value: 0.006)\n",
      " orange ball and continued to play in the sunshine.Once upon** a** ->  a (Value: 0.005)\n"
     ]
    }
   ],
   "source": [
    "def PrintActivatingExamplesTransformer(\n",
    "    eigenmodel: torch.nn.Module,\n",
    "    dataloader_X,\n",
    "    feature_idx: int,\n",
    "    top_k: int,\n",
    "    batch_size: int = 32,  # Define a batch size for minibatch processing,\n",
    "    device: str = 'cuda', \n",
    "    k_logits: int = 5\n",
    ") -> None:\n",
    "    \n",
    "    # Split X into minibatches\n",
    "    dH_list = []\n",
    "    X = []\n",
    "    bottom_logits_list = []\n",
    "    top_logits_list = []\n",
    "    with torch.no_grad():\n",
    "        for x,jac in dataloader_X:\n",
    "            H = einops.einsum(jac.to(device), eigenmodel.u[feature_idx], '... w, w -> ...')            \n",
    "            dH_list.append(H)\n",
    "            X.append(x)\n",
    "    \n",
    "    if True:#for f in feature_idx:\n",
    "\n",
    "        # Concatenate dH results from all minibatches\n",
    "        feature_vals = (torch.cat(dH_list, dim=0))\n",
    "        X = (torch.cat(X, dim=0))\n",
    "\n",
    "        #top_logits_idx = torch.cat(top_logits_list, dim=1)\n",
    "        #bottom_logits_idx = torch.cat(bottom_logits_list, dim=1)\n",
    "\n",
    "        # Flatten the tensor to find the top k values globally\n",
    "        flattened_tensor = feature_vals.flatten()\n",
    "        #print(top_logits_idx.shape)\n",
    "        # Find the top 5 highest values and their indices in the flattened tensor\n",
    "        top_values, top_idx = torch.topk((flattened_tensor), top_k, largest=True)\n",
    "        # Convert the flattened indices back to the original 3D indices\n",
    "        top_idx_sample, top_idx_token = torch.unravel_index(top_idx, feature_vals.shape)\n",
    "\n",
    "\n",
    "        # Iterate over the top values and their indices\n",
    "        for (sample, token, value) in zip(top_idx_sample, top_idx_token, top_values):\n",
    "            #print(sample, token, value)\n",
    "            # Decode the entire sequence of tokens for the current sample as individual tokens\n",
    "            tokens_list = eigenmodel.model.tokenizer.convert_ids_to_tokens(X[sample].tolist())\n",
    "            \n",
    "            # Bold the token at the specific index\n",
    "            tokens_list[token] = f\"**{tokens_list[token]}**\"\n",
    "            \n",
    "            # Join the tokens back together for displaying\n",
    "            bolded_tokens = eigenmodel.model.tokenizer.convert_tokens_to_string(tokens_list[:(token+1)])\n",
    "            bolded_tokens = bolded_tokens.replace(\"\\n\", \"newline\")\n",
    "\n",
    "            # Decode the specific token with the highest value\n",
    "            token_of_value = eigenmodel.model.tokenizer.decode(X[sample, token]).replace(\"\\n\", \"newline\")\n",
    "            \n",
    "            #top_logits =  [eigenmodel.model.tokenizer.decode(i) for i in (top_logits_idx[:,sample,token])]\n",
    "            #bottom_logits =  [eigenmodel.model.tokenizer.decode(i) for i in (bottom_logits_idx[:,sample,token])]\n",
    "\n",
    "\n",
    "            # Print the modified tokens with the bolded token and its value\n",
    "            print(f\"{bolded_tokens} -> {token_of_value} (Value: {value:.3f})\")# top: {top_logits}, bottom: {bottom_logits}\")\n",
    "\n",
    "for i in range(50):\n",
    "    print(f'---------{i}--------')\n",
    "    PrintActivatingExamplesTransformer(\n",
    "        eigenmodel_transformer,\n",
    "        dataloader,\n",
    "        i,\n",
    "        5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[111], line 31\u001b[0m\n",
      "\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39mones_like(transformer_model(x)))\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;32m     28\u001b[0m eigenmodel_transformer \u001b[38;5;241m=\u001b[39m EigenEstimationComparison(transformer_model, transformer_model,\n",
      "\u001b[1;32m     29\u001b[0m                          custom_loss, n_u_vectors)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;32m---> 31\u001b[0m \u001b[43mTrainEigenEstimationComparison\u001b[49m\u001b[43m(\u001b[49m\u001b[43meigenmodel_transformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_transformer_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_penalty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac_chunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/brianna-interpretability/eigenestimation/eigenestimation_algorithm/train.py:128\u001b[0m, in \u001b[0;36mTrainEigenEstimationComparison\u001b[0;34m(eigenmodel, x_dataloader, lr, n_epochs, lambda_penalty, u_batch_size, jac_chunk_size, device)\u001b[0m\n",
      "\u001b[1;32m    126\u001b[0m dH_du_list \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;32m    127\u001b[0m u_list \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;32m--> 128\u001b[0m dP_du \u001b[38;5;241m=\u001b[39m \u001b[43meigenmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meigenmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac_chunk_size\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# n_classes n_u\u001b[39;00m\n",
      "\u001b[1;32m    129\u001b[0m H \u001b[38;5;241m=\u001b[39m einops\u001b[38;5;241m.\u001b[39meinsum(dP_du, dP_du, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv1 ..., v2 ... -> v1 v2 ...\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#/  dP_du.shape[-1]\u001b[39;00m\n",
      "\u001b[1;32m    130\u001b[0m lower_triangular_mask: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtril(\n",
      "\u001b[1;32m    131\u001b[0m     torch\u001b[38;5;241m.\u001b[39mones(H\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],H\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbool), diagonal\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;32m    132\u001b[0m     )\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\n",
      "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "File \u001b[0;32m~/brianna-interpretability/eigenestimation/eigenestimation_algorithm/eigenestimation.py:167\u001b[0m, in \u001b[0;36mEigenEstimationComparison.forward\u001b[0;34m(self, x, param_dict, chunk_size)\u001b[0m\n",
      "\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, param_dict, chunk_size) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor]:\n",
      "\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Compute the double gradient along u\u001b[39;00m\n",
      "\u001b[1;32m    166\u001b[0m     partial_func \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss, x)\n",
      "\u001b[0;32m--> 167\u001b[0m     jac \u001b[38;5;241m=\u001b[39m \u001b[43mjacrev\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    168\u001b[0m     j_vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams_to_vectors(jac)\n",
      "\u001b[1;32m    169\u001b[0m     j_u \u001b[38;5;241m=\u001b[39m einops\u001b[38;5;241m.\u001b[39meinsum(j_vector, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mu, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m... w, v w -> v ...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/eager_transforms.py:724\u001b[0m, in \u001b[0;36mjacrev.<locals>.wrapper_fn\u001b[0;34m(*args)\u001b[0m\n",
      "\u001b[1;32m    722\u001b[0m     flat_jacobians_per_input \u001b[38;5;241m=\u001b[39m compute_jacobian_preallocate_and_copy()\n",
      "\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m--> 724\u001b[0m     flat_jacobians_per_input \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_jacobian_stacked\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# Step 2: The returned jacobian is one big tensor per input. In this step,\u001b[39;00m\n",
      "\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# we split each Tensor by output.\u001b[39;00m\n",
      "\u001b[1;32m    728\u001b[0m flat_jacobians_per_input \u001b[38;5;241m=\u001b[39m [\n",
      "\u001b[1;32m    729\u001b[0m     result\u001b[38;5;241m.\u001b[39msplit(flat_output_numels, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;32m    730\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m flat_jacobians_per_input\n",
      "\u001b[1;32m    731\u001b[0m ]\n",
      "\n",
      "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/eager_transforms.py:646\u001b[0m, in \u001b[0;36mjacrev.<locals>.wrapper_fn.<locals>.compute_jacobian_stacked\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m    644\u001b[0m     chunked_result \u001b[38;5;241m=\u001b[39m vjp_fn(basis)\n",
      "\u001b[1;32m    645\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# chunk_size is None or chunk_size != 1\u001b[39;00m\n",
      "\u001b[0;32m--> 646\u001b[0m     chunked_result \u001b[38;5;241m=\u001b[39m \u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvjp_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbasis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    648\u001b[0m flat_results \u001b[38;5;241m=\u001b[39m pytree\u001b[38;5;241m.\u001b[39mtree_leaves(chunked_result)\n",
      "\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunk_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\n",
      "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/apis.py:203\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n",
      "\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/vmap.py:331\u001b[0m, in \u001b[0;36mvmap_impl\u001b[0;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(\n",
      "\u001b[1;32m    321\u001b[0m         func,\n",
      "\u001b[1;32m    322\u001b[0m         flat_in_dims,\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    327\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n",
      "\u001b[1;32m    328\u001b[0m     )\n",
      "\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n",
      "\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    340\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/vmap.py:479\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[0;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n",
      "\u001b[1;32m    476\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(\n",
      "\u001b[1;32m    477\u001b[0m         flat_in_dims, flat_args, vmap_level, args_spec\n",
      "\u001b[1;32m    478\u001b[0m     )\n",
      "\u001b[0;32m--> 479\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
      "\n",
      "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/eager_transforms.py:430\u001b[0m, in \u001b[0;36m_vjp_with_argnums.<locals>.wrapper\u001b[0;34m(cotangents, retain_graph, create_graph)\u001b[0m\n",
      "\u001b[1;32m    428\u001b[0m flat_cotangents, cotangents_spec \u001b[38;5;241m=\u001b[39m tree_flatten(cotangents)\n",
      "\u001b[1;32m    429\u001b[0m _vjp_treespec_compare(primals_out, cotangents)\n",
      "\u001b[0;32m--> 430\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43m_autograd_grad\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_primals_out\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_diff_primals\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_cotangents\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(result, primals_spec)\n",
      "\n",
      "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/_functorch/eager_transforms.py:180\u001b[0m, in \u001b[0;36m_autograd_grad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph)\u001b[0m\n",
      "\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(diff_outputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(torch\u001b[38;5;241m.\u001b[39mzeros_like(inp) \u001b[38;5;28;01mfor\u001b[39;00m inp \u001b[38;5;129;01min\u001b[39;00m inputs)\n",
      "\u001b[0;32m--> 180\u001b[0m grad_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiff_outputs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_outputs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    188\u001b[0m grad_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n",
      "\u001b[1;32m    189\u001b[0m     torch\u001b[38;5;241m.\u001b[39mzeros_like(inp) \u001b[38;5;28;01mif\u001b[39;00m gi \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gi\n",
      "\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m gi, inp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(grad_inputs, inputs)\n",
      "\u001b[1;32m    191\u001b[0m )\n",
      "\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad_inputs\n",
      "\n",
      "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/autograd/__init__.py:496\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n",
      "\u001b[1;32m    492\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n",
      "\u001b[1;32m    493\u001b[0m         grad_outputs_\n",
      "\u001b[1;32m    494\u001b[0m     )\n",
      "\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n",
      "\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n",
      "\u001b[1;32m    507\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n",
      "\u001b[1;32m    508\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n",
      "\u001b[1;32m    509\u001b[0m     ):\n",
      "\n",
      "File \u001b[0;32m~/brianna-interpretability/eigenestimation_venv/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n",
      "\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n",
      "\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n",
      "\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n",
      "\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#@title Train Eigenmodel\n",
    "n_u_vectors = 20\n",
    "batch_size = 16\n",
    "lambda_penalty = [1,.1]\n",
    "n_epochs = 10\n",
    "learning_rate = .001\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "x_transformer_dataloader = DataLoader(X_transformer[:100,], batch_size=batch_size, shuffle=True)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "def custom_loss(outputs, truth):\n",
    "    truth_rearranged = einops.rearrange(truth, '... p -> (...) p')\n",
    "    outputs_rearranged = einops.rearrange(outputs, '... p -> (...) p')\n",
    "\n",
    "    # Randomly select 3 indices based on probabilities in the last dimension\n",
    "    selected_indices = torch.multinomial(truth_rearranged, num_samples=2, replacement=True)\n",
    "    out = torch.gather(outputs_rearranged, 1, selected_indices) #nn.KLDivLoss(reduction='batchmean')(torch.log(torch.gather(truth_rearranged, 1, selected_indices)), torch.gather(outputs_rearranged, 1, selected_indices))\n",
    "    return out\n",
    "\n",
    "def M0(x):\n",
    "    return (torch.ones_like(transformer_model(x))).softmax(dim=-1)\n",
    "\n",
    "eigenmodel_transformer = EigenEstimationComparison(transformer_model, transformer_model,\n",
    "                         custom_loss, n_u_vectors).to(device)\n",
    "\n",
    "TrainEigenEstimationComparison(eigenmodel_transformer, x_transformer_dataloader, learning_rate, n_epochs, lambda_penalty, device='cuda', jac_chunk_size=50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eigenestimation_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
