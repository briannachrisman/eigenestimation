{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2025-02-19 02:10:31 ] Imported TimestampedTimer                                                    0.000 ms,         0.00 s total\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import wandb  # Add Weights & Biases for tracking\n",
    "import os\n",
    "import sys\n",
    "import transformer_lens\n",
    "# Import AutoTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from transformer_lens.utils import tokenize_and_concatenate\n",
    "# import tokenize_and_concatenate\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Append module directory for imports\n",
    "# Append module directory for imports\n",
    "parent_dir = os.path.expanduser('../eigenestimation')\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from eigenmodel.trainer import Trainer\n",
    "from eigenmodel.eigenmodel import EigenModel\n",
    "from utils.utils import TransformDataLoader, DeleteParams, RetrieveWandBArtifact\n",
    "from utils.loss import KLDivergenceVectorLoss\n",
    "\n",
    "\n",
    "from toy_models.transformer_wrapper import TransformerWrapper\n",
    "# Ensure correct device usage\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "from cycling_utils import TimestampedTimer\n",
    "\n",
    "timer = TimestampedTimer(\"Imported TimestampedTimer\")\n",
    "from utils.uniform_models import ZeroOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('transformer.transformer.wte.weight', 3216448), ('transformer.transformer.wpe.weight', 131072), ('transformer.transformer.h.0.ln_1.weight', 64), ('transformer.transformer.h.0.ln_1.bias', 64), ('transformer.transformer.h.0.attn.attention.k_proj.weight', 4096), ('transformer.transformer.h.0.attn.attention.v_proj.weight', 4096), ('transformer.transformer.h.0.attn.attention.q_proj.weight', 4096), ('transformer.transformer.h.0.attn.attention.out_proj.weight', 4096), ('transformer.transformer.h.0.attn.attention.out_proj.bias', 64), ('transformer.transformer.h.0.ln_2.weight', 64), ('transformer.transformer.h.0.ln_2.bias', 64), ('transformer.transformer.h.0.mlp.c_fc.weight', 16384), ('transformer.transformer.h.0.mlp.c_fc.bias', 256), ('transformer.transformer.h.0.mlp.c_proj.weight', 16384), ('transformer.transformer.h.0.mlp.c_proj.bias', 64), ('transformer.transformer.h.1.ln_1.weight', 64), ('transformer.transformer.h.1.ln_1.bias', 64), ('transformer.transformer.h.1.attn.attention.k_proj.weight', 4096), ('transformer.transformer.h.1.attn.attention.v_proj.weight', 4096), ('transformer.transformer.h.1.attn.attention.q_proj.weight', 4096), ('transformer.transformer.h.1.attn.attention.out_proj.weight', 4096), ('transformer.transformer.h.1.attn.attention.out_proj.bias', 64), ('transformer.transformer.h.1.ln_2.weight', 64), ('transformer.transformer.h.1.ln_2.bias', 64), ('transformer.transformer.h.1.mlp.c_fc.weight', 16384), ('transformer.transformer.h.1.mlp.c_fc.bias', 256), ('transformer.transformer.h.1.mlp.c_proj.weight', 16384), ('transformer.transformer.h.1.mlp.c_proj.bias', 64), ('transformer.transformer.h.2.ln_1.weight', 64), ('transformer.transformer.h.2.ln_1.bias', 64), ('transformer.transformer.h.2.attn.attention.k_proj.weight', 4096), ('transformer.transformer.h.2.attn.attention.v_proj.weight', 4096), ('transformer.transformer.h.2.attn.attention.q_proj.weight', 4096), ('transformer.transformer.h.2.attn.attention.out_proj.weight', 4096), ('transformer.transformer.h.2.attn.attention.out_proj.bias', 64), ('transformer.transformer.h.2.ln_2.weight', 64), ('transformer.transformer.h.2.ln_2.bias', 64), ('transformer.transformer.h.2.mlp.c_fc.weight', 16384), ('transformer.transformer.h.2.mlp.c_fc.bias', 256), ('transformer.transformer.h.2.mlp.c_proj.weight', 16384), ('transformer.transformer.h.2.mlp.c_proj.bias', 64), ('transformer.transformer.h.3.ln_1.weight', 64), ('transformer.transformer.h.3.ln_1.bias', 64), ('transformer.transformer.h.3.attn.attention.k_proj.weight', 4096), ('transformer.transformer.h.3.attn.attention.v_proj.weight', 4096), ('transformer.transformer.h.3.attn.attention.q_proj.weight', 4096), ('transformer.transformer.h.3.attn.attention.out_proj.weight', 4096), ('transformer.transformer.h.3.attn.attention.out_proj.bias', 64), ('transformer.transformer.h.3.ln_2.weight', 64), ('transformer.transformer.h.3.ln_2.bias', 64), ('transformer.transformer.h.3.mlp.c_fc.weight', 16384), ('transformer.transformer.h.3.mlp.c_fc.bias', 256), ('transformer.transformer.h.3.mlp.c_proj.weight', 16384), ('transformer.transformer.h.3.mlp.c_proj.bias', 64), ('transformer.transformer.h.4.ln_1.weight', 64), ('transformer.transformer.h.4.ln_1.bias', 64), ('transformer.transformer.h.4.attn.attention.k_proj.weight', 4096), ('transformer.transformer.h.4.attn.attention.v_proj.weight', 4096), ('transformer.transformer.h.4.attn.attention.q_proj.weight', 4096), ('transformer.transformer.h.4.attn.attention.out_proj.weight', 4096), ('transformer.transformer.h.4.attn.attention.out_proj.bias', 64), ('transformer.transformer.h.4.ln_2.weight', 64), ('transformer.transformer.h.4.ln_2.bias', 64), ('transformer.transformer.h.4.mlp.c_fc.weight', 16384), ('transformer.transformer.h.4.mlp.c_fc.bias', 256), ('transformer.transformer.h.4.mlp.c_proj.weight', 16384), ('transformer.transformer.h.4.mlp.c_proj.bias', 64), ('transformer.transformer.h.5.ln_1.weight', 64), ('transformer.transformer.h.5.ln_1.bias', 64), ('transformer.transformer.h.5.attn.attention.k_proj.weight', 4096), ('transformer.transformer.h.5.attn.attention.v_proj.weight', 4096), ('transformer.transformer.h.5.attn.attention.q_proj.weight', 4096), ('transformer.transformer.h.5.attn.attention.out_proj.weight', 4096), ('transformer.transformer.h.5.attn.attention.out_proj.bias', 64), ('transformer.transformer.h.5.ln_2.weight', 64), ('transformer.transformer.h.5.ln_2.bias', 64), ('transformer.transformer.h.5.mlp.c_fc.weight', 16384), ('transformer.transformer.h.5.mlp.c_fc.bias', 256), ('transformer.transformer.h.5.mlp.c_proj.weight', 16384), ('transformer.transformer.h.5.mlp.c_proj.bias', 64), ('transformer.transformer.h.6.ln_1.weight', 64), ('transformer.transformer.h.6.ln_1.bias', 64), ('transformer.transformer.h.6.attn.attention.k_proj.weight', 4096), ('transformer.transformer.h.6.attn.attention.v_proj.weight', 4096), ('transformer.transformer.h.6.attn.attention.q_proj.weight', 4096), ('transformer.transformer.h.6.attn.attention.out_proj.weight', 4096), ('transformer.transformer.h.6.attn.attention.out_proj.bias', 64), ('transformer.transformer.h.6.ln_2.weight', 64), ('transformer.transformer.h.6.ln_2.bias', 64), ('transformer.transformer.h.6.mlp.c_fc.weight', 16384), ('transformer.transformer.h.6.mlp.c_fc.bias', 256), ('transformer.transformer.h.6.mlp.c_proj.weight', 16384), ('transformer.transformer.h.6.mlp.c_proj.bias', 64), ('transformer.transformer.h.7.ln_1.weight', 64), ('transformer.transformer.h.7.ln_1.bias', 64), ('transformer.transformer.h.7.attn.attention.k_proj.weight', 4096), ('transformer.transformer.h.7.attn.attention.v_proj.weight', 4096), ('transformer.transformer.h.7.attn.attention.q_proj.weight', 4096), ('transformer.transformer.h.7.attn.attention.out_proj.weight', 4096), ('transformer.transformer.h.7.attn.attention.out_proj.bias', 64), ('transformer.transformer.h.7.ln_2.weight', 64), ('transformer.transformer.h.7.ln_2.bias', 64), ('transformer.transformer.h.7.mlp.c_fc.weight', 16384), ('transformer.transformer.h.7.mlp.c_fc.bias', 256), ('transformer.transformer.h.7.mlp.c_proj.weight', 16384), ('transformer.transformer.h.7.mlp.c_proj.bias', 64), ('transformer.transformer.ln_f.weight', 64), ('transformer.transformer.ln_f.bias', 64)]\n",
      "False\n",
      "False\n",
      "transformer.transformer.h.3.mlp.c_fc.weight torch.Size([256, 64]) 16384\n",
      "transformer.lm_head.weight torch.Size([50257, 64]) 3216448\n",
      "3232832\n",
      "transformer.transformer.h.3.mlp.c_fc.weight torch.Size([256, 64]) 16384\n",
      "transformer.lm_head.weight torch.Size([50257, 64]) 3216448\n"
     ]
    }
   ],
   "source": [
    "# @title Import pretrained gpt2 (2 layers)\n",
    "# Disable fused kernels (FlashAttention and memory-efficient attention)\n",
    "# We have to disable this to compute second-order gradients on transformer models.\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "\n",
    "# Ensure the math kernel is enabled (it is True by default)\n",
    "torch.backends.cuda.enable_math_sdp(True)\n",
    "# Download tinystories-1M, not from hookedtransformer\n",
    "# https://huggingface.co/datasets/roneneldan/TinyStories-1M\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "\n",
    "tinystories_1m = AutoModelForCausalLM.from_pretrained('roneneldan/TinyStories-1M')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "transformer_model = TransformerWrapper(tinystories_1m, tokenizer, outputs_logits=False)\n",
    "\n",
    "\n",
    "print( [(name, param.numel()) for name, param in transformer_model.named_parameters()])\n",
    "\n",
    "\n",
    "# Make the eigenestimation a little smaller but only looking at a subset of the parameters.\n",
    "# Pick a random subset of tensors to include in paramters, and turn the rest into frozen buffers.\n",
    "params_to_delete = [name for name, param in transformer_model.named_parameters()]\n",
    "\n",
    "print('transformer.lm_head.weight' in params_to_delete)\n",
    "\n",
    "params_to_delete = [p for p in params_to_delete if \n",
    "   'transformer.transformer.h.3.mlp.c_fc.weight' not in p]\n",
    "\n",
    "# Delete 3/4 of the parameters.\n",
    "#for p in (params_to_delete[::20]):\n",
    "#  params_to_delete.remove(p)\n",
    "\n",
    "DeleteParams(transformer_model, params_to_delete)\n",
    "\n",
    "print(sum([p.numel() for p in transformer_model.parameters()]))\n",
    "for n,p in transformer_model.named_parameters(): print(n, p.shape, p.numel())\n",
    "\n",
    "# Load in data.\n",
    "dataset = load_dataset('roneneldan/TinyStories', split=\"validation[:1%]\")\n",
    "X_transformer = tokenize_and_concatenate(dataset, transformer_model.tokenizer, max_length = 8, add_bos_token=False)['tokens']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('transformer.transformer.h.3.mlp.c_fc.weight', 16384), ('transformer.lm_head.weight', 3216448)]\n",
      "True\n",
      "True\n",
      "transformer.transformer.h.3.mlp.c_fc.weight torch.Size([256, 64]) 16384\n"
     ]
    }
   ],
   "source": [
    "transformer_model = TransformerWrapper(tinystories_1m, tokenizer, outputs_logits=False)\n",
    "\n",
    "\n",
    "print( [(name, param.numel()) for name, param in transformer_model.named_parameters()])\n",
    "\n",
    "\n",
    "# Make the eigenestimation a little smaller but only looking at a subset of the parameters.\n",
    "# Pick a random subset of tensors to include in paramters, and turn the rest into frozen buffers.\n",
    "params_to_delete = [name for name, param in transformer_model.named_parameters()]\n",
    "\n",
    "print('transformer.lm_head.weight' in params_to_delete)\n",
    "params_to_delete = [p for p in params_to_delete if \n",
    "   'transformer.transformer.h.3.mlp.c_fc.weight' not in p]\n",
    "print('transformer.lm_head.weight' in params_to_delete)\n",
    "\n",
    "DeleteParams(transformer_model, params_to_delete)\n",
    "for n,p in transformer_model.named_parameters():\n",
    "    print(n, p.shape, p.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.transformer.h.3.mlp.c_fc.weight torch.Size([256, 64]) 16384\n",
      "transformer.lm_head.weight torch.Size([50257, 64]) 3216448\n"
     ]
    }
   ],
   "source": [
    "for n,p in transformer_model.named_parameters(): print(n, p.shape, p.numel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_to_delete = [name for name, param in transformer_model.named_parameters()]\n",
    "\n",
    "params_to_delete = [p for p in params_to_delete if \n",
    "   'transformer.transformer.h.3.mlp.c_fc.weight' not in p]\n",
    "\n",
    "'transformer.lm_head.weight' in params_to_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_delete = [name for name, param in transformer_model.named_parameters()]\n",
    "DeleteParams(transformer_model, params_to_delete)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'transformer.lm_head.weight' in transformer_model.named_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for n,p in transformer_model.named_parameters(): print(n, p.shape, p.numel())\n",
    "print(sum([p.numel() for p in transformer_model.parameters()]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = X_transformer[::10,:8]\n",
    "eval_dataset = X_transformer[1::10,:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 7.7580,  2.3624, -7.0801,  ..., -8.2345,  1.1284,  1.7170],\n",
       "         [-0.2748,  6.6603, -1.8956,  ..., -4.4409, -1.2141,  3.7374],\n",
       "         [ 6.9880,  3.1286, -4.4858,  ..., -6.7440,  2.3033, -0.4636],\n",
       "         ...,\n",
       "         [ 7.2013, -1.0819, -7.8657,  ..., -6.3906, -5.0056, -2.4216],\n",
       "         [10.4197,  0.0953, -5.4691,  ..., -8.8656, -4.5735, -2.2194],\n",
       "         [ 1.0557,  1.6034, -6.9371,  ..., -7.0611,  5.1501,  0.2257]],\n",
       "\n",
       "        [[ 6.8507,  3.1315, -8.0478,  ..., -8.5349, -3.7631,  3.2066],\n",
       "         [ 2.7750,  4.4037, -4.5321,  ..., -7.9039, -5.9186,  3.0265],\n",
       "         [-4.1229,  9.9840,  2.3348,  ..., -1.8931,  4.5458,  2.5225],\n",
       "         ...,\n",
       "         [14.9818,  4.9248, -8.1071,  ..., -8.0346, -2.0046, -3.2659],\n",
       "         [ 3.9872,  1.0837, -8.7434,  ..., -7.4886, -3.3030, -1.9253],\n",
       "         [ 3.8538, -2.9488, -5.6578,  ..., -5.1305, -5.4858, -0.1017]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = model(X_transformer[:2,:8]).logits\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenestimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HERE!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CausalLMOutputWithPast' object has no attribute 'softmax'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[129], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m eigenmodel \u001b[38;5;241m=\u001b[39m EigenModel(transformer_model, ZeroOutput, KLDivergenceVectorLoss(), \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_batch \u001b[38;5;129;01min\u001b[39;00m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43meigenmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     loss \u001b[38;5;241m=\u001b[39m eigenmodel\u001b[38;5;241m.\u001b[39mloss(predictions, predictions)\n\u001b[1;32m      6\u001b[0m     grads \u001b[38;5;241m=\u001b[39m eigenmodel\u001b[38;5;241m.\u001b[39mcompute_gradients(X_batch[:\u001b[38;5;241m2\u001b[39m,:\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.eigenestimation/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/eigenestimation/notebooks/../eigenestimation/toy_models/transformer_wrapper.py:20\u001b[0m, in \u001b[0;36mTransformerWrapper.forward\u001b[0;34m(self, tokenized_X)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Rearrange the output to a flat batch of logits\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs_logits:\n\u001b[0;32m---> 20\u001b[0m     probs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[1;32m     22\u001b[0m     probs \u001b[38;5;241m=\u001b[39m (model_output\u001b[38;5;241m.\u001b[39mlogits)\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CausalLMOutputWithPast' object has no attribute 'softmax'"
     ]
    }
   ],
   "source": [
    "eigenmodel = EigenModel(transformer_model, ZeroOutput, KLDivergenceVectorLoss(), 10, 10)\n",
    "\n",
    "for X_batch in DataLoader(train_dataset, batch_size=2):\n",
    "    predictions = eigenmodel.model(X_batch)\n",
    "    loss = eigenmodel.loss(predictions, predictions)\n",
    "    grads = eigenmodel.compute_gradients(X_batch[:2,:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5854, 8])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import einops\n",
    "if True:\n",
    "            jvp_flattened = einops.rearrange(jvp, '... -> (...)')\n",
    "            # Get the nth highest value of jvp_flattened\n",
    "            with torch.no_grad():\n",
    "                top_k = .1\n",
    "                sorted_values, _ = torch.sort(abs(jvp_flattened), descending=True)#\n",
    "                nth_highest_value = sorted_values[round(top_k*len(jvp_flattened))]\n",
    "                nth_lowest_value = sorted_values[-round(top_k*len(jvp_flattened))]\n",
    "            jvp_topk = jvp*(abs(jvp)>=nth_highest_value).float()\n",
    "            jvp_bottomk = jvp*(abs(jvp)<=nth_lowest_value).float()\n",
    "            \n",
    "            reconstruction = eigenmodel.reconstruct(jvp_topk)\n",
    "\n",
    "compute_reconstruction_loss(reconstruction, gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reconstruction_loss(reconstruction, gradients):\n",
    "        #'''\n",
    "        \n",
    "        A_dot_A = (torch.concat([einops.rearrange(\n",
    "            reconstruction[name] * reconstruction[name], \n",
    "            f'b ... -> b (...)')\n",
    "                                 for name in gradients\n",
    "            ], dim=-1).sum(dim=-1)) # batch x params#.mean()#sum(dim=0).mean()\n",
    "                    \n",
    "            \n",
    "        B_dot_B = (torch.concat([einops.rearrange(\n",
    "                    gradients[name] * gradients[name], \n",
    "                    f'b ... -> b (...)')\n",
    "                for name in gradients\n",
    "            ], dim=-1).sum(dim=-1)) # batch x params#.mean()#sum(dim=0).mean()(dim=0).mean()\n",
    "            \n",
    "        A_dot_B = (torch.concat([einops.rearrange(\n",
    "                    reconstruction[name] * gradients[name], \n",
    "                    'b ... -> b (...)')\n",
    "                for name in gradients\n",
    "            ], dim=-1).sum(dim=-1)) # batch x params#.mean()#sum(dim=0).mean()(dim=0).mean()\n",
    "            \n",
    "        eps = 1e-10\n",
    "\n",
    "        L2_error = (A_dot_A*A_dot_A - 2*A_dot_B*A_dot_B + B_dot_B*B_dot_B).sum()/(B_dot_B*B_dot_B + eps).sum()\n",
    "\n",
    "        return L2_error #diff/baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/workspace/eigenestimation/notebooks/artifacts/eigenestimation_tiny_stores_transformer_1m_TopActivatingTexts:v5\n",
      "-----f0------\n",
      " with Max* and* have fun. They ran->0.0\n",
      " Max* and* Sue knew they had to help->0.0\n",
      " children in the classroom. The end*.*->0.0\n",
      "-----f1------\n",
      " at mom. He looked* at* dad.->0.0\n",
      "newline\"Tom* and* Anna, you are->0.0\n",
      " Lily and Ben. They looked* at* Mom->0.0\n",
      "-----f2------\n",
      "newlinenewlineBut then Lily remembered what* her*->0.0\n",
      " and lots* of* fun.Once upon a->0.0\n",
      ". What should they do?*newline*newline->0.0\n",
      "-----f3------\n",
      " and their owners. *newline*newlineSuddenly->0.0\n",
      " pick them* and* hold them close to her->0.0\n",
      ", he found a new truck* that*->0.0\n",
      "-----f4------\n",
      ".newlinenewlineWhen he got to* the*->0.0\n",
      " it. The ball goes faster* and* faster->0.0\n",
      ", Jack went outside to play* and* saw->0.0\n",
      "-----f5------\n",
      " mom bought him a trumpet*,* but he->0.0\n",
      ". She says, \"I* love* you->0.0\n",
      " talk. His mom found him* and* cried->0.0\n",
      "-----f6------\n",
      " bear. They tell them that they* have*->0.0\n",
      "?\" The little boy said*,* \"I->0.0\n",
      " From* that* day on, Lily played with->0.0\n",
      "-----f7------\n",
      " potatoes will be soft and yummy* soon*->0.0\n",
      ". He told them which way* to* go->0.0\n",
      " is an ice cream truck,* Lily*.->0.0\n",
      "-----f8------\n",
      " were playing in the park*.* They liked->0.0\n",
      " was more important than being bossy*.*->0.0\n",
      " he could finally eat it*.*newlinenewline->0.0\n",
      "-----f9------\n",
      "Ow! That hurts*!\"* he cried->0.0\n",
      " blue. The strange cloud was gone*.*->0.0\n",
      " end.Once upon a time*,* there->0.0\n",
      "-----f10------\n",
      ". She loved how it looked and* how*->0.0\n",
      ". She loved how* it* looked and how->0.0\n",
      " himself. newlinenewlineBut* then*,->0.0\n",
      "-----f11------\n",
      " with his mom* and* dad. They played->0.0\n",
      "my. Lily said yes*,* and her->0.0\n",
      " said, \"Wow,* Kitty*, your->0.0\n",
      "-----f12------\n",
      " rain helped the plants grow too*.*newline->0.0\n",
      " the fountain*,* but she couldn't reach->0.0\n",
      " There*,* they found a perfect outfit for->0.0\n",
      "-----f13------\n",
      " all day and* then* went back to their->0.0\n",
      "newlinenewline\"Are* you* okay, Lily->0.0\n",
      " robot and the little* girl* became friends.->0.0\n",
      "-----f14------\n",
      " From* that* day on, Lily played with->0.0\n",
      " wanted to see what was happening*,* so->0.0\n",
      " cheek. From* that* day on, Lily->0.0\n",
      "-----f15------\n",
      " hedge.* As* they were eating, they->0.0\n",
      "When she got home, she* told* her->0.0\n",
      " time, there was a little girl* named*->0.0\n",
      "-----f16------\n",
      " They do not know what to* say*.->0.0\n",
      "newlinenewline\"Wow*,* Lily! Your->0.0\n",
      " is an ice cream truck*,* Lily.->0.0\n",
      "-----f17------\n",
      "immons are fruits that grow on* trees*->0.0\n",
      " His friend*,* a wise owl named O->0.0\n",
      " for help,* but* it was too late->0.0\n",
      "-----f18------\n",
      ", red ball in the* park*. He->0.0\n",
      " trucks and my* dolls*. It will be->0.0\n",
      "newlinenewline\"Wow*,* Lily! Your->0.0\n",
      "-----f19------\n",
      " named Lily,* did* not permit Spot to->0.0\n",
      ". He told them which way* to* go->0.0\n",
      ". She loved how it looked* and* how->0.0\n",
      "-----f20------\n",
      " shiny gold coin* on* the ground.->0.0\n",
      " and their owners. *newline*newlineSuddenly->0.0\n",
      " carrot didn't taste good at all*!*->0.0\n",
      "-----f21------\n",
      ".newlinenewlineS*ara* did not want->0.0\n",
      " nothing happened.*newline*newline\"Be careful->0.0\n",
      " nothing happened.newlinenewline\"Be* careful*->0.0\n",
      "-----f22------\n",
      "newlinenewlineBut then Lily remembered what* her*->0.0\n",
      ", there was a big* lion*. He->0.0\n",
      " was very patient and waited for Lily* to*->0.0\n",
      "-----f23------\n",
      " goat was sad and* miserable*. newline->0.0\n",
      " He saw her on the ground,* crying*->0.0\n",
      ".newlinenewlineThey lined* up* their trucks->0.0\n",
      "-----f24------\n",
      " other treasures she* found*.Once upon a->0.0\n",
      ", red ball in the* park*. He->0.0\n",
      " wanted to eat something.*newline*newlineOne->0.0\n",
      "-----f25------\n",
      "Yes, Ben. This is End*.*->0.0\n",
      " children in the classroom. The end*.*->0.0\n",
      " to touch it. *newline*newline->0.0\n",
      "-----f26------\n",
      " with his mom* and* dad. They played->0.0\n",
      " found the cat* and* gave it some food->0.0\n",
      " to the park with Mom* and* Dad.->0.0\n",
      "-----f27------\n",
      " mean things to her. *newline*newline->0.0\n",
      " and their owners. *newline*newlineSuddenly->0.0\n",
      " goat was sad and miserable. *newline*->0.0\n",
      "-----f28------\n",
      " to touch it. *newline*newline->0.0\n",
      " goat was sad and miserable. *newline*->0.0\n",
      " mean things to her. *newline*newline->0.0\n",
      "-----f29------\n",
      "newlinenewline\"Are* you* okay, Lily->0.0\n",
      " robot and the little* girl* became friends.->0.0\n",
      ". He played with his friends* and* they->0.0\n",
      "-----f30------\n",
      " how to swim across* it*. One day->0.0\n",
      " pick them* and* hold them close to her->0.0\n",
      " mom bought him a trumpet*,* but he->0.0\n",
      "-----f31------\n",
      "newlineWhen they got home, Lily* pu*->0.0\n",
      " bear. They tell them that they* have*->0.0\n",
      " sweeties. Did you* have* fun?\"->0.0\n",
      "-----f32------\n",
      " faucet working. The moral* of*->0.0\n",
      " Mia's mom said, \"*This* f->0.0\n",
      "?\"newlinenewline\"Okay*,* I will->0.0\n",
      "-----f33------\n",
      " named Lily*,* did not permit Spot to->0.0\n",
      " like you*.\"*newlinenewlineTimmy was->0.0\n",
      " to cover his bald head and* went* to->0.0\n",
      "-----f34------\n",
      " \"Okay, let's swing together*!\"*->0.0\n",
      " his head.newline*newline*\"Ow->0.0\n",
      " fold the blankets. Finally*,* we need->0.0\n",
      "-----f35------\n",
      "Yes, Ben. This is End*.*->0.0\n",
      " children in the classroom. The end*.*->0.0\n",
      " are gone. The end*.*Lily->0.0\n",
      "-----f36------\n",
      " charity.* Now*, give them back or->0.0\n",
      " was so happy! She* and* Billy played->0.0\n",
      ". She loved how it looked* and* how->0.0\n",
      "-----f37------\n",
      "immons are fruits that* grow* on trees->0.0\n",
      "Pip* landed* on the branch and said->0.0\n",
      " hedge. As they* were* eating, they->0.0\n",
      "-----f38------\n",
      " robot and the little* girl* became friends.->0.0\n",
      " time at the lab with* his* friend Spot->0.0\n",
      " sad,* and* Sue was sorry. The->0.0\n",
      "-----f39------\n",
      " mean things to her. *newline*newline->0.0\n",
      " a cat. The cat was on* the*->0.0\n",
      " named Lily, did not permit Spot* to*->0.0\n",
      "-----f40------\n",
      " not very* fun*, but he took it->0.0\n",
      " She sees the letter.* It* is torn->0.0\n",
      " was so happy to* see* the pretty candle->0.0\n",
      "-----f41------\n",
      "\"Wow,* look* at this!\" Sara->0.0\n",
      " said, \"Wow,* Kitty*, your->0.0\n",
      " clothes, but none of them fit* him*->0.0\n",
      "-----f42------\n",
      "Mom said, \"L*ily*, we->0.0\n",
      " said, \"L*ily*, it'->0.0\n",
      " looked at Buzz*y* and said, \"->0.0\n",
      "-----f43------\n",
      " it home. newlinenewlineAt* home*->0.0\n",
      " \"Okay,* let*'s swing together!\"->0.0\n",
      ", red ball in the* park*. He->0.0\n",
      "-----f44------\n",
      "immons are fruits that grow on* trees*->0.0\n",
      " goat was sad and* miserable*. newline->0.0\n",
      ". She loved how* it* looked and how->0.0\n",
      "-----f45------\n",
      " saved me!\"newlinenewline\"I*'m*->0.0\n",
      " mean things to her. *newline*newline->0.0\n",
      " and your* box*.\"newlinenewlineThe man->0.0\n",
      "-----f46------\n",
      " robot and the little* girl* became friends.->0.0\n",
      " likes that.\"newlinenewlineAnna* gets* angry->0.0\n",
      ". She loved how* it* looked and how->0.0\n",
      "-----f47------\n",
      "\"Wow,* look* at this!\" Sara->0.0\n",
      ". She loved how it looked and* how*->0.0\n",
      ". He told them which way* to* go->0.0\n",
      "-----f48------\n",
      ", there* was* a big lion. He->0.0\n",
      ", there* was* a little boy named Tim->0.0\n",
      ", there* was* a little boy named Tim->0.0\n",
      "-----f49------\n",
      "newlinenewline\"Wow*,* Lily! Your->0.0\n",
      " happy bec*ause* she knew that meant the->0.0\n",
      " saw a charming butterfly* and* tried to catch->0.0\n",
      "-----f50------\n",
      " good to take a break* and* try again->0.0\n",
      ", \"L*ily*, it's time->0.0\n",
      " said, \"L*ily*, it'->0.0\n",
      "-----f51------\n",
      " if they would like to* adopt* a dog->0.0\n",
      " help. So, he got another* cow*->0.0\n",
      "ia looked at the shell and frowned*.*->0.0\n",
      "-----f52------\n",
      " to the park with Mom and* Dad*.->0.0\n",
      " smiled and said, \"Thanks,* mom*->0.0\n",
      ",* Mom*. Please, can he stay->0.0\n",
      "-----f53------\n",
      ".newlinenewlineThey lined* up* their trucks->0.0\n",
      " is a big* dog* with black and white->0.0\n",
      ". She gives* each* doll a cup and->0.0\n",
      "-----f54------\n",
      " friendly surfing crab* named* Crabby. Crab->0.0\n",
      " time, there was a little girl* named*->0.0\n",
      ", there was a little boy* named* Tim->0.0\n",
      "-----f55------\n",
      " were running and laughing on the* grass* when->0.0\n",
      " yellow bananas, and green* grapes*. Lily->0.0\n",
      " asked, feeling scared.newlinenewline*\"*->0.0\n",
      "-----f56------\n",
      "immons are fruits that* grow* on trees->0.0\n",
      "immons are fruits that grow on* trees*->0.0\n",
      ". But* it* still looked alive. Anna->0.0\n",
      "-----f57------\n",
      " children in the classroom. The end*.*->0.0\n",
      " are gone. The end*.*Lily->0.0\n",
      ". \"We* have* glue, we can->0.0\n",
      "-----f58------\n",
      ", \"L*ily*, it's time->0.0\n",
      " is an ice cream truck*,* Lily.->0.0\n",
      " named Lily,* did* not permit Spot to->0.0\n",
      "-----f59------\n",
      " and decided to share his ball* with* Sally->0.0\n",
      " They do not know what to* say*.->0.0\n",
      " not very* fun*, but he took it->0.0\n",
      "-----f60------\n",
      ".newlinenewlineThey lined* up* their trucks->0.0\n",
      " do anything dangerous again.*Once* upon a->0.0\n",
      ".*Once* upon a time, there w->0.0\n",
      "-----f61------\n",
      ". He told them which way* to* go->0.0\n",
      "newline\"Tom* and* Anna, you are->0.0\n",
      " was so happy! But* then* she heard->0.0\n",
      "-----f62------\n",
      ". He told them which way* to* go->0.0\n",
      " They talked about how the sun* makes* everything->0.0\n",
      " sad,* and* Sue was sorry. The->0.0\n",
      "-----f63------\n",
      "\"Wow,* look* at this!\" Sara->0.0\n",
      " talk. His mom found* him* and cried->0.0\n",
      " talk. His mom* found* him and cried->0.0\n",
      "-----f64------\n",
      "ayons. One* day*, Timmy->0.0\n",
      "ayons. One day*,* Timmy->0.0\n",
      ". What should they do?newline*newline*->0.0\n",
      "-----f65------\n",
      "newlinenewlineThe next day*,* Daddy got->0.0\n",
      " children in the classroom. The end*.*->0.0\n",
      "newlinenewline*As* she read more books,->0.0\n",
      "-----f66------\n",
      " saved me!\"*newline*newline\"I'm->0.0\n",
      " her mom if they could buy it*,*->0.0\n",
      " the story is* that* true friendship can help->0.0\n",
      "-----f67------\n",
      ". She loved how* it* looked and how->0.0\n",
      " She sees the letter.* It* is torn->0.0\n",
      "newlinenewline\"Are* you* okay, Lily->0.0\n",
      "-----f68------\n",
      ". He told them which way* to* go->0.0\n",
      " time at the lab with his friend* Spot*->0.0\n",
      " is a big* dog* with black and white->0.0\n",
      "-----f69------\n",
      "\"Wow*,* look at this!\" Sara->0.0\n",
      "newlinenewline\"Are you okay*,* Lily->0.0\n",
      "\"Wow,* look* at this!\" Sara->0.0\n",
      "-----f70------\n",
      "\"Wow, look at this*!\"* Sara->0.0\n",
      ".\" So*,* he swam and sw->0.0\n",
      " me?\" Her* friend* thought about it and->0.0\n",
      "-----f71------\n",
      " potatoes will be soft and yummy* soon*->0.0\n",
      "Pip landed* on* the branch and said->0.0\n",
      " little girl named Lily*.* She liked to->0.0\n",
      "-----f72------\n",
      " smiled and said, \"That's* so*->0.0\n",
      " is an ice cream truck*,* Lily.->0.0\n",
      " her mom and stayed away from the* snake*->0.0\n",
      "-----f73------\n",
      " thought it was not nice* to* fight.->0.0\n",
      " the sunflower and the butterfly every* day*->0.0\n",
      " to cover his bald head and* went* to->0.0\n",
      "-----f74------\n",
      " be with her* family* and couldn't wait->0.0\n",
      " said, \"L*ily*, it'->0.0\n",
      " for help*,* but it was too late->0.0\n",
      "-----f75------\n",
      "newlinenewline\"Wow*,* Lily! Your->0.0\n",
      "\"Wow*,* look at this!\" Sara->0.0\n",
      " said, \"Wow*,* Kitty, your->0.0\n",
      "-----f76------\n",
      " to the top floor and* had* a great->0.0\n",
      "\"Wow*,* look at this!\" Sara->0.0\n",
      " friendly surfing crab named Crab*by*. Crab->0.0\n",
      "-----f77------\n",
      "newlinenewline\"Are* you* okay, Lily->0.0\n",
      " talk. His mom found* him* and cried->0.0\n",
      " on. The house was* no* longer dark->0.0\n",
      "-----f78------\n",
      " is an ice cream truck*,* Lily.->0.0\n",
      " it home. newlinenewlineAt* home*->0.0\n",
      " robot and the little* girl* became friends.->0.0\n",
      "-----f79------\n",
      " Max and Sue knew they* had* to help->0.0\n",
      " bear. They tell them that they* have*->0.0\n",
      ". They all* had* fun together and Lily->0.0\n",
      "-----f80------\n",
      " children in the classroom. The end*.*->0.0\n",
      " The end*.*Once upon a time,->0.0\n",
      "\"Wow, look at this*!\"* Sara->0.0\n",
      "-----f81------\n",
      " There, they* found* a perfect outfit for->0.0\n",
      " wanted to see what was happening,* so*->0.0\n",
      ". But it still looked* alive*. Anna->0.0\n",
      "-----f82------\n",
      ". She loved how* it* looked and how->0.0\n",
      " Max* and* Sue knew they had to help->0.0\n",
      " sweeties. Did you* have* fun?\"->0.0\n",
      "-----f83------\n",
      " asked, feeling scared.*newline*newline\"->0.0\n",
      " to touch it. *newline*newline->0.0\n",
      " I stay with you?\" End asked*.*->0.0\n",
      "-----f84------\n",
      " rain helped the* plants* grow too.newline->0.0\n",
      " rain* helped* the plants grow too.newline->0.0\n",
      " enjoyed the sunshine*.*Once upon a time->0.0\n",
      "-----f85------\n",
      " talk. His mom found him* and* cried->0.0\n",
      " is an ice cream truck,* Lily*.->0.0\n",
      " with his owner,* Sarah*. Sarah let->0.0\n",
      "-----f86------\n",
      " pick them and* hold* them close to her->0.0\n",
      " back the jewelry now. It*'s* time->0.0\n",
      " to the park with Mom* and* Dad.->0.0\n",
      "-----f87------\n",
      " is a big* dog* with black and white->0.0\n",
      " the park. They* had* found a better->0.0\n",
      " her mom and stayed away from the* snake*->0.0\n",
      "-----f88------\n",
      " with Max* and* have fun. They ran->0.0\n",
      " on, Lily* and* the little bird became->0.0\n",
      ". You are very compassionate, Lily* and*->0.0\n",
      "-----f89------\n",
      ". He told them which way* to* go->0.0\n",
      "\"Wow*,* look at this!\" Sara->0.0\n",
      "newlinenewline\"Are you okay*,* Lily->0.0\n",
      "-----f90------\n",
      ", \"Lily, it*'s* time->0.0\n",
      "newlinenewline\"Are you* okay*, Lily->0.0\n",
      " lost toy. He searched everywhere* but* couldn->0.0\n",
      "-----f91------\n",
      " not very* fun*, but he took it->0.0\n",
      ".newlinenewlineOne day, they* found*->0.0\n",
      " to the park with Mom* and* Dad.->0.0\n",
      "-----f92------\n",
      " to play with cars and balls* and* blocks->0.0\n",
      " asked, feeling scared.newlinenewline*\"*->0.0\n",
      " to play with cars* and* balls and blocks->0.0\n",
      "-----f93------\n",
      " right away. She told* them* to stay->0.0\n",
      ". He told* them* which way to go->0.0\n",
      " charity.* Now*, give them back or->0.0\n",
      "-----f94------\n",
      ". She loved how* it* looked and how->0.0\n",
      " want to be* in* trouble. I want->0.0\n",
      " robot and the little girl* became* friends.->0.0\n",
      "-----f95------\n",
      ". What should they do?*newline*newline->0.0\n",
      " he could finally eat it.*newline*newline->0.0\n",
      " mom about her nightmare.*newline*newline\"->0.0\n",
      "-----f96------\n",
      "immons are fruits that grow* on* trees->0.0\n",
      " was so happy! She* and* Billy played->0.0\n",
      "immons are fruits* that* grow on trees->0.0\n",
      "-----f97------\n",
      " said, \"Wow,* Kitty*, your->0.0\n",
      " was so happy to* see* the pretty candle->0.0\n",
      "?\" The little boy said*,* \"I->0.0\n",
      "-----f98------\n",
      " goat was sad and* miserable*. newline->0.0\n",
      " and* slippery*, and they could see fish->0.0\n",
      " not very* fun*, but he took it->0.0\n",
      "-----f99------\n",
      " was more important than being boss*y*.->0.0\n",
      " island. On the island, they* saw*->0.0\n",
      " had a* name*. Her name was Daisy->0.0\n"
     ]
    }
   ],
   "source": [
    "top_texts = RetrieveWandBArtifact(project_path=f\"brianna-chrisman-2024/Eigenestimation/eigenestimation_{run_name}\", metric_name=\"TopActivatingTexts\")\n",
    "for feature_idx in top_texts:\n",
    "    print(f'-----f{feature_idx}------')\n",
    "    for val, _, _, text in top_texts[feature_idx]:\n",
    "        print(f'{text}->{round(val, 5)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".eigenestimation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
