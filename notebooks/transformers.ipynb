{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remember to login to wandb!\n",
    "import sys\n",
    "import os \n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import copy \n",
    "import numpy as np\n",
    "import gc\n",
    "import itertools\n",
    "# Append module directory for imports\n",
    "parent_dir = os.path.expanduser('../eigenestimation/eigenestimation')\n",
    "\n",
    "from eigenestimation.evaluation.networks import DrawNeuralNetwork\n",
    "from eigenestimation.eigenmodel.eigenmodel import EigenModel\n",
    "from eigenestimation.utils.loss import MSELoss\n",
    "from eigenestimation.utils.uniform_models import ZeroOutput\n",
    "from eigenestimation.toy_models.data import GenerateTMSInputs\n",
    "from eigenestimation.toy_models.parallel_serial_network import CustomMLP\n",
    "from torch import Tensor\n",
    "import einops\n",
    "\n",
    "import figure_names\n",
    "from datasets import load_dataset\n",
    "from transformer_lens.utils import tokenize_and_concatenate\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenmodel_path = f\"../outputs/eigenmodels/transformer.pt\"\n",
    "eigenmodel = torch.load(eigenmodel_path)['model']\n",
    "tokenizer = eigenmodel.model.tokenizer\n",
    "frac_activated = torch.load(eigenmodel_path)['frac_activated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tinystories data\n",
    "token_length = 8\n",
    "dataset = load_dataset('roneneldan/TinyStories', split=\"validation[:1%]\")\n",
    "X_transformer = tokenize_and_concatenate(dataset, tokenizer, max_length = token_length, add_bos_token=False)['tokens']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_vals = []\n",
    "X_ordered = []\n",
    "iters = 5\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "for X_batch in DataLoader(X_transformer[:1000], batch_size=8, shuffle=True):\n",
    "    X_ordered.append(X_batch)\n",
    "        # Compute gradients many times and take the average\n",
    "    each_circuit_val = torch.zeros(X_batch.shape[0]*X_batch.shape[1], eigenmodel.n_features).to('cuda')\n",
    "    for _ in range(iters):\n",
    "        grads = eigenmodel.compute_gradients(X_batch.to('cuda'))\n",
    "        each_circuit_val = each_circuit_val + abs(eigenmodel(grads))\n",
    "    circuit_vals.append(each_circuit_val.view(X_batch.shape[0], X_batch.shape[1], eigenmodel.n_features))\n",
    "circuit_vals = torch.concat(circuit_vals, dim=0)/iters\n",
    "X_ordered = torch.concat(X_ordered, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---- Feature 0 ---- Activation: 0.181\n",
      " named Tim went to play*** with*** his friend --> 47.54\n",
      ". He loved to play*** with*** his red --> 44.67\n",
      " played*** with*** the orange ball. But then --> 42.98\n",
      " and Lily played*** with*** the skull every day --> 42.53\n",
      " score. Sam was happy and*** not*** angry --> 39.25\n",
      "\n",
      "\n",
      "---- Feature 2 ---- Activation: 0.356\n",
      ". Mia was*** so*** tired that she closed --> 72.02\n",
      " anymore.=newline==newline=\"***Good*** job, --> 69.46\n",
      "Yes, I want*** to*** play, but --> 62.24\n",
      " was happy*** to*** help.=newline==newline=As --> 60.90\n",
      " shiny rock! Timmy*** was*** so happy --> 60.74\n",
      "\n",
      "\n",
      "---- Feature 4 ---- Activation: 0.412\n",
      " a time***,*** there was a big, --> 71.37\n",
      "Spot. Spot saw the shiny car*** and*** --> 69.25\n",
      " asked his friends to*** help*** him.=newline= --> 64.56\n",
      ".=newline==newline=***One*** day, they found --> 63.89\n",
      "Once upon a time, there*** was*** a --> 63.73\n",
      "\n",
      "\n",
      "---- Feature 5 ---- Activation: 0.173\n",
      " there was a little girl named Lily***.*** --> 45.24\n",
      ", they were happy to*** play*** and tease --> 42.64\n",
      ", Tom got lost in the park***.*** --> 34.48\n",
      " was a pirate named Tom***.*** Tom was --> 34.03\n",
      " thoughtful and careful.\" Sue felt proud*** that*** --> 33.97\n",
      "\n",
      "\n",
      "---- Feature 6 ---- Activation: 0.196\n",
      " boy who*** loved*** to share his toys with --> 47.60\n",
      "After a while, they*** got*** up and --> 44.33\n",
      " dog*** was*** big and had a name too --> 43.98\n",
      " favorite. Sue*** wanted*** to do something nice --> 42.75\n",
      " thoughtful and careful.\" Sue felt proud*** that*** --> 41.21\n",
      "\n",
      "\n",
      "---- Feature 8 ---- Activation: 0.215\n",
      "=newline==newline=***One*** day, Max and Sue --> 35.22\n",
      " day long.Once upon*** a*** time, --> 33.81\n",
      "Yes, I want*** to*** play, but --> 33.44\n",
      ", a little bird named Tweety***.*** --> 33.11\n",
      " had a big friend*** in*** Max.Once --> 32.18\n",
      "\n",
      "\n",
      "---- Feature 9 ---- Activation: 0.141\n",
      ", and laughed together***.***One day, --> 33.75\n",
      " sleep.=newline=***=newline=***One day, Mia --> 33.34\n",
      "=newline=***=newline=***Roxy told Billy about the --> 33.09\n",
      " time, there was a sweet dog*** named*** --> 32.71\n",
      ", \"***I*** can try!\"=newline==newline= --> 30.33\n",
      "\n",
      "\n",
      "---- Feature 10 ---- Activation: 0.469\n",
      ". Tim*** and*** his friends were so happy --> 89.02\n",
      " shiny rock! Timmy*** was*** so happy --> 74.13\n",
      " was happy*** to*** help.=newline==newline=As --> 73.38\n",
      " and Lily played*** with*** the skull every day --> 71.65\n",
      " found a big box*** and*** put it under --> 71.25\n",
      "\n",
      "\n",
      "---- Feature 13 ---- Activation: 0.399\n",
      ". Tim went outside*** and*** washed the truck --> 80.25\n",
      " saw a little box under a tree***.*** --> 73.62\n",
      "Yes, I want*** to*** play, but --> 68.98\n",
      ", they were happy to*** play*** and tease --> 66.58\n",
      " felt better soon. The next day***,*** --> 66.30\n",
      "\n",
      "\n",
      "---- Feature 14 ---- Activation: 0.354\n",
      " her chair. It*** was*** uncomfortable, but --> 68.60\n",
      " to play with it, but when*** he*** --> 62.50\n",
      " she wanted to climb it.=newline=***=newline=*** --> 61.38\n",
      "Once upon a time,*** there*** was a --> 59.27\n",
      " was happy to help.***=newline=***=newline=As --> 57.64\n",
      "\n",
      "\n",
      "---- Feature 16 ---- Activation: 0.293\n",
      " there was a little girl*** named*** Lily. --> 61.14\n",
      " time, there was a little girl*** named*** --> 57.72\n",
      "Once upon a time***,*** there was a --> 52.14\n",
      " there was a little girl*** named*** Mia. --> 49.00\n",
      "Once upon a time***,*** there was a --> 44.13\n",
      "\n",
      "\n",
      "---- Feature 17 ---- Activation: 0.354\n",
      ",*** \"***I can't find my belt --> 65.28\n",
      " the book.***=newline=***=newline=As Mia read --> 57.69\n",
      " very yummy, and Lily*** was*** happy --> 49.95\n",
      " shiny rock! Timmy*** was*** so happy --> 49.90\n",
      " big tree, and everyone was*** happy***. --> 49.82\n",
      "\n",
      "\n",
      "---- Feature 18 ---- Activation: 0.154\n",
      " the jewelry back*** in*** the box and went --> 37.76\n",
      " big tree and play*** with*** the other bees --> 37.60\n",
      " Tim. Tim*** had*** a big, orange --> 35.31\n",
      ", \"Thank*** you***, Sam!\" They --> 35.21\n",
      " Roxy was*** sad*** and asked, \" --> 31.35\n",
      "\n",
      "\n",
      "---- Feature 20 ---- Activation: 0.182\n",
      ",*** \"***I can't find my belt --> 42.18\n",
      " She loved to help*** her*** mom in the --> 39.67\n",
      " Max. Max loved to jog in*** the*** --> 39.43\n",
      " One day,*** her*** mom asked her to --> 35.40\n",
      " nail. The ants did*** not*** know what --> 34.07\n",
      "\n",
      "\n",
      "---- Feature 21 ---- Activation: 0.287\n",
      " little bird named Billy. Billy saw*** that*** --> 54.47\n",
      "=newline==newline=One day***,*** Mia was very --> 53.31\n",
      "Yes, I want*** to*** play, but --> 43.77\n",
      "One day,*** a*** small cat named Tim --> 40.70\n",
      " loved his orange ball. Sue*** said***, --> 40.18\n",
      "\n",
      "\n",
      "---- Feature 23 ---- Activation: 0.396\n",
      "Yes, I want*** to*** play, but --> 66.01\n",
      " boy who loved to share his toys*** with*** --> 65.10\n",
      " it was time to pick the vegetables*** for*** --> 60.67\n",
      "Once upon a time,*** there*** was a --> 59.38\n",
      " knew he should*** not*** kick the ball too --> 56.04\n",
      "\n",
      "\n",
      "---- Feature 24 ---- Activation: 0.145\n",
      " her chair. It*** was*** uncomfortable, but --> 43.18\n",
      ". Tim and his friends were*** so*** happy --> 41.44\n",
      " bunny.One day,*** a*** little boy --> 36.67\n",
      " very yummy, and Lily*** was*** happy --> 36.32\n",
      "=newline=Later, Lily saw*** how*** sad Spot --> 36.31\n",
      "\n",
      "\n",
      "---- Feature 25 ---- Activation: 0.118\n",
      " very happy.Once upon a time***,*** --> 36.27\n",
      " small pond.*** He*** was very hungry and --> 35.88\n",
      " and saw the flower too.*** \"***That --> 34.19\n",
      " tried again*** and*** again, but the ball --> 33.33\n",
      "Once upon a time, there*** was*** a --> 32.76\n",
      "\n",
      "\n",
      "---- Feature 26 ---- Activation: 0.542\n",
      " up. She searched the park*** for*** her --> 83.80\n",
      " a little girl*** named*** Lily. She went --> 83.77\n",
      ". Sam wanted to help*** his*** friend feel --> 77.45\n",
      " He loved to play*** with*** his ball in --> 77.00\n",
      ", Tim*** met*** a strange man. The --> 75.84\n",
      "\n",
      "\n",
      "---- Feature 27 ---- Activation: 0.214\n",
      " He loved*** to*** play with his ball in --> 77.18\n",
      " map. He decided*** to*** look for the --> 57.67\n",
      " The family was very happy*** to*** have met --> 57.26\n",
      " Max. Max loved*** to*** jog in the --> 56.34\n",
      " was happy*** to*** help.=newline==newline=As --> 55.45\n",
      "\n",
      "\n",
      "---- Feature 29 ---- Activation: 0.425\n",
      ", \"I can***'t*** find my belt --> 67.19\n",
      " a time***,*** there was a little girl --> 63.66\n",
      " a time***,*** there was a little boy --> 60.25\n",
      " to play with her*** ball*** and jump around --> 60.22\n",
      " was a little boy named Tim.*** Tim*** --> 58.53\n",
      "\n",
      "\n",
      "---- Feature 30 ---- Activation: 0.259\n",
      " hug. From*** that*** day on, Tom --> 55.53\n",
      " named Tim went to play*** with*** his friend --> 46.04\n",
      " day, Daisy saw a dog***.*** The --> 45.44\n",
      "ture and couldn***'t*** wait to explore --> 43.92\n",
      " saw a little box under a tree***.*** --> 43.02\n",
      "\n",
      "\n",
      "---- Feature 32 ---- Activation: 0.498\n",
      " Sam,\" said Tim.*** \"***Do you --> 81.55\n",
      " to play in the yard***.*** Daisy liked --> 79.27\n",
      " fast as he could***.*** The alligator --> 79.20\n",
      " Bob had an idea***.*** \"We can --> 77.75\n",
      " unknown in the mud***.*** It was a --> 74.36\n",
      "\n",
      "\n",
      "---- Feature 37 ---- Activation: 0.149\n",
      " named Lily***,*** did not permit Spot to --> 46.10\n",
      "=newline=One day,*** Lily***'s mom said --> 45.36\n",
      " a little bird that couldn***'t*** fly. --> 44.75\n",
      " there was a little girl named*** Lily***. --> 41.78\n",
      " time, there was a little girl*** named*** --> 38.81\n",
      "\n",
      "\n",
      "---- Feature 38 ---- Activation: 0.364\n",
      ", her mom*** asked*** her to wipe the --> 60.80\n",
      " led them to*** help*** the little bird. --> 57.25\n",
      ". They played together in the sea***.*** --> 57.22\n",
      " went to his mommy and*** said***, --> 56.67\n",
      " stronger. His friends*** saw*** him and wanted --> 55.12\n",
      "\n",
      "\n",
      "---- Feature 39 ---- Activation: 0.443\n",
      " was happy to help.***=newline=***=newline=As --> 109.25\n",
      " to find the treasure.***=newline=***=newline=In --> 100.78\n",
      " ran to get help.***=newline=***=newline=Sadly --> 92.72\n",
      " she could help her mom.***=newline=***=newline= --> 88.93\n",
      " time for bed.***=newline=***=newline=Mia --> 87.25\n",
      "\n",
      "\n",
      "---- Feature 43 ---- Activation: 0.251\n",
      ",*** \"***I can't find my belt --> 50.32\n",
      " with the sun shining and birds singing***.*** --> 49.26\n",
      " to play and run all day.*** One*** --> 47.47\n",
      " a*** time***, there was a little boy --> 45.29\n",
      " him a new TV, so*** he*** started --> 42.46\n",
      "\n",
      "\n",
      "---- Feature 45 ---- Activation: 0.309\n",
      " favorite. Sue*** wanted*** to do something nice --> 59.14\n",
      "Once upon a time***,*** there was a --> 52.53\n",
      ", Sam. They wanted to*** play*** a --> 50.77\n",
      "=newline=Later, Lily saw*** how*** sad Spot --> 46.45\n",
      "When they got*** to*** the train station, --> 45.39\n",
      "\n",
      "\n",
      "---- Feature 46 ---- Activation: 0.453\n",
      " car. Tim*** was*** so happy to have --> 80.93\n",
      " ball. One sunny day, Tom*** went*** --> 75.91\n",
      " car. Tim was*** so*** happy to have --> 75.55\n",
      "The moral of the story is*** to*** always --> 65.17\n",
      ". Sam wanted*** to*** help his friend feel --> 61.63\n",
      "\n",
      "\n",
      "---- Feature 47 ---- Activation: 0.325\n",
      "=newline==newline=One day, Max*** and*** Sue --> 56.52\n",
      " tree. He was very happy***.*** Tom --> 55.07\n",
      " trip. They*** had*** to pack their clothes --> 54.50\n",
      " in the video. They laughed and*** had*** --> 52.60\n",
      ". From*** that*** day on, Buzzy --> 51.84\n",
      "\n",
      "\n",
      "---- Feature 48 ---- Activation: 0.635\n",
      " round rock. He picked it*** up*** and --> 135.13\n",
      ", rocks, and hills. One*** day*** --> 117.08\n",
      " to complain. He was*** sad*** and bored --> 116.90\n",
      ". They played*** together*** in the sea. --> 115.96\n",
      " One day, her mom asked*** her*** to --> 109.50\n",
      "\n",
      "\n",
      "---- Feature 49 ---- Activation: 0.236\n",
      "=newline=One day, Kitty*** saw*** a tap --> 61.06\n",
      "=newline==newline=Lily took a big*** bite*** --> 59.31\n",
      ".Once upon a time***,*** there was --> 48.29\n",
      "=newline==newline=***One*** day, Max and Sue --> 46.26\n",
      ", rocks, and hills. One*** day*** --> 45.69\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "bold_idx = tokenizer.encode('***')\n",
    "\n",
    "for i in range(eigenmodel.n_features):\n",
    "    if frac_activated[i] < 0.05:\n",
    "        continue\n",
    "    \n",
    "    # Get the absolute values for feature i\n",
    "    abs_vals = (circuit_vals[..., i])\n",
    "\n",
    "    # Find the top 5 (b, t) indices for feature i\n",
    "    top_indices = abs_vals.flatten().argsort(descending=True)[:5]\n",
    "    \n",
    "    # Convert the flat indices back to (b, t) indices\n",
    "    top_b, top_t = torch.div(top_indices, token_length, rounding_mode='floor'), top_indices % token_length\n",
    "\n",
    "    # Get the corresponding top values\n",
    "    top_values = abs_vals[top_b, top_t]\n",
    "\n",
    "    print(f'\\n\\n---- Feature {i} ---- Activation: {frac_activated[i]:.3f}')\n",
    "    for j in range(len(top_indices)):\n",
    "        sample_idx = top_b[j].item()\n",
    "        token_idx = top_t[j].item()\n",
    "        tokens = X_ordered[sample_idx]\n",
    "        tokens = torch.cat([tokens[:token_idx], torch.Tensor(bold_idx), tokens[token_idx:]])\n",
    "        tokens = torch.cat([tokens[:(token_idx+2)], torch.Tensor(bold_idx), tokens[(token_idx+2):]])\n",
    "        sentence = tokenizer.decode(tokens.long())\n",
    "        sentence = sentence.replace('\\n', '=newline=')\n",
    "        print(sentence, '-->', f'{top_values[j].item():.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.eigenestimation/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight torch.Size([50257, 64]) 3216448\n",
      "transformer.wpe.weight torch.Size([2048, 64]) 131072\n",
      "transformer.h.0.ln_1.weight torch.Size([64]) 64\n",
      "transformer.h.0.ln_1.bias torch.Size([64]) 64\n",
      "transformer.h.0.attn.attention.k_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.0.attn.attention.v_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.0.attn.attention.q_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.0.attn.attention.out_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.0.attn.attention.out_proj.bias torch.Size([64]) 64\n",
      "transformer.h.0.ln_2.weight torch.Size([64]) 64\n",
      "transformer.h.0.ln_2.bias torch.Size([64]) 64\n",
      "transformer.h.0.mlp.c_fc.weight torch.Size([256, 64]) 16384\n",
      "transformer.h.0.mlp.c_fc.bias torch.Size([256]) 256\n",
      "transformer.h.0.mlp.c_proj.weight torch.Size([64, 256]) 16384\n",
      "transformer.h.0.mlp.c_proj.bias torch.Size([64]) 64\n",
      "transformer.h.1.ln_1.weight torch.Size([64]) 64\n",
      "transformer.h.1.ln_1.bias torch.Size([64]) 64\n",
      "transformer.h.1.attn.attention.k_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.1.attn.attention.v_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.1.attn.attention.q_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.1.attn.attention.out_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.1.attn.attention.out_proj.bias torch.Size([64]) 64\n",
      "transformer.h.1.ln_2.weight torch.Size([64]) 64\n",
      "transformer.h.1.ln_2.bias torch.Size([64]) 64\n",
      "transformer.h.1.mlp.c_fc.weight torch.Size([256, 64]) 16384\n",
      "transformer.h.1.mlp.c_fc.bias torch.Size([256]) 256\n",
      "transformer.h.1.mlp.c_proj.weight torch.Size([64, 256]) 16384\n",
      "transformer.h.1.mlp.c_proj.bias torch.Size([64]) 64\n",
      "transformer.h.2.ln_1.weight torch.Size([64]) 64\n",
      "transformer.h.2.ln_1.bias torch.Size([64]) 64\n",
      "transformer.h.2.attn.attention.k_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.2.attn.attention.v_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.2.attn.attention.q_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.2.attn.attention.out_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.2.attn.attention.out_proj.bias torch.Size([64]) 64\n",
      "transformer.h.2.ln_2.weight torch.Size([64]) 64\n",
      "transformer.h.2.ln_2.bias torch.Size([64]) 64\n",
      "transformer.h.2.mlp.c_fc.weight torch.Size([256, 64]) 16384\n",
      "transformer.h.2.mlp.c_fc.bias torch.Size([256]) 256\n",
      "transformer.h.2.mlp.c_proj.weight torch.Size([64, 256]) 16384\n",
      "transformer.h.2.mlp.c_proj.bias torch.Size([64]) 64\n",
      "transformer.h.3.ln_1.weight torch.Size([64]) 64\n",
      "transformer.h.3.ln_1.bias torch.Size([64]) 64\n",
      "transformer.h.3.attn.attention.k_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.3.attn.attention.v_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.3.attn.attention.q_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.3.attn.attention.out_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.3.attn.attention.out_proj.bias torch.Size([64]) 64\n",
      "transformer.h.3.ln_2.weight torch.Size([64]) 64\n",
      "transformer.h.3.ln_2.bias torch.Size([64]) 64\n",
      "transformer.h.3.mlp.c_fc.weight torch.Size([256, 64]) 16384\n",
      "transformer.h.3.mlp.c_fc.bias torch.Size([256]) 256\n",
      "transformer.h.3.mlp.c_proj.weight torch.Size([64, 256]) 16384\n",
      "transformer.h.3.mlp.c_proj.bias torch.Size([64]) 64\n",
      "transformer.h.4.ln_1.weight torch.Size([64]) 64\n",
      "transformer.h.4.ln_1.bias torch.Size([64]) 64\n",
      "transformer.h.4.attn.attention.k_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.4.attn.attention.v_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.4.attn.attention.q_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.4.attn.attention.out_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.4.attn.attention.out_proj.bias torch.Size([64]) 64\n",
      "transformer.h.4.ln_2.weight torch.Size([64]) 64\n",
      "transformer.h.4.ln_2.bias torch.Size([64]) 64\n",
      "transformer.h.4.mlp.c_fc.weight torch.Size([256, 64]) 16384\n",
      "transformer.h.4.mlp.c_fc.bias torch.Size([256]) 256\n",
      "transformer.h.4.mlp.c_proj.weight torch.Size([64, 256]) 16384\n",
      "transformer.h.4.mlp.c_proj.bias torch.Size([64]) 64\n",
      "transformer.h.5.ln_1.weight torch.Size([64]) 64\n",
      "transformer.h.5.ln_1.bias torch.Size([64]) 64\n",
      "transformer.h.5.attn.attention.k_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.5.attn.attention.v_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.5.attn.attention.q_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.5.attn.attention.out_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.5.attn.attention.out_proj.bias torch.Size([64]) 64\n",
      "transformer.h.5.ln_2.weight torch.Size([64]) 64\n",
      "transformer.h.5.ln_2.bias torch.Size([64]) 64\n",
      "transformer.h.5.mlp.c_fc.weight torch.Size([256, 64]) 16384\n",
      "transformer.h.5.mlp.c_fc.bias torch.Size([256]) 256\n",
      "transformer.h.5.mlp.c_proj.weight torch.Size([64, 256]) 16384\n",
      "transformer.h.5.mlp.c_proj.bias torch.Size([64]) 64\n",
      "transformer.h.6.ln_1.weight torch.Size([64]) 64\n",
      "transformer.h.6.ln_1.bias torch.Size([64]) 64\n",
      "transformer.h.6.attn.attention.k_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.6.attn.attention.v_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.6.attn.attention.q_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.6.attn.attention.out_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.6.attn.attention.out_proj.bias torch.Size([64]) 64\n",
      "transformer.h.6.ln_2.weight torch.Size([64]) 64\n",
      "transformer.h.6.ln_2.bias torch.Size([64]) 64\n",
      "transformer.h.6.mlp.c_fc.weight torch.Size([256, 64]) 16384\n",
      "transformer.h.6.mlp.c_fc.bias torch.Size([256]) 256\n",
      "transformer.h.6.mlp.c_proj.weight torch.Size([64, 256]) 16384\n",
      "transformer.h.6.mlp.c_proj.bias torch.Size([64]) 64\n",
      "transformer.h.7.ln_1.weight torch.Size([64]) 64\n",
      "transformer.h.7.ln_1.bias torch.Size([64]) 64\n",
      "transformer.h.7.attn.attention.k_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.7.attn.attention.v_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.7.attn.attention.q_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.7.attn.attention.out_proj.weight torch.Size([64, 64]) 4096\n",
      "transformer.h.7.attn.attention.out_proj.bias torch.Size([64]) 64\n",
      "transformer.h.7.ln_2.weight torch.Size([64]) 64\n",
      "transformer.h.7.ln_2.bias torch.Size([64]) 64\n",
      "transformer.h.7.mlp.c_fc.weight torch.Size([256, 64]) 16384\n",
      "transformer.h.7.mlp.c_fc.bias torch.Size([256]) 256\n",
      "transformer.h.7.mlp.c_proj.weight torch.Size([64, 256]) 16384\n",
      "transformer.h.7.mlp.c_proj.bias torch.Size([64]) 64\n",
      "transformer.ln_f.weight torch.Size([64]) 64\n",
      "transformer.ln_f.bias torch.Size([64]) 64\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained('roneneldan/TinyStories-1M')\n",
    "for n,p in model.named_parameters(): print(n, p.shape, p.numel())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".eigenestimation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
