{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.eigenestimation/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import sys \n",
    "import importlib\n",
    "\n",
    "# Add the test directory to sys.path\n",
    "parent_dir = os.path.expanduser('../eigenestimation')\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Standard library imports\n",
    "import importlib\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "# Third-party imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import GPT2Model, GPT2Config, GPT2Tokenizer\n",
    "from datasets import load_dataset\n",
    "from transformer_lens.utils import tokenize_and_concatenate\n",
    "from evaluation.networks import DrawNeuralNetwork\n",
    "\n",
    "\n",
    "# Reload modules for interactive sessions\n",
    "\n",
    "# Specific imports from local modules\n",
    "from toy_models.polytope import ReluNetwork, GeneratePolytopeData\n",
    "from toy_models.trainer import Trainer\n",
    "\n",
    "# Device configuration\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4789"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polytope = torch.load('../outputs/toy_models/polytope.pt')\n",
    "polytope_data = torch.load('../outputs/toy_models/polytope_data.pt')\n",
    "X = 5*torch.rand(10000, 2)\n",
    "\n",
    "\n",
    "np.mean(polytope['model'].to(device)(\n",
    "    X.to(device)).argmax(dim=-1).cpu().numpy() == np.array([polytope_data[tuple(x.tolist())] for x in X.floor().long()])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8, 16, 18, 15,  8, 21, 18,  8, 24,  8,  7, 19, 21, 10, 20, 14, 20,  7,\n",
       "         5,  4, 21, 10, 18, 13, 18, 19, 17,  7, 17, 24, 23, 19, 24, 10, 16, 21,\n",
       "        10,  3,  4, 20, 13, 17,  7,  3, 21, 20, 18, 24,  3, 17, 24, 20, 23,  3,\n",
       "         9,  2, 15,  2, 17, 20, 20, 17, 18,  5, 19, 21, 23, 23, 24, 13, 23, 18,\n",
       "         4, 14,  2, 24, 24, 12, 22,  9,  2,  6,  2, 19, 19, 13, 20, 23, 20,  5,\n",
       "        23, 24, 13, 18, 10,  5, 18, 20, 11, 19, 10, 24, 11,  2,  3, 12, 22, 18,\n",
       "         2, 18,  9, 18, 10,  7,  2, 22, 24, 17, 12, 24, 20,  6,  8, 16,  2, 13,\n",
       "        10, 24,  7, 18, 16, 13, 20, 24, 14, 19, 16, 18, 14, 19, 24,  1,  5, 21,\n",
       "         5,  2, 24, 20, 20, 10,  4,  2, 18, 21,  2, 20,  4, 24,  5,  5, 21, 21,\n",
       "         8, 23, 12, 14, 23, 21, 24,  4, 10, 15,  4,  8, 13, 13,  2, 24, 22,  4,\n",
       "        24,  2, 10, 22, 18, 24, 12, 22, 23, 16, 16,  1,  4,  3,  4,  2,  7,  8,\n",
       "        10,  7, 21, 18,  8,  2, 20, 20, 21,  3, 23,  5, 19,  2,  4,  4, 18, 13,\n",
       "        21, 22,  7, 21, 12,  7, 18, 17, 18,  1, 11, 19,  2, 24, 17,  4,  5, 23,\n",
       "        22, 17, 17,  9,  5,  3, 23, 20,  2, 13, 23, 19, 17,  5, 24, 24, 16, 13,\n",
       "         2,  2, 10, 12, 13, 13, 13, 23, 20, 18,  4,  8, 23,  2, 12, 20, 19, 21,\n",
       "         9, 12,  7, 13, 21,  4,  5, 10, 21,  4,  8, 16, 19,  2, 24, 19, 20, 12,\n",
       "        17, 22, 18, 24, 19, 18,  4, 13,  9,  1, 20,  9,  9, 24,  5, 23,  8, 13,\n",
       "         9, 23, 14, 16,  4,  9,  9,  8, 17, 17,  8, 24, 21,  9,  5,  5,  1, 16,\n",
       "        24,  4,  8,  8, 22,  2, 10,  1, 16,  7, 12, 19, 21,  5, 22, 21, 21,  2,\n",
       "        12, 17,  5, 10,  8,  2, 13, 19,  3, 17, 10, 24, 23,  9, 17, 16, 21,  8,\n",
       "         3,  8,  9, 14, 18,  1,  9, 18, 18, 17, 10, 18, 10, 18,  9, 16, 16,  4,\n",
       "        18, 24, 20, 13, 18,  5,  7, 18,  8,  4,  4,  7, 13,  5,  2,  8, 12, 23,\n",
       "        18,  4, 23, 10,  4, 16, 24,  3,  3, 18, 10, 16, 16, 22, 17, 20, 16, 13,\n",
       "        10,  8, 16, 10,  4, 13, 22, 22,  3, 19, 12,  4,  5,  5,  4, 14,  8, 21,\n",
       "         5, 17,  8,  8,  8, 17, 17,  8, 24,  2, 24,  9,  3,  5, 24, 22, 11,  9,\n",
       "        13, 24, 22, 24, 18, 23, 22, 22,  8,  8, 13, 22,  9,  2,  9, 11, 21,  4,\n",
       "        11,  6,  8, 18, 10, 20, 11, 19,  2, 24, 19, 18, 10, 24, 10, 17, 20,  2,\n",
       "         5, 17, 13, 24,  3,  5, 13,  2, 20, 21, 22,  8, 24, 11, 17, 22, 23,  3,\n",
       "         2, 14, 23,  6, 16,  9,  8,  3, 10, 18,  9, 22, 24,  3, 16, 12, 12,  8,\n",
       "         8, 21, 13,  5, 12, 21,  4,  8, 12,  8, 12,  9, 22, 18,  6,  2, 10,  6,\n",
       "        10, 10, 24, 18, 10,  3, 23,  5,  3,  9,  7,  4,  5, 14, 18, 22, 20, 16,\n",
       "        19, 17,  8, 16,  8,  8, 21, 16, 21,  4,  5,  4, 17,  4, 18, 17,  2, 23,\n",
       "         8,  9, 23,  7, 22,  7, 12, 21,  7,  2, 20, 20, 18, 10,  9, 24,  8,  4,\n",
       "        17, 20,  5, 14,  5, 22, 19, 24,  9, 17,  5, 17,  6, 23, 22,  2, 17,  5,\n",
       "        24, 16, 17, 10,  2,  1, 11, 17, 24, 18, 21, 23, 22,  5,  5, 24, 15, 24,\n",
       "         9, 17, 12, 16, 18, 19, 20, 22,  4,  9, 18, 17, 15,  2, 19, 24,  4, 20,\n",
       "         5,  4,  2, 22,  8, 18, 18, 24, 24, 17, 12, 16,  8, 23, 21, 20, 13, 24,\n",
       "        20,  8,  4, 18, 22, 16, 22, 16,  8,  5, 24,  9,  7,  1,  8, 23, 15, 19,\n",
       "        14, 21,  3, 21,  5, 10,  4, 20, 23, 23,  5,  2,  8, 24,  3, 17, 18, 24,\n",
       "         4,  2,  5,  5, 13, 13, 22,  3,  7, 12, 13, 14,  6, 24,  9,  7, 17, 12,\n",
       "         3,  5,  8,  3, 19, 22, 22, 24, 24, 13, 10,  5,  3,  8, 17, 23,  2, 17,\n",
       "        18,  9, 21, 21,  6, 13,  5,  2,  5, 17,  2, 21,  5, 10,  7,  5, 23, 19,\n",
       "         4, 10,  7, 15,  9,  3,  7, 14,  7, 24, 20, 23,  7,  5,  8, 24, 18, 15,\n",
       "        24,  3, 20,  9,  1, 12,  4, 20, 16, 20, 13,  4, 23, 10, 13, 19,  6, 19,\n",
       "        18, 10,  4,  2, 19, 24, 21, 17,  7, 22, 17,  8,  5, 20, 16, 17, 21,  4,\n",
       "        20,  5,  5,  2,  8, 10, 21, 24,  9,  4,  7, 21, 18,  8,  8,  3,  8, 17,\n",
       "         6,  5, 20,  8, 20, 24, 23,  4, 18, 19, 16, 22,  3,  7,  4, 21, 17, 24,\n",
       "         9, 19,  2, 13, 13,  5, 16,  2, 20, 21, 18,  9, 23, 24,  1,  5, 14, 24,\n",
       "        22,  8,  5, 24,  6,  2, 24, 23,  5, 10, 17, 10,  5, 12,  5, 24,  8,  5,\n",
       "        13, 10,  9, 17, 20, 18, 13, 10, 21, 13, 17, 14,  8, 10, 20,  3, 17, 21,\n",
       "         2,  3, 24, 12,  4, 23, 24, 22, 18, 10, 23, 16, 19, 20,  5,  6, 13, 20,\n",
       "        17, 23, 17,  2, 18, 18,  9, 20, 10, 24, 20,  3,  8, 14, 22,  2, 20,  6,\n",
       "         3, 18, 13,  3,  7, 10, 21, 13,  1, 19, 24, 23, 10,  3, 23,  9,  9,  7,\n",
       "        16,  4, 24, 24,  5, 21, 24, 16,  9, 23, 22, 18, 24,  4, 22, 14, 16, 23,\n",
       "        20,  3, 14,  7, 10, 14,  9, 23,  3,  3, 14, 20, 21, 19, 21, 20,  5,  9,\n",
       "        16, 24,  3, 12, 18,  8,  8, 21, 16,  9], device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polytope['model'].to(device)(\n",
    "    X.to(device)).argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  0, 11, 12,  9, 21, 21, 18, 20, 16])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.491"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpolytope\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dict' object is not callable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(polytope_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Training...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'TrainModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m relu_network \u001b[38;5;241m=\u001b[39m ReluNetwork(n_inputs, n_polytopes, n_hidden_layers,n_hidden_neurons_per_layer)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mTrainModel\u001b[49m(\n\u001b[1;32m     45\u001b[0m     relu_network, nn\u001b[38;5;241m.\u001b[39mNLLLoss(), learning_rate, model_dataloader, n_epochs\u001b[38;5;241m=\u001b[39mn_epochs, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TrainModel' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Standard library imports\n",
    "import importlib\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "# Third-party imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import GPT2Model, GPT2Config, GPT2Tokenizer\n",
    "from datasets import load_dataset\n",
    "from transformer_lens.utils import tokenize_and_concatenate\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Specific imports from local modules\n",
    "from toy_models.polytope import ReluNetwork, GeneratePolytopeData\n",
    "from toy_models.trainer import Trainer\n",
    "\n",
    "# Device configuration\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "n_inputs = 3\n",
    "n_input_choices = 3\n",
    "n_polytopes =  n_input_choices**n_inputs\n",
    "\n",
    "n_hidden_layers = 5\n",
    "n_hidden_neurons_per_layer = 5\n",
    "n_samples = 10000\n",
    "n_epochs = 10000\n",
    "\n",
    "learning_rate = .001\n",
    "print(\"Generating data...\")\n",
    "train_X, train_y, lookup_dict = GeneratePolytopeData(n_inputs, n_input_choices, n_samples)\n",
    "model_dataloader = DataLoader(\n",
    "    TensorDataset(train_X, train_y), batch_size=64, shuffle=True)\n",
    "relu_network = ReluNetwork(n_inputs, n_polytopes, n_hidden_layers,n_hidden_neurons_per_layer).to(device)\n",
    "\n",
    "print(\"Training...\")\n",
    "_, _, _ = TrainModel(\n",
    "    relu_network, nn.NLLLoss(), learning_rate, model_dataloader, n_epochs=n_epochs, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_inputs = 2\n",
    "n_input_choices = 3\n",
    "n_polytopes = n_input_choices**n_inputs\n",
    "n_hidden_neurons = 4\n",
    "n_hidden_layers = 4\n",
    "n_samples = 1000\n",
    "n_epochs = 1000\n",
    "\n",
    "learning_rate = .01\n",
    "\n",
    "\n",
    "# Load TMS model\n",
    "polytope_model  = ReluNetwork(n_inputs, n_polytopes, n_hidden_neurons,n_hidden_layers).to(device)\n",
    "\n",
    "#polytope_model.load_state_dict(torch.load(f\"{parent_dir}/models/polytope.pth\", weights_only=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DrawNeuralNetwork() missing 1 required positional argument: 'biases_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mDrawNeuralNetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mname\u001b[49m\u001b[43m:\u001b[49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpolytope_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamed_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: DrawNeuralNetwork() missing 1 required positional argument: 'biases_dict'"
     ]
    }
   ],
   "source": [
    "DrawNeuralNetwork({name:param.transpose(0,1) for name,param in polytope_model.named_parameters() if 'weight' in name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating data\n"
     ]
    }
   ],
   "source": [
    "print(\"generating data\")\n",
    "\n",
    "\n",
    "train_X, _, _ = GeneratePolytopeData(n_inputs, n_polytopes, 1000)\n",
    "eval_X, _, _ = GeneratePolytopeData(n_inputs, n_polytopes, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'eigenestimation.eigenhora'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 31\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Reload modules using importlib\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(\u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meigenestimation.eigenhora\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     32\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meigenestimation.loss\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     33\u001b[0m importlib\u001b[38;5;241m.\u001b[39mreload(importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meigenestimation.train\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'eigenestimation.eigenhora'"
     ]
    }
   ],
   "source": [
    "# Remember to login to wandb!\n",
    "!wandb login ${WANDB_API}\n",
    "\n",
    "import sys\n",
    "import os \n",
    "\n",
    "# Add the test directory to sys.path\n",
    "parent_dir = os.path.expanduser('..')\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "\n",
    "\n",
    "# Standard library imports\n",
    "import importlib\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "# Third-party imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import GPT2Model, GPT2Config, GPT2Tokenizer\n",
    "from datasets import load_dataset\n",
    "from transformer_lens.utils import tokenize_and_concatenate\n",
    "import wandb\n",
    "\n",
    "\n",
    "# Reload modules using importlib\n",
    "importlib.reload(importlib.import_module('eigenestimation.eigenhora'))\n",
    "importlib.reload(importlib.import_module('eigenestimation.loss'))\n",
    "importlib.reload(importlib.import_module('eigenestimation.train'))\n",
    "importlib.reload(importlib.import_module('evaluation.examples'))\n",
    "importlib.reload(importlib.import_module('evaluation.networks'))\n",
    "\n",
    "importlib.reload(importlib.import_module('toy_models.tms'))\n",
    "importlib.reload(importlib.import_module('eigenestimation.utils'))\n",
    "\n",
    "\n",
    "\n",
    "from eigenestimation.eigenhora import EigenHora\n",
    "from eigenestimation import loss\n",
    "from eigenestimation.train import Train\n",
    "from evaluation.examples import TopActivatingSamples \n",
    "from evaluation.networks import DrawNeuralNetwork\n",
    "\n",
    "from toy_models import tms\n",
    "from eigenestimation.utils import TransformDataLoader, DeleteParams, RetrieveWandBArtifact\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/workspace/eigenestimation/notebooks/wandb/run-20250108_193753-7xo4rgyi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/brianna-chrisman-2024/Eigenestimation/runs/7xo4rgyi' target=\"_blank\">polytopes</a></strong> to <a href='https://wandb.ai/brianna-chrisman-2024/Eigenestimation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/brianna-chrisman-2024/Eigenestimation' target=\"_blank\">https://wandb.ai/brianna-chrisman-2024/Eigenestimation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/brianna-chrisman-2024/Eigenestimation/runs/7xo4rgyi' target=\"_blank\">https://wandb.ai/brianna-chrisman-2024/Eigenestimation/runs/7xo4rgyi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "einsum(): subscript c has size 4 for operand 1 which does not broadcast with previously seen size 16",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m project_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meigenestimation\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     18\u001b[0m run_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolytopes\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 20\u001b[0m \u001b[43mTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43meigenmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL0_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m      \u001b[49m\u001b[43meval_fns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mTopActivatingSamples\u001b[49m\u001b[43m:\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataloader\u001b[49m\u001b[43m)\u001b[49m \n",
      "File \u001b[0;32m~/workspace/eigenestimation/notebooks/../eigenestimation/train.py:61\u001b[0m, in \u001b[0;36mTrain\u001b[0;34m(eigenmodel, jacobian_dataloader, lr, n_epochs, L0_penalty, device, project_name, run_name, eval_fns, eval_dataloader)\u001b[0m\n\u001b[1;32m     58\u001b[0m jacobian \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m jacobian\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     60\u001b[0m n_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 61\u001b[0m jvp \u001b[38;5;241m=\u001b[39m \u001b[43meigenmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjacobian\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m reconstruction \u001b[38;5;241m=\u001b[39m eigenmodel\u001b[38;5;241m.\u001b[39mreconstruct(jvp\u001b[38;5;241m.\u001b[39mrelu())\n\u001b[1;32m     63\u001b[0m jvp_einops_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(jvp\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)])\n",
      "File \u001b[0;32m~/workspace/eigenestimation/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/eigenestimation/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1844\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1846\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1848\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[1;32m   1849\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/workspace/eigenestimation/env/lib/python3.11/site-packages/torch/nn/modules/module.py:1790\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1787\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1788\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1790\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1792\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1793\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1794\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1795\u001b[0m     ):\n\u001b[1;32m   1796\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/eigenestimation/notebooks/../eigenestimation/eigenhora.py:43\u001b[0m, in \u001b[0;36mEigenHora.forward\u001b[0;34m(self, jacobian)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_rank[name][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m     42\u001b[0m         jvp_dict[name] \u001b[38;5;241m=\u001b[39m einops\u001b[38;5;241m.\u001b[39meinsum(jvp_dict[name], tensor, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf r ... w, w r f -> f r ...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m     jvp_dict[name] \u001b[38;5;241m=\u001b[39m \u001b[43meinops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjvp_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlow_rank\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf r ... w, w r f -> ... f\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m jvp \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([jvp_dict[name] \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m jvp_dict], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# Dimensions = (samples) x features\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jvp\n",
      "File \u001b[0;32m~/workspace/eigenestimation/env/lib/python3.11/site-packages/einops/einops.py:907\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*tensors_and_pattern)\u001b[0m\n\u001b[1;32m    905\u001b[0m tensors \u001b[38;5;241m=\u001b[39m tensors_and_pattern[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    906\u001b[0m pattern \u001b[38;5;241m=\u001b[39m _compactify_pattern_for_einsum(pattern)\n\u001b[0;32m--> 907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/eigenestimation/env/lib/python3.11/site-packages/einops/_backends.py:287\u001b[0m, in \u001b[0;36mTorchBackend.einsum\u001b[0;34m(self, pattern, *x)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meinsum\u001b[39m(\u001b[38;5;28mself\u001b[39m, pattern, \u001b[38;5;241m*\u001b[39mx):\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/eigenestimation/env/lib/python3.11/site-packages/torch/functional.py:402\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    404\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[0;31mRuntimeError\u001b[0m: einsum(): subscript c has size 4 for operand 1 which does not broadcast with previously seen size 16"
     ]
    }
   ],
   "source": [
    "def model0(y):\n",
    "    return torch.ones_like(y).softmax(dim=-1)\n",
    "\n",
    "hora_features = 9\n",
    "hora_rank = 1\n",
    "\n",
    "#DeleteParams(polytope_model, [name for name, param in polytope_model.#named_parameters() if 'bias' in name])\n",
    "\n",
    "eigen_X\n",
    "eigenmodel = EigenHora(\n",
    "    polytope_model, model0, loss.KLDivergenceLoss(), hora_features, hora_rank, device=device).to(device)\n",
    "dataloader = TransformDataLoader(\n",
    "    eigen_X.to(device), batch_size=16, transform_fn=eigenmodel.compute_jacobian)\n",
    "\n",
    "eval_dataloader = TransformDataLoader(eval_X.to(device), batch_size=16, transform_fn=eigenmodel.compute_jacobian)\n",
    "\n",
    "project_name = 'eigenestimation'\n",
    "run_name = 'polytopes'\n",
    "\n",
    "Train(eigenmodel, dataloader, lr=.001, n_epochs=500, L0_penalty=.01, device=device, project_name=project_name, run_name=run_name,\n",
    "      eval_fns={TopActivatingSamples:[10, None, True]}, eval_dataloader=eval_dataloader) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".eigenestimation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
